[
  {
    "objectID": "variosparametros.html#ejemplo-1.-página-66-gelman.",
    "href": "variosparametros.html#ejemplo-1.-página-66-gelman.",
    "title": "3  Modelos de varios parámetros",
    "section": "3.1 Ejemplo 1. Página 66, Gelman.",
    "text": "3.1 Ejemplo 1. Página 66, Gelman.\nCargamos la librería MASS, que contiene los datos del experimento de Simon Newcomb en 1882:\n\nlibrary(MASS)\ndata(\"newcomb\")\n\nRecuerden que se busca estimar la velocidad media en la que la luz viaja en una distancia de 7442 metros.\nHistograma de los datos observados por Newcomb:\n\nhist(newcomb,breaks = 40)\n\n\n\n\ndonde se nota un cierto grado de simetría en la densidad excepto por los dos valores negativos de la serie.\nCon el fin de generar una muestra posterior multivariada de \\((\\mu,\\sigma^2)\\), primero generamos la muestra posterior de \\(\\sigma^2\\):\n\ns2 &lt;- var(newcomb)\nsigma2_pre &lt;- rchisq(n = 1000,df = 65)\nsigma2_post &lt;- sqrt(s2)/sigma2_pre\nhist(sigma2_post)\n\n\n\n\nla cual es una muestra de una variable según \\(Inv-\\chi^2(n-1,s^2)\\). La muestra de la media \\(\\mu|\\sigma^2,y\\) es:\n\nn_tot &lt;- length(newcomb)\nybar &lt;- mean(newcomb)\nmu_post &lt;- rnorm(n = 1000,mean = ybar,sd = sqrt(sigma2_post/n_tot))\nhist(mu_post)\n\n\n\n\nUn intervalo de credibilidad al 90% para \\(\\mu\\) (dado que \\(\\sigma\\) es fijo) es:\n\nquantile(mu_post,probs = c(0.05,0.95))\n\n      5%      95% \n26.13033 26.29706 \n\n\nVale la pena compararlo con un intervalo de credibilidad para \\(\\mu\\) sin considerar \\(\\sigma\\) fijo:\n\nybar + c(-1,1)*qt(0.95,df = 65)*sqrt(s2/n_tot)\n\n[1] 24.00509 28.41916\n\n\nel cual por supuesto va a ser más disperso.\nLa distribución posterior predictiva de una nueva observación del experimento, se infiere a través de una muestra:\n\ny_tilde_post &lt;- rnorm(n = 1000,mean = mu_post,sd = sqrt(sigma2_post))\nhist(y_tilde_post)\n\n\n\nquantile(y_tilde_post,probs = c(0.05,0.95))\n\n      5%      95% \n25.54431 26.87329 \n\n\ny este ultimo sería el intervalo de credibilidad al 90% para la nueva observación \\(\\tilde y\\)."
  },
  {
    "objectID": "variosparametros.html#ejemplo-2-sección-4.2-albert.",
    "href": "variosparametros.html#ejemplo-2-sección-4.2-albert.",
    "title": "3  Modelos de varios parámetros",
    "section": "3.2 Ejemplo 2: sección 4.2, Albert.",
    "text": "3.2 Ejemplo 2: sección 4.2, Albert.\nDatos de tiempos (en minutos) de corredores de maratón con edades entre 20 y 29 años:\n\nlibrary(LearnBayes)\ndata(\"marathontimes\")\nattach(marathontimes)\nhist(time)\n\n\n\n\n\n\n\n\nAsimismo se puede graficar una figura de contorno:\n\nd = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab=\"mean\",ylab=\"variance\")\n\n\n\n\n\n\n\n\nPor otro lado generamos una muestra posterior de los dos parámetros de interés, para incorporarlos en el gráfico anterior:\n\nS &lt;- sum((time-mean(time))^2)\n\nn &lt;- length(time)\n\nsigma2_post &lt;- S/rchisq(1000,n-1)\nhist(sigma2_post)\n\n\n\n\n\n\n\nmu_post &lt;- rnorm(n = 1000,mean = mean(time),sd = sqrt(sigma2_post/n))\nhist(mu_post)\n\n\n\n\n\n\n\n\nIncorporamos la muestra en el gráfico de la log-densidad-posterior:\n\nd = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab=\"mean\",ylab=\"variance\")\npoints(mu_post,sigma2_post)\n\n\n\n\n\n\n\n\nIntervalos de credibilidad para \\(\\mu|\\sigma^2, y\\) (en horas) y para \\(\\sigma^2|y\\) son:\n\nquantile(mu_post,c(0.025,0.975))/60\n\n    2.5%    97.5% \n4.250180 5.046258 \n\nquantile(sqrt(sigma2_post),c(0.025,0.975))\n\n    2.5%    97.5% \n38.13595 71.99675",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "variosparametros.html#ejemplo-3-sección-4.3-del-albert",
    "href": "variosparametros.html#ejemplo-3-sección-4.3-del-albert",
    "title": "3  Modelos de varios parámetros",
    "section": "3.3 Ejemplo 3: sección 4.3 del Albert",
    "text": "3.3 Ejemplo 3: sección 4.3 del Albert\n1447 adultos mostraron su preferencia de voto a Bush: \\(y_1=727\\), Dukakis: \\(y_2=583\\) y \\(y_3=137\\) a otros candidatos para la elección presidencial de 1988. Se asume que \\(y_1,y_2,y_3\\) sigue una distribución multinomial con parámetros \\(\\theta_1,\\theta_2,\\theta_3\\) respectivamente. Entonces la distribución posterior de estos parámetros sigue una distribución Dirichlet, simulados de la siguiente forma:\n\nalpha &lt;- c(728,584,138)\ntheta_post &lt;- rdirichlet(1000,alpha)\n\ncon histogramas:\n\nhist(theta_post[,1])\n\n\n\n\n\n\n\nhist(theta_post[,2])\n\n\n\n\n\n\n\nhist(theta_post[,3])\n\n\n\n\n\n\n\n\nEs de interés hacer inferencia acerca de la diferencia en la probabilidad de voto de Bush vs Dukakis: \\(\\theta_1-\\theta_2\\):\n\nhist(theta_post[,1]-theta_post[,2])\n\n\n\n\n\n\n\n\ny un intervalo de credibilidad al 95% para esta diferencia es:\n\nquantile(theta_post[,1]-theta_post[,2],c(0.025,0.975))\n\n      2.5%      97.5% \n0.05140505 0.14737474 \n\n\nPor lo tanto con una probabilidad del 95% la diferencia siempre faorece al primer candidato. Es más, si estimamos la probabilidad de que el segundo candidato resulte ganador:\n\nsum(theta_post[,1]-theta_post[,2]&lt;0)/1000\n\n[1] 0\n\n\nEsta probabilidad es nula.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "variosparametros.html#evaluación-práctica-3",
    "href": "variosparametros.html#evaluación-práctica-3",
    "title": "3  Modelos de varios parámetros",
    "section": "3.4 Evaluación Práctica 3",
    "text": "3.4 Evaluación Práctica 3\nDefinición de variables:\n\ny_N &lt;- 1601\nn_N &lt;- y_N+162527\n\ny_S &lt;- 510\nn_S &lt;- y_S+412368\n\nSimulación de 1000 valores de la distribución posterior conjunta de \\((p_N,p_S)\\):\n\np_N_post &lt;- rbeta(1000,shape1 = y_N+1,shape2 = n_N-y_N+1)\n\np_S_post &lt;- rbeta(1000,shape1 = y_S+1,shape2 = n_S-y_S+1)\n\nhist(p_N_post)\n\n\n\n\n\n\n\nhist(p_S_post)\n\n\n\n\n\n\n\n\nHistograma del riesgo relativo:\n\nriesgo_rel_post &lt;- p_N_post/p_S_post\nhist(riesgo_rel_post)\n\n\n\n\n\n\n\n\nIntervalo de credibilidad al 95% para el riesgo relativo:\n\nquantile(riesgo_rel_post,probs = c(0.025,0.975))\n\n    2.5%    97.5% \n7.157067 8.717791 \n\n\nHistograma de la diferencia en riesgos:\n\ndiferencia_post &lt;- p_N_post-p_S_post\nhist(diferencia_post)\n\n\n\n\n\n\n\n\nProbabilidad posterior de que la diferencia exceda 0:\n\nmean(diferencia_post&gt;0)\n\n[1] 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "pensamiento.html#ejemplo-1",
    "href": "pensamiento.html#ejemplo-1",
    "title": "1  Pensamiento Bayesiano",
    "section": "",
    "text": "Pregunta de investigación: ¿Qué proporción de estudiantes universitarios duermen al menos 8 horas diarias?\nNotación: \\(p\\): proporción de estudiantes que duermen al menos 8 horas diarias.\nDatos: Muestra de 27 estudiantes donde 11 sí durmieron al menos 8 horas ayer.\nModelo: \\[L(p)\\propto p^s(1-p)^f\\]\nDistribución posterior: Si \\(g(p)\\) es la densidad previa de \\(p\\), entonces: \\[g(p|\\text{datos})\\propto g(p)L(p)\\] Primera escogencia de previa \\(g(p)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1.1.1 Predicción\nBajo la primera previa:\n\np &lt;- seq(0.05, 0.95, by=.1)\nprior &lt;- c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\nprior &lt;- prior/sum(prior)\nm &lt;- 20\nys &lt;- 0:20\npred &lt;- pdiscp(p, prior, m, ys)\nround(cbind(0:20,pred),3)\n\n          pred\n [1,]  0 0.020\n [2,]  1 0.044\n [3,]  2 0.069\n [4,]  3 0.092\n [5,]  4 0.106\n [6,]  5 0.112\n [7,]  6 0.110\n [8,]  7 0.102\n [9,]  8 0.089\n[10,]  9 0.074\n[11,] 10 0.059\n[12,] 11 0.044\n[13,] 12 0.031\n[14,] 13 0.021\n[15,] 14 0.013\n[16,] 15 0.007\n[17,] 16 0.004\n[18,] 17 0.002\n[19,] 18 0.001\n[20,] 19 0.000\n[21,] 20 0.000\n\n\nBajo la segunda previa (beta):\n\nfy &lt;- choose(m,ys)*beta(a+ys,b = b+m-ys)/beta(a,b)\nab &lt;- c(3.26, 7.19)\npred &lt;- pbetap(ab, m, ys)\n\nO por simulación:\n\np &lt;- rbeta(1000, 3.26, 7.19)\ny &lt;- rbinom(1000, 20, p)\ntable(y)\n\ny\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18 \n 21  44  72  87 103 114 102 109  91  82  68  40  26  17  13   7   3   1 \n\n\n\nfreq &lt;- table(y)\nys &lt;- as.integer(names(freq))\npredprob &lt;- freq / sum(freq)\n\ndf &lt;- data.frame(ys = ys, predprob = predprob)\n\n\nggplot(df, aes(x = ys, y = predprob)) +\n  geom_line(stat = \"identity\", type = \"h\", color = \"blue\", size = 1.5) +\n  labs(x = \"y\", y = \"Predictive Probability\") +\n  theme_minimal()\n\nWarning in geom_line(stat = \"identity\", type = \"h\", color = \"blue\", size =\n1.5): Ignoring unknown parameters: `type`\n\n\nDon't know how to automatically pick scale for object of type &lt;table&gt;.\nDefaulting to continuous.\n\n\n\n\n\n\n\n\n\nCálculo de intervalo de credibilidad al 90% usando la probabilidad predictiva anterior:\n\ndist &lt;- cbind(ys,predprob)\ncovprob &lt;- .9\ndiscint(dist,covprob)\n\n$prob\n   11 \n0.912 \n\n$set\n 1  2  3  4  5  6  7  8  9 10 11 \n 1  2  3  4  5  6  7  8  9 10 11",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pensamiento Bayesiano</span>"
    ]
  },
  {
    "objectID": "pensamiento.html#ejemplo-2-ejercicio-5-capítulo-2-albert",
    "href": "pensamiento.html#ejemplo-2-ejercicio-5-capítulo-2-albert",
    "title": "1  Pensamiento Bayesiano",
    "section": "1.2 Ejemplo 2 (Ejercicio 5, Capítulo 2, Albert)",
    "text": "1.2 Ejemplo 2 (Ejercicio 5, Capítulo 2, Albert)\nPrevia:\n\nprevia_mu &lt;- data.frame(mu = seq(20,70,by = 10),\n                        gmu = c(.1,.15,.25,.25,.15,.1))\n\nDatos:\n\ny_snow &lt;- c(38.6,42.4,57.5,40.5,51.7,67.1,33.4,\n            60.9,64.1,40.1,40.7,6.4)\ny_bar &lt;- mean(y_snow)\n\nVerosimilitud:\n\nposterior_mu &lt;- previa_mu %&gt;%\n  mutate(like = exp(-12/(2*10^2)*(mu-y_bar)^2))\n\nPosterior:\n\nposterior_mu &lt;- posterior_mu %&gt;% \n  mutate(post = gmu*like/sum(gmu*like))\nposterior_mu\n\n  mu  gmu         like         post\n1 20 0.10 2.201480e-17 1.954479e-17\n2 30 0.15 8.192991e-07 1.091063e-06\n3 40 0.25 1.873425e-01 4.158078e-01\n4 50 0.25 2.632064e-01 5.841881e-01\n5 60 0.15 2.272076e-06 3.025731e-06\n6 70 0.10 1.205079e-16 1.069871e-16\n\n\nIntervalo de credibilidad al 80% para \\(\\mu\\):\n\ndist_mu &lt;- posterior_mu %&gt;% select(mu,post)\ncovprob &lt;- .8\ndiscint(dist_mu,covprob)\n\n$prob\n[1] 0.9999959\n\n$set\n[1] 40 50\n\n\nTambién se podría estimar el intervalo de credibilidad vía simulación:\n\nmuestra_mu &lt;- sample(dist_mu$mu,size = 1000,replace = T,prob = dist_mu$post)\nquantile(muestra_mu,probs = c(0.1,0.9))\n\n10% 90% \n 40  50",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pensamiento Bayesiano</span>"
    ]
  },
  {
    "objectID": "pensamiento.html#ejemplo-3-evaluación-práctica-1",
    "href": "pensamiento.html#ejemplo-3-evaluación-práctica-1",
    "title": "1  Pensamiento Bayesiano",
    "section": "1.3 Ejemplo 3 (Evaluación Práctica 1)",
    "text": "1.3 Ejemplo 3 (Evaluación Práctica 1)\nLos siguientes datos simulan el sexo de 200 recién nacidos, en donde 1 denota niño y 0 denota niña.\n\nrecien_n\n\n  [1] 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0\n [38] 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1\n [75] 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0\n[112] 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0\n[149] 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n[186] 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0\n\n\nVamos a utilizar dos distintas formas de definir numéricamente la previa:\n\n1.3.1 Previa 1\nSe va a definir una previa usando una grilla de tamaño 1000 con 100000 muestras:\n\nset.seed(10)\np_prev_sample &lt;- runif(n = 100000)\nhisto_1 &lt;- hist(p_prev_sample,breaks = 1000)\n\n\n\n\n\n\n\np_post1 &lt;- data.frame(p = histo_1$breaks[-1],prev = histo_1$counts)\n\np_post1 &lt;- p_post1 %&gt;% mutate(prev = prev / sum(prev))\n\nCálculo de probabilidad posterior y valor de \\(p\\) que la maximiza:\n\ny &lt;- sum(recien_n)\nn_tot &lt;- length(recien_n)\np_post1 &lt;- p_post1 %&gt;% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %&gt;%\n  mutate(post = post / sum(post))\nplot(p_post1$p,p_post1$post,type='l')\n\n\n\n\n\n\n\n\nValor que maximiza la posterior:\n\np_post1$p[which.max(p_post1$post)]\n\n[1] 0.606\n\n\n\n\n1.3.2 Previa 2\nSe va a definir una previa usando una grilla de tamaño 10 con 1000 muestras:\n\nset.seed(10)\np_prev_sample &lt;- runif(n = 1000)\nhisto_2 &lt;- hist(p_prev_sample,breaks = 10)\n\n\n\n\n\n\n\np_post2 &lt;- data.frame(p = histo_2$breaks[-1],prev = histo_2$counts)\n\np_post2 &lt;- p_post2 %&gt;% mutate(prev = prev / sum(prev))\n\nCálculo de probabilidad posterior y valor de \\(p\\) que la maximiza:\n\np_post2 &lt;- p_post2 %&gt;% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %&gt;%\n  mutate(post = post / sum(post))\nplot(p_post2$p,p_post2$post,type='l')\n\n\n\n\n\n\n\n\nValor que maximiza la posterior:\n\np_post2$p[which.max(p_post2$post)]\n\n[1] 0.6\n\n\nDe ahora en adelante se utilizará la primera previa para calcular la muestra de tamaño 10000 de la distribución posterior:\n\nmuestra_post &lt;- sample(p_post1$p,replace = T,size = 10000,prob = p_post1$post)\n\nCálculo del intervalo de credibilidad al 90%:\n\nquantile(muestra_post,probs = c(0.05,0.95))\n\n   5%   95% \n0.552 0.666 \n\n\nde donde se deduce que con una probabilidad de 90%, el parámetro \\(p\\) (proporción de niños) esté contenido en el intervalo \\((0.55,0.67)\\).\nAhora vamos a estimar la probabilidad posterior de que un recién nacido fuera de la muestra sea niño:\n\ny_post &lt;- rbinom(n = 1000,prob = muestra_post,size = 1)\n\nprob_prediccion &lt;- sum(y_post)/1000\nprob_prediccion\n\n[1] 0.609",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pensamiento Bayesiano</span>"
    ]
  },
  {
    "objectID": "unparametro.html#ejemplo-1",
    "href": "unparametro.html#ejemplo-1",
    "title": "2  Modelos de un parámetro",
    "section": "2.1 Ejemplo 1",
    "text": "2.1 Ejemplo 1\nAnálisis del ejemplo de la página 37 del Gelman.\nUn estudio alemán concluyó que de un total de 980 nacimientos con condición de placenta previa, 437 nacieron niñas.\nPregunta de investigación: Qué tan evidente es la afirmación de que en la población de nacimientos de placenta previa, la proporción de nacimientos femeninos sea menor a 0.485?"
  },
  {
    "objectID": "unparametro.html#primera-previa",
    "href": "unparametro.html#primera-previa",
    "title": "2  Modelos de un parámetro",
    "section": "2.2 Primera previa",
    "text": "2.2 Primera previa\nSuponga que \\(\\theta\\): proporción de niñas que nacieron bajo la condición de placenta previa. Usando una previa uniforme para \\(\\theta\\) en (0,1), la media posterior es \\(Beta(438,544)\\):\n\na_post &lt;- 438\nb_post &lt;- 544\n\npor lo tanto la media y la desviación posterior del parámetro \\(\\theta\\) es:\n\nmedia_post &lt;- a_post/(a_post+b_post)\nsd_post &lt;- sqrt(media_post*(1-media_post)/983)\n\nComo la posterior es beta, se puede calcular directamente que un intervalo de credibilidad al 95% es \\((0.415,0.477)\\), lo cual se puede comprobar de manera aproximada al calcular:\n\npbeta(0.477,shape1 = a_post,shape2 = b_post)-\n  pbeta(0.415,shape1 = a_post,shape2 = b_post)\n\n[1] 0.9495027\n\n\nPor la justificación vista en clase, se puede aproximar la distribución posterior con una distribución normal y calcular directamente los límites del intervalo de credibilidad a como sigue:\n\ncuantil0975_norm &lt;- media_post+qnorm(0.975)*sd_post\ncuantil025_norm &lt;- media_post-qnorm(0.975)*sd_post\nc(cuantil025_norm,cuantil0975_norm)\n\n[1] 0.4149546 0.4771025\n\n\nAsimismo, podemos obtener una muestra aleatoria de la posterior de la sifuiente forma:\n\ntheta_post &lt;- rbeta(1000,shape1 = a_post,b_post)\nhist(theta_post)\n\n\n\n\n\n\n\n\ny así calcular el mismo intervalo de credibilidad:\n\nquantile(theta_post,probs = c(0.025,0.975))\n\n     2.5%     97.5% \n0.4137056 0.4769427 \n\n\ny un estimador puntual bayesiano para \\(\\theta\\):\n\nmedian(theta_post)\n\n[1] 0.4451357\n\n\nPor otro lado también podemos usar la reparametrización \\(\\phi=\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\) para aplicar la aproximación normal sobre un parámetro totalmente definido en \\(\\mathbb R\\):\n\nphi_post &lt;- log(theta_post/(1-theta_post))\nhist(phi_post)\n\n\n\n\n\n\n\nphi_mean &lt;- mean(phi_post)\nphi_sd &lt;- sd(phi_post)\n\ny de esta forma aproximar el mismo intervalo de credibilidad para \\(\\theta\\), usando la transformación logística:\n\nlogistico &lt;- function(u){\n  exp(u)/(1+exp(u))\n}\n\nlogistico(phi_mean+qnorm(0.975)*phi_sd)\n\n[1] 0.4766789\n\nlogistico(phi_mean-qnorm(0.975)*phi_sd)\n\n[1] 0.4133679\n\n\nTambién podemos hacer inferencia sobre la razón niña/niño (\\(\\theta/(1-\\theta)\\)):\n\nrazon_post &lt;- theta_post/(1-theta_post)\nquantile(razon_post,probs = c(0.025,0.975))\n\n     2.5%     97.5% \n0.7056280 0.9118364 \n\n\nLa pregunta de investigación puede ser contestada al calcular lo siguiente e interpretarlo de forma apropiada según lo comentado en clase:\n\npbeta(0.485,shape1 = a_post,shape2 = b_post)\n\n[1] 0.992826\n\n\nAsimismo, podemos calcular el periodo de retorno del evento principal al calcular:\n\n1/pbeta(0.485,shape1 = a_post,shape2 = b_post,lower.tail = F)\n\n[1] 139.392",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modelos de un parámetro</span>"
    ]
  },
  {
    "objectID": "unparametro.html#ejemplo-2",
    "href": "unparametro.html#ejemplo-2",
    "title": "2  Modelos de un parámetro",
    "section": "2.3 Ejemplo 2",
    "text": "2.3 Ejemplo 2\nDesarrollamos una solución alternativa al ejemplo en la sección 3.2 del Albert:\nEn este caso se tiene datos correspondientes a las diferencias entre los resultados de partidos de fútbol americano y “point spreads”:\n\nlibrary(LearnBayes)\ndata(\"footballscores\")\nattach(footballscores)\nd &lt;- favorite-underdog-spread\n\nSi asumimos un modelo normal en las diferencias con media 0 y varianza \\(\\sigma^2\\), el estadístico suficiente respectivo es:\n\nv &lt;- sum(d^2)\nn &lt;- length(d)\nshow(v)\n\n[1] 128902\n\n\nAsumiendo una distribución previa \\(Inv-\\chi^2(v_0=1, \\sigma^2_0=1)\\), según lo visto en clase, la probabilidad posterior de \\(\\sigma^2\\) es \\(Inv-\\chi^2(v_1=n+1, \\sigma^2_1=nv+1)\\) en donde:\n\nv1 &lt;- n+1\nsigma1 &lt;- sqrt(n*v+1) \n\nSimulamos una muestra de tamaño 1000 de la distribución posterior de \\(\\sigma^2\\). Noten que la simulación usa las propiedades de una chi-cuadrado inversa.\n\nXpost &lt;- rchisq(n = 1000,df = n+1) \nZ &lt;- 1/Xpost\nsigma2_post &lt;- sigma1*Z\n\nO bien pueden usar la siguiente función que simula las muestras directamente:\n\nlibrary(LaplacesDemon)\n\n\nAttaching package: 'LaplacesDemon'\n\n\nThe following object is masked from 'package:LearnBayes':\n\n    rdirichlet\n\nsigma2_post2 &lt;- rinvchisq(n = 1000,df = v1,scale = sigma1/v1)\n\nNoten que el parametro de escala en esta función hay que dividirlo por los grados de libertad para que sea igual al que definimos en clase. En ambos casos se puede calcular un intervalo de credibilidad al 95% y un estimador puntual de \\(\\sigma^2\\):\n\nquantile(sigma2_post, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n12.50771 13.81855 15.51500 \n\nquantile(sigma2_post2, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n12.39380 13.80629 15.41711",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modelos de un parámetro</span>"
    ]
  },
  {
    "objectID": "unparametro.html#ejemplo-3",
    "href": "unparametro.html#ejemplo-3",
    "title": "2  Modelos de un parámetro",
    "section": "2.4 Ejemplo 3",
    "text": "2.4 Ejemplo 3\nConsidere el ejemplo de la página 45 del Gelman, en donde se modela la tasa de muerte producto del asma en una ciudad de Estados Unidos. La población de la ciudad es de 200000 personas. En un año han fallecido 3 personas, dando una tasa cruda de:\n\n3/200000\n\n[1] 1.5e-05\n\n\n1.5 muertes por 100000 habitantes. Asumimos que el conteo de muertes \\(y\\sim Poisson(2\\theta)\\) indicando que la tasa se mide en número de casos por 100000 habitantes, con una población expuesta de \\(2\\times 100000\\) habitantes. Asumiendo una previa \\(\\theta \\sim Gamma(3,5)\\) se tiene un valor esperado (previo) de la tasa de muerte de:\n\n3/5\n\n[1] 0.6\n\n\npor cada 100000 habitantes. Note que en este caso hay una probabilidad previa de más de un 97.5% de que la tasa de muerte esté por debajo de 1.44:\n\npgamma(1.5,shape = 3,rate = 5)\n\n[1] 0.9797433\n\n\nUna muestra posterior de \\(\\theta\\) asumiendo que \\(y=3\\) es:\n\ntheta_post &lt;- rgamma(n = 1000,shape = 6,rate = 7)\n\ny gráficamente:\n\nhist(theta_post)\n\n\n\n\n\n\n\n\ny un intervalo de credibilidad al 95% sería:\n\nquantile(theta_post, probs = c(0.025, 0.5, 0.975))\n\n     2.5%       50%     97.5% \n0.3243252 0.8210934 1.6520077 \n\n\nSi se observara la misma cantidad de muertes por año en la misma ciudad en un periodo de 10 años, y asumimos que la población es constante, la posterior la podemos muestrear de la siguiente forma:\n\ntheta_post2 &lt;- rgamma(n = 1000,shape = 33,rate = 25)\nhist(theta_post2)\n\n\n\n\n\n\n\n\ny el intervalo de credibilidad correspondiente para \\(\\theta\\) al 95% sería:\n\nquantile(theta_post2, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n0.931524 1.310252 1.854992",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modelos de un parámetro</span>"
    ]
  },
  {
    "objectID": "unparametro.html#evaluación-práctica-2",
    "href": "unparametro.html#evaluación-práctica-2",
    "title": "2  Modelos de un parámetro",
    "section": "2.5 Evaluación Práctica 2",
    "text": "2.5 Evaluación Práctica 2\nTiempo de quemado de las cinco bombillas:\n\ny &lt;- c(751,594,1213,1126,819)\n\nSimulación de la distribución posterior de \\(\\theta\\):\n\nn_tot &lt;- length(y)\ns &lt;- sum(y)\ntheta_post &lt;- rgamma(n = 1000,shape = n_tot,rate = s)\nhist(theta_post)\n\n\n\n\n\n\n\n\nMuestra posterior de \\(\\lambda\\):\n\nlambda_post &lt;- 1/theta_post\nhist(lambda_post)\n\n\n\n\n\n\n\n\nLa probabilidad posterior de que \\(\\lambda\\) exceda las 1000 horas se puede estimar:\n\nsum(lambda_post&gt;1000)/1000\n\n[1] 0.446\n\n\nLa probabilidad predictiva posterior del tiempo de quemado de una bombilla es:\n\ny_tilde &lt;- rexp(n = 1000,rate = 1/lambda_post)\ny_tilde_freq &lt;- hist(y_tilde,breaks = 20)\n\n\n\n\n\n\n\ny_tilde_x &lt;- y_tilde_freq$mids\ny_tilde_post &lt;- y_tilde_freq$counts/1000\nplot(y_tilde_x,y_tilde_post,type='l',ylab = 'Prob. Post.')\n\n\n\n\n\n\n\n\nIntervalo de credibilidad al 90% para el tiempo de quemado:\n\nquantile(y_tilde,probs = c(0.05,0.95))\n\n        5%        95% \n  44.79943 3585.42291",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modelos de un parámetro</span>"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Bayesiana",
    "section": "",
    "text": "Prefacio\nNotas computacionales del curso XS0128 (Inferencia Bayesiana) para el I-2024.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "variosparametros.html",
    "href": "variosparametros.html",
    "title": "3  Modelos de varios parámetros",
    "section": "",
    "text": "3.1 Ejemplo 1. Página 66, Gelman.\nCargamos la librería MASS, que contiene los datos del experimento de Simon Newcomb en 1882:\nlibrary(MASS)\ndata(\"newcomb\")\nRecuerden que se busca estimar la velocidad media en la que la luz viaja en una distancia de 7442 metros.\nHistograma de los datos observados por Newcomb:\nhist(newcomb,breaks = 40)\ndonde se nota un cierto grado de simetría en la densidad excepto por los dos valores negativos de la serie.\nCon el fin de generar una muestra posterior multivariada de \\((\\mu,\\sigma^2)\\), primero generamos la muestra posterior de \\(\\sigma^2\\):\ns2 &lt;- var(newcomb)\nsigma2_pre &lt;- rchisq(n = 1000,df = 65)\nsigma2_post &lt;- sqrt(s2)/sigma2_pre\nhist(sigma2_post)\nla cual es una muestra de una variable según \\(Inv-\\chi^2(n-1,s^2)\\). La muestra de la media \\(\\mu|\\sigma^2,y\\) es:\nn_tot &lt;- length(newcomb)\nybar &lt;- mean(newcomb)\nmu_post &lt;- rnorm(n = 1000,mean = ybar,sd = sqrt(sigma2_post/n_tot))\nhist(mu_post)\nUn intervalo de credibilidad al 90% para \\(\\mu\\) (dado que \\(\\sigma\\) es fijo) es:\nquantile(mu_post,probs = c(0.05,0.95))\n\n      5%      95% \n26.13126 26.29339\nVale la pena compararlo con un intervalo de credibilidad para \\(\\mu\\) sin considerar \\(\\sigma\\) fijo:\nybar + c(-1,1)*qt(0.95,df = 65)*sqrt(s2/n_tot)\n\n[1] 24.00509 28.41916\nel cual por supuesto va a ser más disperso.\nLa distribución posterior predictiva de una nueva observación del experimento, se infiere a través de una muestra:\ny_tilde_post &lt;- rnorm(n = 1000,mean = mu_post,sd = sqrt(sigma2_post))\nhist(y_tilde_post)\n\n\n\n\n\n\n\nquantile(y_tilde_post,probs = c(0.05,0.95))\n\n      5%      95% \n25.56766 26.91178\ny este ultimo sería el intervalo de credibilidad al 90% para la nueva observación \\(\\tilde y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-capítulo-5-albert.",
    "href": "computacion_bayes.html#ejemplo-capítulo-5-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.1 Ejemplo Capítulo 5, Albert.",
    "text": "4.1 Ejemplo Capítulo 5, Albert.\nLibrerías:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(LearnBayes)\n\nDatos de número de casos de cáncer de estómago en hombres en ciudades de Missouri, USA:\n\ndata(\"cancermortality\")\n\nGráfico de contorno de la logverosimilitud del modelo beta-binomial, ante la posible presencia de sobredispersión:\n\nmycontour(betabinexch0,c(.0001,.003,1,20000),cancermortality,\n          xlab=\"eta\",ylab=\"K\")\n\n\n\n\nen donde se evidencia una alta asimetría en ambos parámetros. Se reparametriza el modelo usando las transformaciones \\(\\theta_1=\\log\\left(\\frac{\\eta}{1-\\eta}\\right)\\), \\(\\theta_2=\\log K\\) y se obtiene la siguiente logverisimilitud transformada:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\n\n\n\n\nAproximamos la log-densidad posterior usando el método de Laplace:\n\nfit &lt;- laplace(betabinexch,c(-7,6),cancermortality)\n\ncon el gráfico de contorno de log-verosimilitud:\n\nnpar=list(m=fit$mode,v=fit$var)\nmycontour(lbinorm,c(-8,-4.5,3,16.5),npar,\n              xlab=\"logit eta\", ylab=\"log K\")\n\n\n\n\nPor lo tanto podemos sacar muestras posteriores de los parámetros transformados a través de una normal multivariada:\n\nset.seed(10)\nlibrary(mvtnorm)\nmu_sigma_post &lt;- rmvnorm(1000,mean = npar$m,sigma = npar$v)\n\ny graficamos los puntos sobre el gráfico de contorno:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\npoints(mu_sigma_post,add=T)\n\nWarning in plot.xy(xy.coords(x, y), type = type, ...): \"add\" is not a graphical\nparameter"
  },
  {
    "objectID": "computacion_bayes.html",
    "href": "computacion_bayes.html",
    "title": "4  Computación Bayesiana",
    "section": "",
    "text": "4.1 Ejemplo Capítulo 5, Albert.\nLibrerías:\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(LearnBayes)\nDatos de número de casos de cáncer de estómago en hombres en ciudades de Missouri, USA:\ndata(\"cancermortality\")\nGráfico de contorno de la logverosimilitud del modelo beta-binomial, ante la posible presencia de sobredispersión:\nmycontour(betabinexch0,c(.0001,.003,1,20000),cancermortality,\n          xlab=\"eta\",ylab=\"K\")\nen donde se evidencia una alta asimetría en ambos parámetros. Se reparametriza el modelo usando las transformaciones \\(\\theta_1=\\log\\left(\\frac{\\eta}{1-\\eta}\\right)\\), \\(\\theta_2=\\log K\\) y se obtiene la siguiente logverisimilitud transformada:\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\nAproximamos la log-densidad posterior usando el método de Laplace:\nfit &lt;- laplace(betabinexch,c(-7,6),cancermortality)\ncon el gráfico de contorno de log-verosimilitud:\nnpar=list(m=fit$mode,v=fit$var)\nmycontour(lbinorm,c(-8,-4.5,3,16.5),npar,\n              xlab=\"logit eta\", ylab=\"log K\")\nPor lo tanto podemos sacar muestras posteriores de los parámetros transformados a través de una normal multivariada:\nset.seed(10)\nlibrary(mvtnorm)\nmu_sigma_post &lt;- rmvnorm(1000,mean = npar$m,sigma = npar$v)\ny graficamos los puntos sobre el gráfico de contorno:\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\npoints(mu_sigma_post,add=T)\n\nWarning in plot.xy(xy.coords(x, y), type = type, ...): \"add\" is not a graphical\nparameter\nA partir de esta muestra es posible obtener un intervalo de credibilidad exacto para cada parámetro usando el supuesto de normalidad:\nnpar$m[1]+c(-1,1)*qnorm(0.975)*sqrt(npar$v[1,1])\n\n[1] -7.370559 -6.269027\n\nnpar$m[2]+c(-1,1)*qnorm(0.975)*sqrt(npar$v[2,2])\n\n[1] 5.300255 9.851966\ny por otro lado se puede calcular los intervalos de credibilidad directamente sobre la muestra:\nquantile(mu_sigma_post[,1],probs = c(0.025,0.975))\n\n     2.5%     97.5% \n-7.371918 -6.223499 \n\nquantile(mu_sigma_post[,2],probs = c(0.025,0.975))\n\n    2.5%    97.5% \n5.244524 9.866338",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-5.7-albert",
    "href": "computacion_bayes.html#ejemplo-sección-5.7-albert",
    "title": "4  Computación Bayesiana",
    "section": "4.2 Ejemplo sección 5.7, Albert",
    "text": "4.2 Ejemplo sección 5.7, Albert\nEn un ejemplo anterior se había calculado la distribución posterior de la proporción de estudiantes que dormían más de 8 horas (\\(p\\)). Si queremos calcular los estimadores Monte Carlo de la probabilidad de que dos estudiantes duerman más de 8 horas (\\(p^2\\)) sería:\n\np_posterior &lt;- rbeta(1000,14.26,23.19)\nhist(p_posterior)\n\n\n\n\n\n\n\nest_posterior &lt;- mean(p_posterior^2)\nest_posterior\n\n[1] 0.1507735\n\nse_posterior &lt;- sd(p_posterior^2)/sqrt(1000)\nse_posterior\n\n[1] 0.001911799\n\n\ny a partir de esto se aproxima (usando el Teorema del Límite Central) un intervalo de credibilidad para \\(p^2\\):\n\nest_posterior+c(-1,1)*qnorm(0.975)*se_posterior\n\n[1] 0.1470265 0.1545206",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#continuación-ejemplo-5-albert.",
    "href": "computacion_bayes.html#continuación-ejemplo-5-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.3 Continuación Ejemplo 5, Albert.",
    "text": "4.3 Continuación Ejemplo 5, Albert.\nEn este caso usaremos el algoritmo de rechazo como una forma de mejorar el proceso de muestreo obtenido a través del método de Laplace. Recuerden que para utilizar este algoritmo se necesita una distribución propuesta (\\(p(\\theta)\\)) que aproxime la distribución posterior sin tomar en cuenta la constante de normalización. Si asumimos una distribución t de Student multivariada como propuesta, entonces podemos encontrar una cota superior para la diferencia entre las log-densidades a través de:\n\nbetabinT=function(theta,datapar){\n  data=datapar$data\n  tpar=datapar$par\n  d=betabinexch(theta,data)-dmt(theta,mean=c(tpar$m),\n                                S=tpar$var,df=tpar$df,log=TRUE)\n  return(d)\n}\n\ntpar=list(m=fit$mode,var=2*fit$var,df=4)\ndatapar=list(data=cancermortality,par=tpar)\n\nstart=c(-6.9,12.4)\nfit1=laplace(betabinT,start,datapar)\n\nde donde se observa que un posible valor para la diferencia sería:\n\nbetabinT(fit1$mode,datapar)\n\n[1] -569.2829\n\n\ny usamos este valor para obtener una muestra posterior de los parámetros usando el algoritmo de rechazo:\n\nset.seed(10)\ntheta=rejectsampling(betabinexch,tpar,-569.2813,10000,\n                     cancermortality)\n\nNoten que la proporción de aceptación en la muestra es:\n\ndim(theta)[1]/10000\n\n[1] 0.2411\n\n\ny además podemos ver la mejora en la capacidad de la muestra posterior de estar localizada en regiones de alta probabilidad:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n          xlab=\"logit eta\",ylab=\"log K\")\npoints(theta[,1],theta[,2])",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-6.2-albert.",
    "href": "computacion_bayes.html#ejemplo-sección-6.2-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.4 Ejemplo sección 6.2, Albert.",
    "text": "4.4 Ejemplo sección 6.2, Albert.\nEn este ejemplo se ilustra una cadena discreta de Markov en donde una persona se mueve aleatoriamente en un conjunto de 6 estados solamente con un paso a la vez, y puede permanecer en el mismo estado de origen en cualquier momento. Si la probabilidad de permanecer en el mismo estado es igual a la probabilidad de avanzar o retroceder una posición, y asimismo las probabilidades de avanzar o retroceder son iguales, entonces la matriz de transición de la cadena de Markov asociada a este ejemplo es:\n\nP &lt;- matrix(c(.5,.5,0,0,0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,\n           0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,0,0,.5,.5),\n         nrow=6,ncol=6,byrow=TRUE)\nP\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,] 0.50 0.50 0.00 0.00 0.00 0.00\n[2,] 0.25 0.50 0.25 0.00 0.00 0.00\n[3,] 0.00 0.25 0.50 0.25 0.00 0.00\n[4,] 0.00 0.00 0.25 0.50 0.25 0.00\n[5,] 0.00 0.00 0.00 0.25 0.50 0.25\n[6,] 0.00 0.00 0.00 0.00 0.50 0.50\n\n\nSi asumimos que la persona empieza en el estado 3 y simulamos el proceso de Markov a lo largo de 50000 pasos:\n\ns=array(0,c(50000,1))\ns[1] &lt;- 3\nset.seed(10)\n\nfor (j in 2:50000){\n  s[j]=sample(1:6,size=1,prob=P[s[j-1],])\n}\n\nGraficamente, los últimos 1000 pasos se pueden representar:\n\nplot(tail(s,1000),type='l')\n\n\n\n\n\n\n\n\nDebido a que esta cadena de Markov es irreducible y aperiódica existe una distribución estacionaria que vamos a aproximar a través del cálculo de la frecuencia relativa en cada uno de los 6 estados:\n\nm=c(500,2000,8000,50000)\n\nfor (i in 1:4){\n  print(table(s[1:m[i]])/m[i])\n}\n\n\n    1     2     3     4     5     6 \n0.118 0.178 0.144 0.222 0.234 0.104 \n\n     1      2      3      4      5      6 \n0.0570 0.1285 0.1640 0.2315 0.2770 0.1420 \n\n       1        2        3        4        5        6 \n0.088625 0.185875 0.206125 0.209750 0.204250 0.105375 \n\n      1       2       3       4       5       6 \n0.09806 0.19734 0.19652 0.20452 0.20450 0.09906 \n\n\nlo cual parece indicar de que hay convergencia a una frecuencia relativa estable por clase. La distribución estacionaria exacta se calcula a través del vector propio asociado al valor propio igual a 1 de la matriz \\(P^T\\):\n\neig_des &lt;- eigen(t(P))\neig_des$values\n\n[1]  1.000000e+00  9.045085e-01  6.545085e-01  3.454915e-01  9.549150e-02\n[6] -3.678415e-17\n\ndist_estacionaria &lt;- eig_des$vectors[,1]\ndist_estacionaria &lt;- dist_estacionaria /sum(dist_estacionaria)\nshow(dist_estacionaria)\n\n[1] 0.1 0.2 0.2 0.2 0.2 0.1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-6.7-albert.",
    "href": "computacion_bayes.html#ejemplo-sección-6.7-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.5 Ejemplo sección 6.7, Albert.",
    "text": "4.5 Ejemplo sección 6.7, Albert.\nUsando la siguiente tabla de datos agrupados, queremos hacer inferencia de la media \\(\\mu\\) y desviación estándar \\(\\sigma\\) de la altura en pulgadas de hombres universitarios:\n\nd=list(int.lo=c(-Inf,seq(66,74,by=2)),\n         int.hi=c(seq(66,74,by=2), Inf),\n         f=c(14,30,49,70,33,15))\nshow(d)\n\n$int.lo\n[1] -Inf   66   68   70   72   74\n\n$int.hi\n[1]  66  68  70  72  74 Inf\n\n$f\n[1] 14 30 49 70 33 15\n\n\ndonde los vectores int.hi y int.lo indican los límites superiores e inferiores de los datos agrupados (en pulgadas). El vector f indica la frecuencia de individuos por intervalo. Asumiendo una distribución normal en la altura de los individuos, y tomando la transformación \\(\\lambda=\\log(\\sigma)\\), la distribución posterior se implementaría:\n\ngroupeddatapost=function(theta,data)\n{\n  dj = function(f, int.lo, int.hi, mu, sigma)\n    f * log(pnorm(int.hi, mu, sigma) -\n              pnorm(int.lo, mu, sigma))\n  mu = theta[1]\n  sigma = exp(theta[2])\n  sum(dj(data$f, data$int.lo, data$int.hi, mu, sigma))\n}\n\nPrimero aproximamos la posterior a través de una normal multivariada con el método de Laplace. Para ello simulamos observaciones por nivel en la tabla agrupada, asumiendo que las alturas son constantes por grupo:\n\ny &lt;- c(rep(65,14),rep(67,30),rep(69,49),rep(71,70),rep(73,33),\n    rep(75,15))\n\nmean(y)\n\n[1] 70.16588\n\nlog(sd(y))\n\n[1] 0.9504117\n\n\ny a partir de lo anterior tomamos como punto inicial (70,1) en el algoritmo de Laplace:\n\nstart &lt;- c(70,1)\nfit &lt;- laplace(groupeddatapost,start,d)\n\ny recuerden que se pueden generar muestras posteriores de \\((\\mu,\\lambda)\\) con este método:\n\nmu_lambda_post &lt;- rmvnorm(5000,mean = fit$m,sigma = fit$v)\n\nUsando el cálculo anterior, tomamos como propuesta en el algoritmo de Metropolis-Hastings con caminata aleatoria una normal multivariada con escala = 2 y la misma matriz de varianza-covarianza anterior:\n\nproposal &lt;- list(var=fit$var,scale=2)\nbayesfit &lt;- rwmetrop(groupeddatapost,proposal,start,10000,d)\n\nLa muestra posterior resultante tuvo una tasa de aceptación de:\n\nbayesfit$accept\n\n[1] 0.2904\n\n\nEl paquete coda nos permite graficar los traceplots de cada muestra posterior. Antes de eso, definimos un objeto mcmc de coda:\n\nlibrary(coda)\ndimnames(bayesfit$par)[[2]]=c(\"mu\",\"log sigma\")\nmcmc_ej &lt;- mcmc(bayesfit$par[-c(1:2000),]) \n\n\nlibrary(coda)\nlibrary(lattice)\nxyplot(mcmc_ej,col=\"black\")\n\n\n\n\n\n\n\n\nNote que usamos un periodo de quemado (burn-in) del 2000 muestras. También podemos incluir un gráfico de autocorrelación:\n\npar(mfrow=c(2,1))\nautocorr.plot(mcmc_ej,auto.layout=FALSE)\n\n\n\n\n\n\n\n\ny por otro lado uno puede tener un resumen de las muestras posteriores vía MCMC:\n\nsummary(mcmc_ej)\n\n\nIterations = 1:8000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 8000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean      SD  Naive SE Time-series SE\nmu        70.1678 0.19553 0.0021861       0.006537\nlog sigma  0.9799 0.05809 0.0006495       0.002016\n\n2. Quantiles for each variable:\n\n             2.5%     25%     50%    75%  97.5%\nmu        69.7960 70.0390 70.1741 70.293 70.551\nlog sigma  0.8729  0.9407  0.9784  1.019  1.095",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos.html",
    "href": "estimacion_modelos.html",
    "title": "5  Estimación de Modelos Bayesianos",
    "section": "",
    "text": "5.1 Sesgo de una moneda (Kruschke, pag 195)\nCarga de librería rjags y funciones utilitarias del Kruschke:\nlibrary(rjags)\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\nsource('DBDA2Eprograms/DBDA2E-utilities.R')\n\n\n*********************************************************************\nKruschke, J. K. (2015). Doing Bayesian Data Analysis, Second Edition:\nA Tutorial with R, JAGS, and Stan. Academic Press / Elsevier.\n*********************************************************************\nCarga de datos y definición de la estructura de datos para JAGS. Los datos se pueden entender como realizaciones de lanzamientos de una moneda (0: escudo, 1: corona; por ejemplo)\nmyData = read.csv(\"DBDA2Eprograms/z15N50.csv\") \ny = myData$y        \nNtotal = length(y)  \ndataList = list(    \n  y = y ,\n  Ntotal = Ntotal \n)\nDefinición de modelo Bernoulli(\\(\\theta\\)), con distribución previa sobre \\(\\theta\\) Beta(1,1):\nmodelString = \"\nmodel {\n  for ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\" \nwriteLines( modelString , con=\"TEMPmodel.txt\" )\nEste modelo permite contestar la pregunta de qué tan grande es el sesgo de una moneda con respecto al valor de una moneda justa (\\(\\theta=1/2\\)).\nDefinición de varios valores iniciales, usando muestreo con reemplazo para estimar un MLE de \\(\\theta\\):\ninitsList = function() {\n  resampledY = sample( y , replace=TRUE )\n  thetaInit = sum(resampledY)/length(resampledY)\n  thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n  return( list( theta=thetaInit ) )\n}\nPreprocesamiento del MCMC:\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nEjecución del MCMC:\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\nDiagnósticos:\ndiagMCMC( codaObject=codaSamples , parName=\"theta\" )\nAjuste con el paquete R2jags:\nlibrary(R2jags)\n\n\nAttaching package: 'R2jags'\n\n\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nbern_model &lt;- function() {\n  for (i in 1:N) {\n    y[i] ~ dbern(theta) \n  }\n  theta ~ dbeta(1, 1)   \n}\n\nbern_jags &lt;- \n  jags(\n    data = list(y = myData$y, N = nrow(myData)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\")\n  )\n\nmodule glm loaded\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nResumen:\nbern_jags\n\nInference for Bugs model at \"/tmp/RtmpkZR5K9/model1c4e439f5ca9d.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.308   0.063  0.192  0.263  0.305  0.349  0.441 1.001  3000\ndeviance  62.054   1.350 61.087 61.188 61.521 62.362 66.108 1.002  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 0.9 and DIC = 63.0\nDIC is an estimate of expected predictive error (lower deviance is better).\nGráficos alternativos usando el paquete bayesplot (compatible con ggplot2):\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\nPrimero transformamos el output de JAGS a coda:\nbern_mcmc &lt;- as.mcmc(bern_jags)\nplot(bern_mcmc)\nGráfico de la distribución posterior:\nmcmc_areas(\n  bern_mcmc,            \n  pars = c(\"theta\"),     \n  prob = 0.90)\nTraceplots combinados:\nmcmc_trace(bern_mcmc, pars = \"theta\")\nTraceplots separados:\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks runjags::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nmcmc_trace(bern_mcmc, pars = \"theta\") %&gt;%\n  gf_facet_grid(chain ~ .) %&gt;%\n  gf_refine(scale_color_viridis_d())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) )\n\n\n\n\n\n\n\n\n           ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 9685.291 0.3080807 0.305302 0.2872137    0.95 0.1889107 0.4364605      NA\n      pGtCompVal ROPElow ROPEhigh pLtROPE pInROPE pGtROPE\ntheta         NA      NA       NA      NA      NA      NA\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) , \n          cenTend=\"median\" , compVal=0.5 , ROPE=c(0.45,0.55) , credMass=0.90 )\n\n\n\n\n\n\n\n\n           ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 9685.291 0.3080807 0.305302 0.2872137     0.9 0.2012697 0.4121144     0.5\n      pGtCompVal ROPElow ROPEhigh   pLtROPE   pInROPE pGtROPE\ntheta 0.00229954    0.45     0.55 0.9830034 0.0169966       0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos.html#ejemplo-2",
    "href": "estimacion_modelos.html#ejemplo-2",
    "title": "5  Estimación de Modelos Bayesianos",
    "section": "5.2 Ejemplo 2",
    "text": "5.2 Ejemplo 2\n\nmyData = read.csv(\"DBDA2Eprograms/z6N8z2N7.csv\")\ny = myData$y\ns = as.numeric(factor(myData$s)) # converts character to consecutive integer levels\n\n\nNtotal = length(y)\nNsubj = length(unique(s))\ndataList = list(\ny = y ,\ns = s ,\nNtotal = Ntotal ,\nNsubj = Nsubj\n)\n\n\nmodelString = \"\n  model {\n    for ( i in 1:Ntotal ) {\n      y[i] ~ dbern( theta[s[i]] )\n    }\n    for ( sIdx in 1:Nsubj ) {\n      theta[sIdx] ~ dbeta( 2 , 2 ) # N.B.: 2,2 prior; change as appropriate.\n    }\n  }\n  \"\nwriteLines( modelString , con=\"TEMPmodel.txt\" )\n\n\ninitsList = function() {\n    thetaInit = rep(0,Nsubj)\n    for ( sIdx in 1:Nsubj ) { # for each subject\n      includeRows = ( s == sIdx ) # identify rows of this subject\n      yThisSubj = y[includeRows]  # extract data of this subject\n      resampledY = sample( yThisSubj , replace=TRUE ) # resample\n      thetaInit[sIdx] = sum(resampledY)/length(resampledY) \n    }\n    thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n    return( list( theta=thetaInit ) )\n  }\n\n\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\n\n\ndiagMCMC( codaObject=codaSamples )\n\n\n\n\n\n\n\n\nJags-Ydich-XnomSsubj-MbernBeta-Example.R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#evaluación-práctica-4",
    "href": "computacion_bayes.html#evaluación-práctica-4",
    "title": "4  Computación Bayesiana",
    "section": "4.6 Evaluación Práctica 4",
    "text": "4.6 Evaluación Práctica 4\nLa siguiente es la implementación de una función que calcule la verosimilitud de este ejemplo:\n\nlogPoisson &lt;- function(betas,data){\n  beta0 &lt;- betas[1]\n  beta1 &lt;- betas[2]\n  month &lt;- data[,1]\n  y &lt;- data[,2]\n  vector_logvero &lt;- y*(beta0+beta1*month)-exp(beta0+beta1*month)\n  logvero &lt;- sum(vector_logvero)\n}\n\nen donde asumimos que los datos son:\n\ndataPoisson &lt;- data.frame(month = 1:18,yi = c(15,11,14,17,5,11,10,4,8,10,7,9,11,3,6,1,1,4))\n\nPara verificar, hacemos un gráfico de contorno de la logverosimilitud:\n\nmycontour(logPoisson,c(2,3.5,-0.18,0),dataPoisson,\n          xlab=\"Beta0\",ylab=\"Beta1\")\n\n\n\n\n\n\n\n\nAjustamos el método de Laplace usando como valor inicial el punto (2.6,-0.1):\n\nfit_laplace &lt;- laplace(logPoisson ,c(2.6,-0.1),dataPoisson)\nfit_laplace$mode\n\n[1]  2.80291445 -0.08373524\n\nfit_laplace$var\n\n             [,1]         [,2]\n[1,]  0.021953402 -0.002067647\n[2,] -0.002067647  0.000282176\n\n\nCon lo anterior podemos estimar la media de \\(\\beta_1\\) como:\n\nmean_laplace &lt;- fit_laplace$mode[2]\nshow(mean_laplace)\n\n[1] -0.08373524\n\n\ny su desviación estándar como:\n\nsd_laplace &lt;- sqrt(fit_laplace$var[2,2])\nshow(sd_laplace)\n\n[1] 0.0167981\n\n\nNota: También se vale hacerlo con simulación. Si no lo hicieron de esa forma, lo pueden intentar.\n\nstart &lt;- fit_laplace$mode\nproposal_poisson &lt;- list(var=fit_laplace$var,scale=2)\nbayesfit_poisson &lt;- rwmetrop(logPoisson,proposal_poisson,start,1000,dataPoisson)\n\nY con esto calculamos la media y desviación posterior usando nuestras muestras MCMC (usamos un burn-in de un 10% de la muestra):\n\nmean_mcmc &lt;- mean(bayesfit_poisson$par[100:1000,2])\nsd_mcmc &lt;- sd(bayesfit_poisson$par[100:1000,2])\n\nTraceplot de la muestra completa:\n\nplot(bayesfit_poisson$par[,2],type='l')\n\n\n\n\n\n\n\n\nLes recomiendo hacer más diagnósticos a las muestras de \\(\\beta_0\\) y \\(\\beta_1\\).\nTabla de resultados basada en la Tabla 6.2 del Albert:\n\nID_laplace &lt;- mean_laplace+c(-1,1)*qnorm(0.975)*sd_laplace\nID_mcmc &lt;- quantile(bayesfit_poisson$par[100:1000,2],probs = c(0.025,0.975))\nlaplace_row &lt;- c(NA,c(ID_laplace[1],mean_laplace,ID_laplace[2]))\nmcmc_row &lt;- c(bayesfit_poisson$accept,c(ID_mcmc[1],mean_mcmc,ID_mcmc[2]))\ntabla_res &lt;- data.frame(rbind(laplace_row,mcmc_row))\ncolnames(tabla_res) &lt;- c('Aceptacion','beta1_low','beta1_est','beta1_up')\nrownames(tabla_res) &lt;- c('Laplace','MH-Random Walk')\n\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nkable(tabla_res)\n\n\n\n\n\nAceptacion\nbeta1_low\nbeta1_est\nbeta1_up\n\n\n\n\nLaplace\nNA\n-0.1166589\n-0.0837352\n-0.0508116\n\n\nMH-Random Walk\n0.281\n-0.1211206\n-0.0848761\n-0.0548695",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html",
    "href": "estimacion_modelos1.html",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "",
    "text": "5.1 Sesgo de una moneda (Kruschke, pag 195)\nCarga de librería rjags y funciones utilitarias del Kruschke:\nlibrary(rjags)\nsource('DBDA2Eprograms/DBDA2E-utilities.R')\n\n\n*********************************************************************\nKruschke, J. K. (2015). Doing Bayesian Data Analysis, Second Edition:\nA Tutorial with R, JAGS, and Stan. Academic Press / Elsevier.\n*********************************************************************\nCarga de datos y definición de la estructura de datos para JAGS. Los datos se pueden entender como realizaciones de lanzamientos de una moneda (0: escudo, 1: corona; por ejemplo)\nmyData = read.csv(\"DBDA2Eprograms/z15N50.csv\") \ny = myData$y        \nNtotal = length(y)  \ndataList = list(    \n  y = y ,\n  Ntotal = Ntotal \n)\nDefinición de modelo Bernoulli(\\(\\theta\\)), con distribución previa sobre \\(\\theta\\) Beta(1,1):\nmodelString = \"\nmodel {\n  for ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\" \nwriteLines( modelString , con=\"TEMPmodel.txt\" )\nEste modelo permite contestar la pregunta de qué tan grande es el sesgo de una moneda con respecto al valor de una moneda justa (\\(\\theta=1/2\\)).\nDefinición de varios valores iniciales, usando muestreo con reemplazo para estimar un MLE de \\(\\theta\\):\ninitsList = function() {\n  resampledY = sample( y , replace=TRUE )\n  thetaInit = sum(resampledY)/length(resampledY)\n  thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n  return( list( theta=thetaInit ) )\n}\nPreprocesamiento del MCMC:\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nEjecución del MCMC:\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\nDiagnósticos:\ndiagMCMC( codaObject=codaSamples , parName=\"theta\" )\nAjuste con el paquete R2jags:\nlibrary(R2jags)\n\nbern_model &lt;- function() {\n  for (i in 1:N) {\n    y[i] ~ dbern(theta) \n  }\n  theta ~ dbeta(1, 1)   \n}\n\nbern_jags &lt;- \n  jags(\n    data = list(y = myData$y, N = nrow(myData)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\")\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nResumen:\nbern_jags\n\nInference for Bugs model at \"/tmp/RtmptFdHKr/model651267e6394d.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.308   0.064  0.193  0.262  0.306  0.350  0.440 1.001  3000\ndeviance  62.076   1.430 61.087 61.194 61.546 62.372 66.074 1.001  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 1.0 and DIC = 63.1\nDIC is an estimate of expected predictive error (lower deviance is better).\nGráficos alternativos usando el paquete bayesplot (compatible con ggplot2):\nlibrary(bayesplot)\nPrimero transformamos el output de JAGS a coda:\nbern_mcmc &lt;- as.mcmc(bern_jags)\nplot(bern_mcmc)\nGráfico de la distribución posterior:\nmcmc_areas(\n  bern_mcmc,            \n  pars = c(\"theta\"),     \n  prob = 0.90)\nTraceplots combinados:\nmcmc_trace(bern_mcmc, pars = \"theta\")\nTraceplots separados:\nlibrary(tidyverse)\nlibrary(ggformula)\n\nmcmc_trace(bern_mcmc, pars = \"theta\") %&gt;%\n  gf_facet_grid(chain ~ .) %&gt;%\n  gf_refine(scale_color_viridis_d())\nGráficos incluidos en los archivos del libro:\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) )\n\n\n\n\n\n\n\n\n        ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 10002 0.3077605 0.305555 0.3018493    0.95 0.1866602 0.4311935      NA\n      pGtCompVal ROPElow ROPEhigh pLtROPE pInROPE pGtROPE\ntheta         NA      NA       NA      NA      NA      NA\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) , \n          cenTend=\"median\" , compVal=0.5 , ROPE=c(0.45,0.55) , credMass=0.90 )\n\n\n\n\n\n\n\n\n        ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 10002 0.3077605 0.305555 0.3018493     0.9 0.2014597 0.4103378     0.5\n      pGtCompVal ROPElow ROPEhigh   pLtROPE    pInROPE pGtROPE\ntheta 0.00229954    0.45     0.55 0.9836033 0.01639672       0\no bien se puede usar el paquete de github CalvinBayes (https://github.com/CalvinData/CalvinBayes) para hacer los mismos gráficos con el objeto obtenido en R2jags:\nlibrary(CalvinBayes)\n\ndiag_mcmc(bern_mcmc, par = \"theta\")\nplot_post(bern_mcmc[, \"theta\"], main = \"theta\", xlab = expression(theta),\n         cenTend = \"median\", compVal = 0.5, ROPE = c(0.45, 0.55), \n         credMass = 0.90, quietly = TRUE)\nOtra corrida de jags con distintos argumentos:\nset.seed(76543)\nbern_jags2 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    n.chains = 4, n.iter = 5000, n.burnin = 1000,n.thin = 1)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\n\nbern_jags2\n\nInference for Bugs model at \"/tmp/RtmptFdHKr/model6512152e0c66.txt\", fit using jags,\n 4 chains, each with 5000 iterations (first 1000 discarded)\n n.sims = 16000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.307   0.063  0.192  0.263  0.305  0.349  0.438 1.001 14000\ndeviance  62.055   1.388 61.088 61.186 61.527 62.355 66.079 1.002  3400\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 1.0 and DIC = 63.0\nDIC is an estimate of expected predictive error (lower deviance is better).\nY podemos correr también modelos con distintos valores iniciales:\nset.seed(2345)\nbern_jags3 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    # start each chain by sampling from the prior\n    inits = function() list(theta = rbeta(1, 3, 3))    \n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\n\nbern_jags4 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    # choose specific starting point for each chain\n    inits = list(\n      list(theta = 0.5), list(theta = 0.7), list(theta = 0.9)\n    )\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nmcmc_trace(as.mcmc(bern_jags4), pars = \"theta\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-2",
    "href": "estimacion_modelos1.html#ejemplo-2",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.2 Ejemplo 2",
    "text": "5.2 Ejemplo 2\nDos individuos (Reginald y Tony) tiran cada uno una moneda. Se tiene los resultados de los tiros de cada moneda:\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nhead(z6N8z2N7)  \n\n# A tibble: 6 × 2\n      y s       \n  &lt;dbl&gt; &lt;chr&gt;   \n1     1 Reginald\n2     0 Reginald\n3     1 Reginald\n4     1 Reginald\n5     1 Reginald\n6     1 Reginald\n\n\n\nTarget &lt;- z6N8z2N7 %&gt;%\n  rename(hit = y, subject = s)\ndf_stats(hit ~ subject, data = Target, props, attempts = length)\n\n  response  subject    prop_0    prop_1 attempts\n1      hit Reginald 0.2500000 0.7500000        8\n2      hit     Tony 0.7142857 0.2857143        7\n\n\nModelo:\n\nbern2_model &lt;- function() {\n  for (i in 1:Nobs) {\n    hit[i] ~ dbern(theta[subject[i]])  \n  }\n  for (s in 1:Nsub) {\n    theta[s] ~ dbeta(2, 2)   \n  }\n}\n\nDatos:\n\nTargetList &lt;-\n  list(\n    Nobs = nrow(Target),\n    Nsub = 2,\n    hit = Target$hit,\n    subject = as.numeric(as.factor(Target$subject))\n)\nTargetList\n\n$Nobs\n[1] 15\n\n$Nsub\n[1] 2\n\n$hit\n [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n\n$subject\n [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n\n\nAjuste:\n\nbern2_jags &lt;- \n  jags(\n    data = TargetList,\n    model = bern2_model,\n    parameters.to.save = \"theta\")\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\n\nDiagnósticos:\n\nbern2_mcmc &lt;- as.mcmc(bern2_jags)\ndiag_mcmc(bern2_mcmc,parName = 'theta[1]')\n\n\n\n\n\n\n\n\n\nmcmc_acf(bern2_mcmc)\n\n\n\n\n\n\n\n\n\nmcmc_pairs(bern2_mcmc, pars = c(\"theta[1]\", \"theta[2]\"))\n\n\n\n\n\n\n\n\n\nmcmc_combo(bern2_mcmc)\n\n\n\n\n\n\n\n\nEstamos interesados en analizar la diferencia entre \\(\\theta_1\\) (Reginald) y \\(\\theta_2\\) (Tony):\n\nhead(posterior(bern2_jags))\n\n  deviance   theta.1   theta.2   chain iter\n1 17.40840 0.7775109 0.2917246 chain:1    1\n2 18.81437 0.8021381 0.4986514 chain:1    2\n3 17.72482 0.6563450 0.2599003 chain:1    3\n4 17.78892 0.6546149 0.3343049 chain:1    4\n5 17.50901 0.7569896 0.3506096 chain:1    5\n6 17.72967 0.6733703 0.3503326 chain:1    6\n\npost2 &lt;- posterior(bern2_jags) %&gt;% mutate(dif = theta.1-theta.2)\nmean(post2$dif)\n\n[1] 0.2996498\n\nquantile(post2$dif,c(0.025,0.975))\n\n       2.5%       97.5% \n-0.09420704  0.66259903 \n\n\n\ngf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerarquica",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerarquica",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerarquica",
    "text": "5.3 Ejemplo de Modelación Jerarquica\nhttps://jamanetwork.com/journals/jama/fullarticle/187390",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#sesgos-de-dos-monedas",
    "href": "estimacion_modelos1.html#sesgos-de-dos-monedas",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.2 Sesgos de dos monedas",
    "text": "5.2 Sesgos de dos monedas\nDos individuos (Reginald y Tony) tiran cada uno una moneda. Se tiene los resultados de los intentos de cada individuo:\n\nlibrary(mosaic)\nhead(z6N8z2N7)  \n\n# A tibble: 6 × 2\n      y s       \n  &lt;dbl&gt; &lt;chr&gt;   \n1     1 Reginald\n2     0 Reginald\n3     1 Reginald\n4     1 Reginald\n5     1 Reginald\n6     1 Reginald\n\n\nCambiamos los nombres de las variables. Además, noten que las proporciones de 0s y 1s obtenidas por cada individuo son muy distintas entre sí, por lo tanto en el modelo sería conveniente usar una probabilidad de ocurrencia de 1s distinta por individuo.\n\nTarget &lt;- z6N8z2N7 %&gt;%\n  rename(hit = y, subject = s)\ndf_stats(hit ~ subject, data = Target, props, attempts = length)\n\n  response  subject    prop_0    prop_1 attempts\n1      hit Reginald 0.2500000 0.7500000        8\n2      hit     Tony 0.7142857 0.2857143        7\n\n\nEl modelo en este caso considera la observación anterior:\n\nbern2_model &lt;- function() {\n  for (i in 1:Nobs) {\n    hit[i] ~ dbern(theta[subject[i]])  \n  }\n  for (s in 1:Nsub) {\n    theta[s] ~ dbeta(2, 2)   \n  }\n}\n\nLos datos deben declararse en la siguiente lista:\n\nTargetList &lt;-\n  list(\n    Nobs = nrow(Target),\n    Nsub = 2,\n    hit = Target$hit,\n    subject = as.numeric(as.factor(Target$subject))\n)\nTargetList\n\n$Nobs\n[1] 15\n\n$Nsub\n[1] 2\n\n$hit\n [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n\n$subject\n [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n\n\nY realizamos el ajuste MCMC:\n\nbern2_jags &lt;- \n  jags(\n    data = TargetList,\n    model = bern2_model,\n    parameters.to.save = \"theta\")\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\n\nDiagnósticos para \\(\\theta_1\\). (Hacer los diagnósticos de \\(\\theta_2\\) como ejercicio)\n\nbern2_mcmc &lt;- as.mcmc(bern2_jags)\ndiag_mcmc(bern2_mcmc,parName = 'theta[1]')\n\n\n\n\n\n\n\n\n\nmcmc_acf(bern2_mcmc)\n\n\n\n\n\n\n\n\n\nmcmc_pairs(bern2_mcmc, pars = c(\"theta[1]\", \"theta[2]\"))\n\n\n\n\n\n\n\n\n\nmcmc_combo(bern2_mcmc)\n\n\n\n\n\n\n\n\nEstamos interesados en analizar la diferencia entre \\(\\theta_1\\) (Reginald) y \\(\\theta_2\\) (Tony), en particular a través de la diferencia \\(\\theta_1-\\theta_2\\). Note que a través de esta diferencia, es posible medir la hipótesis nula \\(H_0: \\theta_1&gt; \\theta_2\\):\n\nhead(posterior(bern2_jags))\n\n  deviance   theta.1   theta.2   chain iter\n1 17.40840 0.7775109 0.2917246 chain:1    1\n2 18.81437 0.8021381 0.4986514 chain:1    2\n3 17.72482 0.6563450 0.2599003 chain:1    3\n4 17.78892 0.6546149 0.3343049 chain:1    4\n5 17.50901 0.7569896 0.3506096 chain:1    5\n6 17.72967 0.6733703 0.3503326 chain:1    6\n\npost2 &lt;- posterior(bern2_jags) %&gt;% mutate(dif = theta.1-theta.2)\nmean(post2$dif)\n\n[1] 0.2996498\n\nquantile(post2$dif,c(0.025,0.975))\n\n       2.5%       97.5% \n-0.09420704  0.66259903 \n\n\n\ngf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags))\n\n\n\n\n\n\n\n\nPara medir \\(H_0\\), estimamos la probabilidad posterior de \\(H_0\\):\n\nsum(post2$dif&gt;0)/3000  \n\n[1] 0.9323333\n\n\nPor lo tanto la probabilidad de que \\(H_0\\) sea cierta es 0.9323 y la probabilidad de rechazar tal hipótesis (o bien aceptar \\(H_1: \\theta_1&lt;\\theta_2\\)) es 6.77%.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerárquica",
    "text": "5.3 Ejemplo de Modelación Jerárquica\nhttps://jamanetwork.com/journals/jama/fullarticle/187390",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica-sección-9.2.4-kruschke",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica-sección-9.2.4-kruschke",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerárquica (sección 9.2.4, Kruschke)",
    "text": "5.3 Ejemplo de Modelación Jerárquica (sección 9.2.4, Kruschke)\nContexto: El Toque Terapéutico (TT) es una práctica de enfermería que se dice trata condiciones médicas manipulando un “campo de energía humano” con las manos de los practicantes. Este estudio tuvo como objetivo probar si los practicantes de TT pueden percibir este campo de energía. Veintiún practicantes con 1 a 27 años de experiencia en TT fueron evaluados en condiciones cegadas. Se les pidió que identificaran cuál de sus manos estaba más cerca de la mano del investigador, que se colocaba al azar mediante el lanzamiento de una moneda. Catorce practicantes fueron evaluados 10 veces cada uno, y siete fueron evaluados 20 veces cada uno. La capacidad de los practicantes para identificar correctamente la posición de la mano del investigador se comparó con una tasa de éxito del 50% esperada por casualidad.\nPregunta de Investigación: ¿Las tasas de acierto para los practicantes será mayor al 50%?\nCarga de datos:\n\nhead(TherapeuticTouch, 3)\n\n# A tibble: 3 × 2\n      y s    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 S01  \n2     0 S01  \n3     0 S01  \n\n\nLas tasas de acierto empíricas para cada individuo se pueden visualizar de la siguiente forma:\n\ngf_bar(s ~ ., data = TherapeuticTouch, fill = ~ factor(y))\n\n\n\n\n\n\n\n\nde donde es interesante observar la diferencia entre tasas de acierto entre individuos (que en este caso está ordenado del que tiene menos al que tiene más acierto). Es por esto que un modelo con tasa de acierto variable por individuos tendría sentido.\nRecuerden que el modelo jerárquico tendría la forma:\n\\[\\begin{align*}\ny_{i|s} & \\sim \\text{Ber}(\\theta_s)\\\\\n\\theta_s & \\sim \\text{Beta}(\\omega(K-2)+1,(1-\\omega)(K-2)+1)\\\\\n\\omega & \\sim \\text{Beta}(1,1)\\\\\nK-2 & \\sim \\text{Gamma}(0.01,0.01)\n\\end{align*}\\]\ndonde esta última escogencia se hiperparámetros se basa en la aplicación de la siguiente función:\n\ngamma_params(mean = 1, sd = 10)\n\n# A tibble: 1 × 6\n  shape  rate scale mode   mean    sd\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.01  0.01   100 NA        1    10\n\n\nque garantiza una v.a. Gamma con media 1 y desviación estándar 10 (previas no-informativas).\nLa definición del modelo en lenguaje JAGS sería:\n\ntouch_model &lt;- function() {\n  for (i in 1:Ntotal) {\n    y[i] ~ dbern(theta[s[i]])\n  }\n  for (s in 1:Nsubj) {\n    theta[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1)\n  }\n  omega ~ dbeta(1, 1)\n  kappa &lt;- kappaMinusTwo + 2\n  kappaMinusTwo ~ dgamma(0.01, 0.01)     # mean = 1, sd = 10\n}\n\ncon el arreglo de datos:\n\nTouchData &lt;- list(\n  Ntotal = nrow(TherapeuticTouch),\n  Nsubj = length(unique(TherapeuticTouch$s)),\n  y = TherapeuticTouch$y,\n  # must convert subjects to sequence 1:Nsubj\n  s = as.numeric(factor(TherapeuticTouch$s))\n)\n\nSe procede a un ajuste preliminar, con los valores por default de JAGS:\n\nset.seed(1234)\ntouch_jags &lt;-\n  jags(\n    data = TouchData,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 280\n   Unobserved stochastic nodes: 30\n   Total graph size: 602\n\nInitializing model\n\n\nSi analizamos los diagnósticos de convergencia, notamos que hay mucho autocorrelación en la series (usando el tamaño efectivo de muestra):\n\ntouch_jags\n\nInference for Bugs model at \"/tmp/RtmptFdHKr/model651224f9fd64.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\nkappa      52.286  54.028   8.932  20.025  34.399  65.489 210.966 1.056    44\nomega       0.439   0.035   0.367   0.416   0.439   0.462   0.508 1.004  1100\ntheta[1]    0.363   0.088   0.175   0.305   0.369   0.426   0.517 1.016   210\ntheta[2]    0.384   0.084   0.208   0.331   0.389   0.444   0.536 1.015   190\ntheta[3]    0.409   0.081   0.241   0.358   0.414   0.463   0.564 1.005   970\ntheta[4]    0.411   0.083   0.236   0.357   0.415   0.467   0.564 1.020   270\ntheta[5]    0.409   0.080   0.244   0.358   0.411   0.461   0.563 1.010   500\ntheta[6]    0.410   0.082   0.235   0.359   0.414   0.464   0.562 1.006  1100\ntheta[7]    0.409   0.080   0.244   0.359   0.412   0.461   0.560 1.019   180\ntheta[8]    0.410   0.080   0.243   0.360   0.413   0.462   0.565 1.012   510\ntheta[9]    0.407   0.080   0.247   0.356   0.410   0.459   0.561 1.008   650\ntheta[10]   0.409   0.081   0.238   0.358   0.413   0.463   0.559 1.008   710\ntheta[11]   0.433   0.077   0.276   0.384   0.433   0.483   0.588 1.004  1700\ntheta[12]   0.433   0.081   0.278   0.383   0.434   0.485   0.593 1.005   710\ntheta[13]   0.434   0.078   0.280   0.385   0.434   0.484   0.587 1.002  3000\ntheta[14]   0.432   0.080   0.272   0.380   0.432   0.482   0.593 1.001  3000\ntheta[15]   0.433   0.080   0.275   0.381   0.434   0.484   0.590 1.004  3000\ntheta[16]   0.457   0.080   0.300   0.408   0.454   0.504   0.624 1.002  3000\ntheta[17]   0.456   0.079   0.295   0.406   0.453   0.506   0.621 1.002  1600\ntheta[18]   0.454   0.081   0.295   0.401   0.453   0.504   0.626 1.003  3000\ntheta[19]   0.457   0.078   0.313   0.407   0.454   0.505   0.618 1.001  3000\ntheta[20]   0.455   0.080   0.298   0.403   0.452   0.508   0.612 1.003  3000\ntheta[21]   0.457   0.082   0.296   0.404   0.455   0.510   0.621 1.005  1000\ntheta[22]   0.457   0.079   0.311   0.405   0.454   0.507   0.625 1.003  1800\ntheta[23]   0.480   0.083   0.328   0.425   0.474   0.529   0.658 1.008   510\ntheta[24]   0.482   0.083   0.327   0.427   0.476   0.531   0.660 1.003  1300\ntheta[25]   0.506   0.088   0.351   0.446   0.497   0.562   0.691 1.008   260\ntheta[26]   0.507   0.088   0.354   0.446   0.498   0.560   0.700 1.003   680\ntheta[27]   0.505   0.087   0.355   0.445   0.495   0.559   0.695 1.008   250\ntheta[28]   0.527   0.093   0.374   0.460   0.517   0.581   0.735 1.008   300\ndeviance  378.963   5.156 368.591 375.437 379.284 382.411 388.755 1.010   220\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 13.2 and DIC = 392.1\nDIC is an estimate of expected predictive error (lower deviance is better).\n\n\nAjustamos el modelo con un número de mayor de cadenas, con mayor tamaño de muestra posterior y con thinning. Noten que ejecutamos el modelo paralelizando el proceso (1 core por cadena)\n\ntouch_jags &lt;-\n  jags.parallel(\n    data = TouchData,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n    n.burnin = 1000,\n    n.iter = 41000,\n    n.chains = 5,\n    n.thin = 10,\n    jags.seed = 54321\n  )   \n\ny la autorrelación se mejora considerablemente, al comparar el tamaño de muestra efectivo del primer modelo con respecto al segundo:\n\ntouch_jags$BUGSoutput$summary[,'n.eff']\n\n deviance     kappa     omega  theta[1]  theta[2]  theta[3]  theta[4]  theta[5] \n    20000      5800     14000     14000     19000     20000      6500     20000 \n theta[6]  theta[7]  theta[8]  theta[9] theta[10] theta[11] theta[12] theta[13] \n    20000     19000     20000     20000     20000     20000     19000     20000 \ntheta[14] theta[15] theta[16] theta[17] theta[18] theta[19] theta[20] theta[21] \n     8300     13000     20000     16000      8700     20000     20000     20000 \ntheta[22] theta[23] theta[24] theta[25] theta[26] theta[27] theta[28] \n    15000     20000     10000     10000     20000     20000     20000 \n\n\nAhora hacemos algunos gráficos para analizar las muestras posteriores:\n\ntouch_mcmc &lt;- as.mcmc(touch_jags)\nplot_post(touch_mcmc[, \"omega\"], comparison_value = 0.5)\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 13197.07 0.4351743 0.4355163 0.4375461\n\n$hdi\n  prob        lo        hi\n1 0.95 0.3597935 0.5071227\n\n$comparison\n  value P(&lt; comp. val.) P(&gt; comp. val.)\n1   0.5          0.9596          0.0404\n\n\nDe donde se concluye que el 96% de la población de practicantes no tienen una tasa de acierto general mayor al 50%. Este análisis se puede realizar para la tasa de acierto del sujeto #28:\n\nplot_post(touch_mcmc[, \"theta[28]\"], comparison_value = 0.5)\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 12746.09 0.5248268 0.5141253 0.4994144\n\n$hdi\n  prob        lo       hi\n1 0.95 0.3582065 0.717917\n\n$comparison\n  value P(&lt; comp. val.) P(&gt; comp. val.)\n1   0.5         0.43435         0.56565\n\n\nDiagnósticos del parámetro de precisión de la tasa de acierto individual:\n\ndiag_mcmc(touch_mcmc, par = \"kappa\")\n\n\n\n\n\n\n\n\nGráfico de dispersión entre las muestras posteriores de \\(K\\) y \\(\\omega\\):\n\nmcmc_pairs(touch_mcmc, pars = c(\"omega\", \"kappa\"))\n\n\n\n\n\n\n\n\nMuestreo a partir de la previa:\n\nTouchData_pre &lt;- list(\n  Ntotal = 0,\n  Nsubj = length(unique(TherapeuticTouch$s)),\n  # must convert subjects to sequence 1:Nsubj\n  s = as.numeric(factor(TherapeuticTouch$s))\n)\n\ntouch_jags_pre &lt;-\n  jags.parallel(\n    data = TouchData_pre,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n    n.burnin = 1000,\n    n.iter = 41000,\n    n.chains = 5,\n    n.thin = 10,\n    jags.seed = 54321,\n    DIC = F\n  )\n\nDiagnósticos:\n\ndiag_mcmc(touch_mcmc, par = \"theta[1]\")\nmcmc_pairs(touch_mcmc, pars = c(\"omega\", \"kappa\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#introducción-a-stan",
    "href": "estimacion_modelos1.html#introducción-a-stan",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.4 Introducción a STAN",
    "text": "5.4 Introducción a STAN\nCarga de librería:\n\nlibrary(rstan)\nrstan_options(auto_write = TRUE)\n\nPara ilustrar el uso de STAN, se va a ajustar un modelo Bernoulli a datos sintéticos. El modelo está definido en el archivo moneda.stan en el repositorio de estas notas.\n\nmodelo_moneda &lt;- stan_model(file = 'moneda.stan',verbose = T)\n\n\nTRANSLATING MODEL '' FROM Stan CODE TO C++ CODE NOW.\n\nmodelo_moneda\n\nS4 class stanmodel 'anon_model' coded as follows:\n//\n// This Stan program defines a simple model, with a\n// vector of values 'y' modeled as normally distributed\n// with mean 'mu' and standard deviation 'sigma'.\n//\n// Learn more about model development with Stan at:\n//\n//    http://mc-stan.org/users/interfaces/rstan.html\n//    https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started\n//\n// The input data is a vector 'y' of length 'N'.\ndata {\n  int&lt;lower=0&gt; N;  // N is a non-negative integer\n  int y[N];          // y is a length-N vector of integers\n}\n// The parameters accepted by the model. Our model\n// accepts two parameters 'mu' and 'sigma'.\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta is between 0 and 1\n}\n// The model to be estimated. We model the output\n// 'y' to be normally distributed with mean 'mu'\n// and standard deviation 'sigma'.\nmodel {\n  theta ~ beta (1,1);\n  y ~ bernoulli(theta);\n} \n\n\nAjuste del modelo en condiciones similares a las que JAGS trabaja por default:\n\nsimple_stanfit &lt;- \n  sampling(\n    modelo_moneda, \n    data  = list(\n      N = 50,\n      y = c(rep(1, 15), rep(0, 35))\n    ),\n    chains = 3,     # default is 4\n    iter = 1000,    # default is 2000\n    warmup = 200    # default is half of iter\n  )\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.1 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 1: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 1: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 1: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 1: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.001 seconds (Warm-up)\nChain 1:                0.004 seconds (Sampling)\nChain 1:                0.005 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 2e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.02 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 2: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 2: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 2: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 2: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.001 seconds (Warm-up)\nChain 2:                0.004 seconds (Sampling)\nChain 2:                0.005 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 3: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 3: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 3: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 3: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.001 seconds (Warm-up)\nChain 3:                0.004 seconds (Sampling)\nChain 3:                0.005 seconds (Total)\nChain 3: \n\n\n\nsimple_stanfit\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=200; thin=1; \npost-warmup draws per chain=800, total post-warmup draws=2400.\n\n        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\ntheta   0.31    0.00 0.07   0.19   0.26   0.31   0.35   0.44   742    1\nlp__  -32.64    0.03 0.80 -34.90 -32.79 -32.34 -32.16 -32.10   949    1\n\nSamples were drawn using NUTS(diag_e) at Mon Jun 17 22:22:04 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nAlgunos diagnósticos:\n\ngf_dens(~theta, data = posterior(simple_stanfit))\n\n\n\n\n\n\n\nsimple_mcmc &lt;- as.matrix(simple_stanfit)\nmcmc_areas(as.mcmc.list(simple_stanfit), prob = 0.9, pars = \"theta\")\n\n\n\n\n\n\n\ndiag_mcmc(as.mcmc.list(simple_stanfit))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos2.html",
    "href": "estimacion_modelos2.html",
    "title": "6  Estimación de Modelos Bayesianos (Parte 2)",
    "section": "",
    "text": "6.1 Comparación de medias\nCushny, A. R. and Peebles, A. R. (1905) “The action of optical isomers: II hyoscines.” The Journal of Physiology 32, 501–510.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 2)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos2.html#comparación-de-medias",
    "href": "estimacion_modelos2.html#comparación-de-medias",
    "title": "6  Estimación de Modelos Bayesianos (Parte 2)",
    "section": "",
    "text": "6.1.1 Datos\nVamos a ver los datos. (extra = sueño adicional con el medicamento; group debería ser realmente drug, así que vamos a renombrarlo.)\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nlibrary(dplyr)\nsleep &lt;- \n  datasets::sleep %&gt;% rename(drug = group)\ngf_boxplot(extra ~ drug, data = sleep)\n\n\n\n\n\n\n\n df_stats(extra ~ drug, data = sleep)\n\n  response drug  min     Q1 median   Q3 max mean       sd  n missing\n1    extra    1 -1.6 -0.175   0.35 1.70 3.7 0.75 1.789010 10       0\n2    extra    2 -0.1  0.875   1.75 4.15 5.5 2.33 2.002249 10       0\n\n\nProblema de estudio: Se compararon los hábitos de sueño de los sujetos sin un medicamento para inducir el sueño y luego con él para ver cómo dos medicamentos diferentes afectaban de manera significativa el sueño.\n\n\n6.1.2 Modelo\nEl punto de partida tradicional para modelar las medias es asumir que cada grupo se muestrea de una distribución normal con media desconocida y una desviación estándar común. (Veremos que no es más difícil tener desviaciones estándar diferentes).\nEntonces, para dos grupos, nuestro modelo tiene tres parámetros: dos medias ((_1) y (_2)) y una desviación estándar ().\nPor supuesto, también necesitamos previas para estos parámetros. Una previa común para las medias es una distribución normal. Comenzaremos con un previa uniforme para la desviación estándar, pero discutiremos mejores alternativas en breve.\nEsto nos da el siguiente esquema para nuestro modelo:\n[ \\[\\begin{align*}\nY_{i|g} & \\sim \\text{Norm}(\\mu_g, \\sigma) \\\\\n\\mu_g & \\sim \\text{Norm}(?, ?) \\\\\n\\sigma & \\sim \\text{Unif}(?, ?)\n\\end{align*}\\] ]\nLos signos de interrogación se llenarán en función de consideraciones de la escala (orden de magnitud de los datos) y la cantidad de regularización que queremos hacer.\nAlgunas alternativas:\n\nMedia para la previa en (_g): 0\n\nCorresponde a que el medicamento no tenga impacto en el sueño\nPermite que el medicamento aumente o disminuya el sueño sin prejuicios\nCualquier otro número requeriría más justificación.\n\nDesviación estándar para la previa en (_g): 3\n\nIndica que estamos 95% seguros de que el impacto de un medicamento estará entre -6 y 6 horas adicionales de sueño y que es muy poco probable que el medicamento cambie el sueño en 9 o más horas. Esta es una previa bastante débil (6 horas adicionales de sueño sería mucho).\n\n\nPlanteamiento en JAGS:\n\nlibrary(R2jags)\n\nLoading required package: rjags\n\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\n\nAttaching package: 'R2jags'\n\n\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nsleep_model &lt;- function() {\n  for (i in 1:Nobs) {\n    extra[i] ~ dnorm(mu[drug[i]], 1 / sigma^2)\n  }\n  for (d in 1:Ndrugs) {\n    mu[d] ~ dnorm(0, 1/3^2)          # sd = 3\n  }\n  sigma ~ dunif(2/1000, 2 * 1000)    \n  delta_mu    &lt;- mu[2] - mu[1]\n  tau         &lt;- 1 / sigma^2               \n}\n\nsleep_jags &lt;- \n  jags(\n    model = sleep_model,\n    parameters.to.save = c(\"mu\", \"sigma\", \"delta_mu\"),\n    data = list(\n      extra = sleep$extra,\n      drug  = sleep$drug,\n      Nobs  = nrow(sleep),\n      Ndrugs = 2\n    ),\n    DIC = FALSE  # because we haven't discussed deviance yet\n  )\n\nmodule glm loaded\n\n\nmodule dic loaded\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 20\n   Unobserved stochastic nodes: 3\n   Total graph size: 57\n\nInitializing model\n\n\n\nlibrary(CalvinBayes)\n\nLoading required package: bayesplot\n\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\n\n\nAttaching package: 'CalvinBayes'\n\n\nThe following object is masked from 'package:bayesplot':\n\n    rhat\n\n\nThe following object is masked from 'package:datasets':\n\n    HairEyeColor\n\nlibrary(bayesplot)\nsummary(sleep_jags)\n\nfit using jags\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n         mu.vect sd.vect   2.5%   25%   50%   75% 97.5%  Rhat n.eff\ndelta_mu   1.504   0.901 -0.272 0.924 1.508 2.083 3.272 1.001  3000\nmu[1]      0.723   0.641 -0.530 0.312 0.718 1.126 1.994 1.001  3000\nmu[2]      2.227   0.622  0.926 1.823 2.228 2.641 3.395 1.001  3000\nsigma      2.048   0.369  1.474 1.785 1.998 2.265 2.873 1.005   410\n\nsleep_mcmc &lt;- as.mcmc(sleep_jags)\nmcmc_areas(sleep_mcmc, prob = 0.95, regex_pars = \"mu\")\n\n\n\n\n\n\n\nmcmc_areas(sleep_mcmc, prob = 0.95, regex_pars = \"sigma\")\n\n\n\n\n\n\n\nmcmc_pairs(sleep_mcmc)\n\n\n\n\n\n\n\n\nCuantificamos la probabilidad posterior de que el tiempo medio de sueño fue superior en la segunda droga que en la primera:\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nprop( ~(delta_mu &gt; 0), data = posterior(sleep_jags))\n\nprop_TRUE \n0.9523333 \n\n\n\n\n6.1.3 Desviaciones estándar distintas para cada grupo:\nSi consideramos una desviación estándar distinta para cada grupo:\n\nsleep_model2 &lt;- function() {\n  for (i in 1:Nobs) {\n    extra[i] ~ dnorm(mu[drug[i]], 1/sigma[drug[i]]^2)\n  }\n  for (d in 1:Ndrugs) {\n    mu[d]    ~  dnorm(0, 1/3^2)\n    sigma[d] ~  dunif(2/1000, 2 * 1000)  \n    tau[d]   &lt;- 1 / sigma[d]^2\n  }\n  delta_mu    &lt;- mu[2] - mu[1]\n  delta_sigma &lt;- sigma[2] - sigma[1]\n}\n\nsleep_jags2 &lt;- \n  jags(\n    model = sleep_model2,\n    parameters.to.save = c(\"mu\", \"sigma\", \"delta_mu\", \"delta_sigma\", \"tau\"),\n    data = list(\n      extra = sleep$extra,\n      drug  = sleep$drug,\n      Nobs  = nrow(sleep),\n      Ndrugs = 2\n    ),\n    DIC = FALSE\n  )\n\nResultados:\n\nsummary(sleep_jags2)\n\nfit using jags\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n            mu.vect sd.vect   2.5%    25%   50%   75% 97.5%  Rhat n.eff\ndelta_mu      1.465   1.000 -0.615  0.852 1.486 2.122 3.365 1.001  3000\ndelta_sigma   0.251   0.897 -1.503 -0.267 0.239 0.748 2.096 1.004   870\nmu[1]         0.707   0.653 -0.611  0.306 0.709 1.118 2.006 1.001  3000\nmu[2]         2.172   0.751  0.666  1.701 2.195 2.646 3.601 1.003  2100\nsigma[1]      2.084   0.605  1.269  1.672 1.963 2.363 3.604 1.002  3000\nsigma[2]      2.335   0.686  1.440  1.875 2.189 2.625 3.978 1.006   390\ntau[1]        0.283   0.143  0.077  0.179 0.260 0.358 0.621 1.002  3000\ntau[2]        0.224   0.109  0.063  0.145 0.209 0.284 0.482 1.006   390\n\nsleep_mcmc2 &lt;- as.mcmc(sleep_jags2)\nmcmc_areas(sleep_mcmc2, prob = 0.95, regex_pars = \"mu\")\n\n\n\n\n\n\n\nmcmc_areas(sleep_mcmc2, prob = 0.95, regex_pars = \"sigma\")\n\n\n\n\n\n\n\n\nProbabilidades posteriores:\n\nprop( ~(delta_mu &gt; 0), data = posterior(sleep_jags2))\n\nprop_TRUE \n0.9283333 \n\nprop( ~(delta_sigma &gt; 0), data = posterior(sleep_jags2))\n\nprop_TRUE \n    0.628 \n\nhdi(sleep_jags2, pars = c(\"delta\"))\n\n[1] par   lo    hi    prob  chain\n&lt;0 rows&gt; (or 0-length row.names)\n\nhdi(sleep_jags2)\n\n           par          lo        hi prob chain\n1     delta_mu -0.42916899 3.3958879 0.95     1\n2     delta_mu -0.43841097 3.6903099 0.95     2\n3     delta_mu -0.47902367 3.3569485 0.95     3\n4  delta_sigma -1.78814725 2.0722085 0.95     1\n5  delta_sigma -1.48567086 1.9934718 0.95     2\n6  delta_sigma -1.44612968 1.9262436 0.95     3\n7        mu[1] -0.62948924 1.8380521 0.95     1\n8        mu[1] -0.60592683 2.0782703 0.95     2\n9        mu[1] -0.54697367 2.0189645 0.95     3\n10       mu[2]  0.68648858 3.6563255 0.95     1\n11       mu[2]  0.86477453 3.6639031 0.95     2\n12       mu[2]  0.57237962 3.4360608 0.95     3\n13    sigma[1]  1.08678891 3.4499865 0.95     1\n14    sigma[1]  1.22152506 3.3496403 0.95     2\n15    sigma[1]  1.19640352 3.2401768 0.95     3\n16    sigma[2]  1.37994931 3.8579394 0.95     1\n17    sigma[2]  1.29662877 3.5625917 0.95     2\n18    sigma[2]  1.39009923 3.6987587 0.95     3\n19      tau[1]  0.04248336 0.5768080 0.95     1\n20      tau[1]  0.05097988 0.5330824 0.95     2\n21      tau[1]  0.06194363 0.5756741 0.95     3\n22      tau[2]  0.03103432 0.4190067 0.95     1\n23      tau[2]  0.05079998 0.4630146 0.95     2\n24      tau[2]  0.04720248 0.4356277 0.95     3\n\n\nComparación con una prueba t de dos muestras:\n\nt.test(extra ~ drug, data = sleep)\n\n\n    Welch Two Sample t-test\n\ndata:  extra by drug\nt = -1.8608, df = 17.776, p-value = 0.07939\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -3.3654832  0.2054832\nsample estimates:\nmean in group 1 mean in group 2 \n           0.75            2.33 \n\nprop( ~(delta_mu &lt; 0), data = posterior(sleep_jags2))\n\n prop_TRUE \n0.07166667 \n\n\n\n\n6.1.4 ROPE (Región de Equivalencia Práctica)\nSaber que dos cosas no son iguales no es de mucha utilidad práctica si la diferencia es pequeña. Una forma de cuantificar esto es especificar una región de equivalencia práctica (ROPE, por sus siglas en inglés). Podríamos decidir, por ejemplo, que no nos interesan las diferencias de menos de 10 minutos (1/6 horas). Nuestra ROPE (para la diferencia en medias) sería entonces el intervalo \\((-1/6, 1/6)\\) y podríamos preguntarnos si hay evidencia de que la diferencia verdadera se encuentra fuera de ese intervalo. Esto podría verificarse viendo si un HDI (Intervalo de Alta Densidad) se encuentra completamente fuera de la ROPE.\n\nplot_post(posterior(sleep_jags2)$delta_mu, ROPE = c(-1/6, 1/6),\n          hdi_prob = 0.9)\n\n\n\n\n\n\n\n\n$posterior\n      ESS     mean   median     mode\nvar1 3000 1.464829 1.486302 1.666862\n\n$hdi\n  prob          lo      hi\n1  0.9 -0.05022473 3.23944\n\n$ROPE\n          lo        hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE)\n1 -0.1666667 0.1666667     0.056 0.03866667 0.9053333\n\n\n\n\n6.1.5 Comparaciones Pareadas\nLos datos en realidad contienen otra variable: ID. Resulta que las mismas diez personas fueron evaluadas con cada medicamento. Si estamos principalmente interesados en comparar los dos medicamentos, podríamos tomar la diferencia entre el sueño adicional con un medicamento y con el otro para cada persona.\n\nsleep_wide &lt;-\n  datasets::sleep %&gt;% \n  rename(drug = group) %&gt;%\n  mutate(drug = paste0(\"drug\", drug)) %&gt;%\n  spread(key = drug, value = extra) \nsleep_wide\n\n   ID drug1 drug2\n1   1   0.7   1.9\n2   2  -1.6   0.8\n3   3  -0.2   1.1\n4   4  -1.2   0.1\n5   5  -0.1  -0.1\n6   6   3.4   4.4\n7   7   3.7   5.5\n8   8   0.8   1.6\n9   9   0.0   4.6\n10 10   2.0   3.4\n\nsleep_wide &lt;-\n  sleep_wide %&gt;%\n  mutate(delta = drug2 - drug1)\nsleep_wide\n\n   ID drug1 drug2 delta\n1   1   0.7   1.9   1.2\n2   2  -1.6   0.8   2.4\n3   3  -0.2   1.1   1.3\n4   4  -1.2   0.1   1.3\n5   5  -0.1  -0.1   0.0\n6   6   3.4   4.4   1.0\n7   7   3.7   5.5   1.8\n8   8   0.8   1.6   0.8\n9   9   0.0   4.6   4.6\n10 10   2.0   3.4   1.4\n\ngf_boxplot(~ delta, data = sleep_wide)\n\n\n\n\n\n\n\n\n\nsleep_model4 &lt;- function() {\n  for (i in 1:Nsubj) {\n    delta[i] ~ dt(mu, 1 / sigma^2, nu)\n  }\n  mu         ~ dnorm(0, 2)\n  sigma      ~ dunif(2/1000, 2 * 1000)\n  nuMinusOne ~ dexp(1/29)\n  nu        &lt;- nuMinusOne + 1\n  tau       &lt;- 1 / sigma^2\n}\n\nsleep_jags4 &lt;- \n  jags(\n    model = sleep_model4,\n    parameters.to.save = c(\"mu\", \"sigma\", \"nu\"),\n    data = list(\n      delta = sleep_wide$delta,\n      Nsubj = nrow(sleep_wide)\n    ),\n    n.iter = 5000,\n    DIC = FALSE)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 10\n   Unobserved stochastic nodes: 3\n   Total graph size: 25\n\nInitializing model\n\n\n\nsummary(sleep_jags4)\n\nfit using jags\n 3 chains, each with 5000 iterations (first 2500 discarded), n.thin = 2\n n.sims = 3750 iterations saved\n      mu.vect sd.vect  2.5%   25%    50%    75%  97.5%  Rhat n.eff\nmu      1.102   0.376 0.270 0.875  1.140  1.349  1.789 1.001  3000\nnu     21.976  25.564 1.331 4.569 12.257 30.024 92.348 1.003  1000\nsigma   1.203   0.506 0.399 0.863  1.145  1.463  2.385 1.002  1200\n\nsleep_mcmc4 &lt;- as.mcmc(sleep_jags4)\nmcmc_areas(sleep_mcmc4, prob = 0.95, pars = \"mu\")\n\n\n\n\n\n\n\nmcmc_areas(sleep_mcmc4, prob = 0.95, pars = \"nu\")\n\n\n\n\n\n\n\nmcmc_pairs(sleep_mcmc4)\n\n\n\n\n\n\n\nprop( ~(mu &gt; 0), data = posterior(sleep_jags4))\n\nprop_TRUE \n0.9933333 \n\nhdi(sleep_jags4, pars = c(\"mu\"))\n\n  par        lo       hi prob chain\n1  mu 0.3098570 1.784371 0.95     1\n2  mu 0.4107900 1.884160 0.95     2\n3  mu 0.2549675 1.775744 0.95     3\n\nhdi(sleep_jags4)\n\n    par        lo        hi prob chain\n1    mu 0.3098570  1.784371 0.95     1\n2    mu 0.4107900  1.884160 0.95     2\n3    mu 0.2549675  1.775744 0.95     3\n4    nu 1.0155811 74.410586 0.95     1\n5    nu 1.0056160 73.228221 0.95     2\n6    nu 1.0032844 77.723312 0.95     3\n7 sigma 0.3573697  2.251646 0.95     1\n8 sigma 0.2505344  2.056300 0.95     2\n9 sigma 0.2842914  2.229940 0.95     3",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 2)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos2.html#regresión-lineal-simple",
    "href": "estimacion_modelos2.html#regresión-lineal-simple",
    "title": "6  Estimación de Modelos Bayesianos (Parte 2)",
    "section": "6.2 Regresión Lineal Simple",
    "text": "6.2 Regresión Lineal Simple\nCarga de STAN:\n\nlibrary(rstan)\n\nLoading required package: StanHeaders\n\n\n\nrstan version 2.32.5 (Stan version 2.32.2)\n\n\nFor execution on a local, multicore CPU with excess RAM we recommend calling\noptions(mc.cores = parallel::detectCores()).\nTo avoid recompilation of unchanged Stan programs, we recommend calling\nrstan_options(auto_write = TRUE)\nFor within-chain threading using `reduce_sum()` or `map_rect()` Stan functions,\nchange `threads_per_chain` option:\nrstan_options(threads_per_chain = 1)\n\n\n\nAttaching package: 'rstan'\n\n\nThe following object is masked from 'package:R2jags':\n\n    traceplot\n\n\nThe following object is masked from 'package:coda':\n\n    traceplot\n\n\nThe following object is masked from 'package:tidyr':\n\n    extract\n\n\n\n6.2.1 Ejemplo: Datos de Galton\nDado que estamos viendo regresión, usemos un conjunto de datos históricos que formó parte de los orígenes de la historia de la regresión: los datos de Galton sobre la altura. Galton recopiló datos sobre la altura de los adultos y sus padres.\n\nlibrary(mosaicData)\nhead(Galton)\n\n  family father mother sex height nkids\n1      1   78.5   67.0   M   73.2     4\n2      1   78.5   67.0   F   69.2     4\n3      1   78.5   67.0   F   69.0     4\n4      1   78.5   67.0   F   69.0     4\n5      2   75.5   66.5   M   73.5     4\n6      2   75.5   66.5   M   72.5     4\n\n\nPara simplificar las cosas por el momento, consideremos solo a las mujeres y solo un hermano por familia.\n\nset.seed(54321)\nGaltonW &lt;-\n  mosaicData::Galton %&gt;% \n  filter(sex == \"F\") %&gt;%\n  group_by(family) %&gt;%\n  sample_n(1)\n\nProblema de estudio: Galton estaba interesado en cómo la altura de las personas se relaciona con la altura de sus padres. Combinó la altura de los padres en la “altura media de los padres”, que era el promedio de ambos.\n\nGaltonW &lt;- \n  GaltonW %&gt;%\n  mutate(midparent = (father + mother) / 2)\ngf_point(height ~ midparent, data = GaltonW, alpha = 0.5)\n\n\n\n\n\n\n\n\n\n\n6.2.2 Modelo de regresión\n\n6.2.2.1 Verosimilitud\n\\[\\begin{align*}\ny_{i} &\\sim {\\sf Norm}(\\mu_i, \\sigma) \\\\\n\\mu_i &\\sim \\beta_0 + \\beta_1 x_i\n\\end{align*}\\]\nAlgunas variaciones:\n\nSustituir la distribución normal por otra (t es común).\nPermitir que las desviaciones estándar varíen con \\(x\\) así como la media.\nUtilizar una relación funcional diferente entre la variable explicativa y la respuesta (regresión no lineal).\n\nLa primera variación a veces se llama regresión robusta porque es más robusta ante observaciones inusuales.\n\\[\\begin{align*}\ny_{i} &\\sim {\\sf T}(\\mu_i, \\sigma, \\nu) \\\\\n\\mu_i &\\sim \\beta_0 + \\beta_1 x_i\n\\end{align*}\\]\n\n\n6.2.2.2 Previas\nNecesitamos previas para \\(\\beta_0\\), \\(\\beta_1\\), \\(\\sigma\\) y \\(\\nu\\).\n\n\\(\\nu\\): Ya hemos visto que una Gamma trasladada con media alrededor de 30 funciona bien como una previa genérica, dando a los datos espacio para alejarnos de la normalidad si es necesario.\n\\(\\beta_1\\): El MLE para \\(\\beta_1\\) es\n\\[ \\hat\\beta_1 = r \\frac{SD_y}{SD_x}\\] por lo que tiene sentido tener una previa que cubra ampliamente el intervalo \\((- \\frac{SD_y}{SD_x}, \\frac{SD_y}{SD_x})\\).\n\\(\\beta_0\\): El MLE para \\(\\beta_0\\) es\n\\[ \\hat\\beta_0 \\; = \\;  \\overline{y} - \\hat \\beta_1 \\overline{x}  \\; = \\; \\overline{y} - r \\frac{SD_y}{SD_x} \\cdot \\overline{x}\\] por lo que podemos elegir un prior que cubra ampliamente el intervalo \\((\\overline{y} - \\frac{SD_y}{SD_x} \\cdot \\overline{x}, \\overline{y} - \\frac{SD_y}{SD_x} \\cdot \\overline{x})\\)\n\\(\\sigma\\) mide la cantidad de variabilidad en las respuestas para un valor fijo de \\(x\\). Una previa débilmente informativa debería cubrir el rango de valores razonables de \\(\\sigma\\) con bastante margen.\n\nImplementación en JAGS:\n\ngalton_model &lt;- function() {\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- beta0 + beta1 * x[i]\n  }\n  sigma ~ dunif(6/100, 6 * 100)\n  nuMinusOne ~ dexp(1/29)\n  nu &lt;- nuMinusOne + 1\n  beta0 ~ dnorm(0, 1/100^2)   # 100 is order of magnitude of data\n  beta1 ~ dnorm(0, 1/4^2)     # expect roughly 1-1 slope\n}\n\n\ngalton_jags &lt;-\n  jags(\n    model = galton_model,\n    data = list(y = GaltonW$height, x = GaltonW$midparent),\n    parameters.to.save = c(\"beta0\", \"beta1\", \"sigma\", \"nu\"),\n    n.iter = 5000,\n    n.burnin = 2000,\n    n.chains = 4,\n    n.thin = 1\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 168\n   Unobserved stochastic nodes: 4\n   Total graph size: 439\n\nInitializing model\n\n\n\nsummary(galton_jags)\n\nfit using jags\n 4 chains, each with 5000 iterations (first 2000 discarded)\n n.sims = 12000 iterations saved\n         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\nbeta0     20.485  10.628   4.679  11.691  19.836  28.017  43.115 2.443     5\nbeta1      0.654   0.159   0.314   0.541   0.663   0.785   0.890 2.825     5\nnu        37.706  29.592   7.104  16.803  28.849  49.512 119.715 1.001  4000\nsigma      1.956   0.133   1.703   1.865   1.955   2.044   2.222 1.023   110\ndeviance 715.427   5.446 709.847 711.779 713.932 717.038 732.172 1.657     9\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 9.1 and DIC = 724.5\n\nmcmc_combo(as.mcmc(galton_jags))\n\n\n\n\n\n\n\n\nClaramente la convergencia no es la más adecuada.\n\nposterior(galton_jags) %&gt;% \n  gf_point(beta0 ~ beta1, color = ~ chain, alpha = 0.2, size = 0.4) %&gt;%\n  gf_density2d(alpha = 0.5)\n\n\n\n\n\n\n\nposterior(galton_jags) %&gt;% filter(iter &lt;= 250, chain == \"chain:1\") %&gt;%\n  gf_step(beta0 ~ beta1, alpha = 0.8, color = ~iter) %&gt;%\n  gf_density2d(alpha = 0.2) %&gt;%\n  gf_refine(scale_color_viridis_c()) %&gt;%\n  gf_facet_wrap(~chain) #, scales = \"free\")\n\nWarning: The following aesthetics were dropped during statistical transformation:\ncolour.\nℹ This can happen when ggplot fails to infer the correct grouping structure in\n  the data.\nℹ Did you forget to specify a `group` aesthetic or to convert a numerical\n  variable into a factor?\n\n\n\n\n\n\n\n\n\nLa correlación de los parámetros en la distribución posterior produce una cresta larga, estrecha y diagonal que el muestreador de Gibbs muestrea muy lentamente porque sigue chocando con el borde de la región.\nEntonces, ¿cómo solucionamos esto? Se supone que este es el modelo lineal simple después de todo. Hay dos formas en las que podríamos esperar solucionar nuestro problema.\n\nReparametrizar el modelo para que la correlación entre los parámetros (en la distribución posterior) se reduzca o elimine.\nUsar un algoritmo diferente para el muestreo posterior.\n\nReparametrización 1: centrado\nPodemos expresar este modelo como\n\\[\\begin{align*}\ny_{i} &\\sim {\\sf T}(\\mu_i, \\sigma, \\nu) \\\\\n\\mu_i &= \\alpha_0 + \\alpha_1 (x_i - \\overline{x})\n\\end{align*}\\]\nDado que\n\\[\\begin{align*}\n\\alpha_0 + \\alpha_1 (x_i - \\overline{x})\n&= (\\alpha_0 - \\alpha_1 \\overline{x}) + \\alpha_1 x_i\n\\end{align*}\\]\nVemos que \\(\\beta_0 = \\alpha_0 - \\alpha_1 \\overline{x}\\) y \\(\\beta_1 = \\alpha_1\\). Por lo tanto, podemos recuperar fácilmente los parámetros originales si lo deseamos. (Y si estamos principalmente interesados en \\(\\beta_1\\), no se requiere ninguna traducción).\nEsta reparametrización mantiene la escala natural de los datos, y tanto \\(\\alpha_0\\) como \\(\\alpha_1\\) son fácilmente interpretados: \\(\\alpha_0\\) es la respuesta media cuando el predictor es el promedio de los valores del predictor en los datos.\nModelación en JAGS:\n\ngaltonC_model &lt;- function() {\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x))\n  }\n  sigma ~ dunif(6/100, 6 * 100)\n  nuMinusOne ~ dexp(1/29)\n  nu &lt;- nuMinusOne + 1\n  alpha0 ~ dnorm(0, 1/100^2)   # 100 is order of magnitude of data\n  alpha1 ~ dnorm(0, 1/4^2)     # expect roughly 1-1 slope\n  beta0 = alpha0 - alpha1 * mean(x)\n  beta1 = alpha1               # not necessary, but gives us both names\n}\ngaltonC_jags &lt;-\n  jags(\n    model = galtonC_model,\n    data = list(y = GaltonW$height, x = GaltonW$midparent),\n    parameters.to.save = c(\"beta0\", \"beta1\", \"alpha0\", \"alpha1\", \"sigma\", \"nu\"),\n    n.iter = 5000,\n    n.burnin = 2000,\n    n.chains = 4,\n    n.thin = 1\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 168\n   Unobserved stochastic nodes: 4\n   Total graph size: 484\n\nInitializing model\n\n\n\nsummary(galtonC_jags)\n\nfit using jags\n 4 chains, each with 5000 iterations (first 2000 discarded)\n n.sims = 12000 iterations saved\n         mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\nalpha0    64.131   0.157  63.824  64.026  64.130  64.237  64.443 1.001  5800\nalpha1     0.706   0.085   0.539   0.649   0.706   0.763   0.873 1.001 12000\nbeta0     16.964   5.662   5.816  13.161  16.985  20.773  28.140 1.001 12000\nbeta1      0.706   0.085   0.539   0.649   0.706   0.763   0.873 1.001 12000\nnu        37.384  29.036   7.126  17.277  28.864  48.228 117.040 1.003  1200\nsigma      1.940   0.128   1.686   1.856   1.940   2.026   2.190 1.002  3200\ndeviance 712.626   2.596 709.617 710.731 711.961 713.813 719.426 1.002  2400\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 3.4 and DIC = 716.0\n\nmcmc_combo(as.mcmc(galtonC_jags))\n\n\n\n\n\n\n\n\n\ngf_point(beta1 ~ beta0, data = posterior(galtonC_jags), alpha = 0.1)\n\n\n\n\n\n\n\ngf_point(alpha1 ~ alpha0, data = posterior(galtonC_jags), alpha = 0.1)\n\n\n\n\n\n\n\n\n\n\n\n6.2.3 Análisis posterior\n\n6.2.3.1 Estimar parámetros\nSi estamos principalmente interesados en un parámetro de regresión (generalmente el parámetro de pendiente es mucho más interesante que el parámetro de intercepción), podemos usar un HDI para expresar nuestra estimación.\n\nhdi(posterior(galtonC_jags), pars = \"beta1\")\n\n    par        lo        hi      mode prob\n1 beta1 0.5435323 0.8770839 0.7127963 0.95\n\nmcmc_areas(as.mcmc(galtonC_jags), pars = \"beta1\", prob = 0.95)\n\n\n\n\n\n\n\n\nGalton notó lo que vemos aquí: que la pendiente es menor que 1. Esto significa que los hijos de padres más altos que el promedio tienden a ser más bajos que sus padres y los hijos de padres por debajo del promedio tienden a ser más altos que sus padres. Se refirió a esto en su artículo como [“regresión hacia la mediocridad”]. Resulta que esto no fue una característica especial de la herencia de la altura, sino una característica general de los modelos lineales.\n\n\n6.2.3.2 Hacer predicciones\nSupongamos que conocemos las alturas de un padre y una madre, a partir de las cuales calculamos la altura del padre y la madre (\\(x\\)). ¿Qué tan alto predeciríamos que serán sus hijas cuando sean adultas? Cada muestra posterior proporciona una respuesta describiendo una distribución t con nu grados de libertad, media \\(\\beta_0 + \\beta_1 x\\) y desviación estándar \\(\\sigma\\).\nLa distribución posterior de la altura promedio de las hijas nacidas de padres con una altura de padre y madre de \\(x = 70\\) se muestra a continuación, junto con un HDI.\n\nposterior(galtonC_jags) %&gt;% \n  mutate(mean_daughter = beta0 + beta1 * 70) %&gt;%\n  gf_dens(~mean_daughter)\n\n\n\n\n\n\n\nGalton_hdi &lt;-\n  posterior(galtonC_jags) %&gt;% \n  mutate(mean_daughter = beta0 + beta1 * 70) %&gt;%\n  hdi(pars = \"mean_daughter\")\nGalton_hdi\n\n            par       lo       hi     mode prob\n1 mean_daughter 65.77185 67.01363 66.34311 0.95\n\n\nEntonces, en promedio, predeciríamos que las hijas tienen aproximadamente 66 o 67 pulgadas de altura.\nPodemos visualizar esto dibujando una línea para cada muestra posterior. El HDI debería abarcar el 95% intermedio de estos.\n\ngf_abline(intercept = ~beta0, slope = ~beta1, alpha = 0.01,\n          color = \"steelblue\", \n          data = posterior(galtonC_jags) %&gt;% sample_n(2000)) %&gt;%\n  gf_point(height ~ midparent, data = GaltonW, \n           inherit = FALSE, alpha = 0.5) %&gt;%\n  gf_errorbar(lo + hi ~ 70, data = Galton_hdi, color = \"skyblue\", \n              width = 0.2, size = 1.2, inherit = FALSE)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nPero esta puede no ser el tipo de predicción que queremos. Observa que las alturas de la mayoría de las hijas no están dentro de la banda azul en la imagen. Esa banda habla sobre la media, pero no tiene en cuenta cuánto varían los individuos alrededor de esa media.\nAquí generamos alturas agregando ruido a la estimación dada por los valores de \\(\\beta_0\\) y \\(\\beta_1\\).\n\nposterior(galtonC_jags) %&gt;%  \n  mutate(new_ht = beta0 + beta1 * 70 + rt(1200, df = nu) * sigma) %&gt;%\n  gf_point(new_ht ~ 70, alpha = 0.01, size = 0.7, color = \"steelblue\") %&gt;%\n  gf_point(height ~ midparent, data = GaltonW, \n           inherit = FALSE, alpha = 0.5) \n\n\n\n\n\n\n\n\n\nGalton_hdi2 &lt;-\n  posterior(galtonC_jags) %&gt;% \n  mutate(new_ht = beta0 + beta1 * 70 + rt(1200, df = nu) * sigma) %&gt;%\n  hdi(regex_pars = \"new\") \nGalton_hdi2\n\n     par       lo       hi     mode prob\n1 new_ht 62.13155 70.25104 65.91627 0.95\n\n\n\n\n6.2.3.3 Verificación predictiva posterior con bayesplot\nEl paquete bayesplot proporciona varios gráficos de verificación predictiva posterior (ppc). Estas funciones requieren dos entradas importantes:\n\ny: un vector de valores de respuesta, generalmente los valores del conjunto de datos original.\nyrep: una matriz de valores y simulados. Cada fila corresponde a una muestra posterior. Hay una columna para cada valor de y.\n\nEntonces, las filas de yrep se pueden comparar con y para ver si el modelo se comporta bien.\nNota: Podemos calcular nuestros valores simulados \\(y\\) utilizando valores de predictores que sean similares a los de nuestros datos o utilizando otros valores de predictores que elijamos. La segunda opción nos permite considerar situaciones contrafactuales. Para distinguir estos, algunas personas usan \\(y_rep\\) para lo primero y \\(\\tilde{y}\\) para lo segundo.\nAhora todo el trabajo está en crear la matriz yrep. Para simplificar eso, usaremos CalvinBayes::posterior_calc(). Lo haremos de dos maneras, una vez para los valores promedio de altura y otra vez para los valores individuales de altura (teniendo en cuenta la variabilidad de persona a persona según lo cuantificado por \\(\\nu\\) y \\(\\sigma\\)).\n\ny_avg &lt;- \n  posterior_calc(\n    galtonC_jags, \n    height ~ beta0 + beta1 * midparent, \n    data = GaltonW)\ny_ind &lt;- \n  posterior_calc(\n    galtonC_jags, \n    height ~ \n      beta0 + beta1 * midparent + rt(nrow(GaltonW), df = nu) * sigma, \n    data = GaltonW)\n\nLos diferentes gráficos de verificación predictiva posterior comienzan con ppc_. Aquí tienes un ejemplo:\n\nppc_intervals(GaltonW$height, y_avg, x = GaltonW$midparent)\n\n\n\n\n\n\n\nppc_intervals(GaltonW$height, y_ind, x = GaltonW$midparent)\n\n\n\n\n\n\n\n\nPodemos extraer los datos utilizados para crear el gráfico y hacer nuestro propio gráfico como queramos.\n\nplot_data &lt;- \n  ppc_ribbon_data(GaltonW$height, y_ind, x = GaltonW$midparent)\nglimpse(plot_data)\n\nRows: 168\nColumns: 10\n$ y_id        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ y_obs       &lt;dbl&gt; 69.0, 65.5, 62.5, 61.0, 64.0, 67.5, 65.5, 65.5, 64.0, 65.2…\n$ x           &lt;dbl&gt; 72.75, 69.75, 67.50, 67.75, 68.00, 67.75, 67.75, 67.50, 67…\n$ outer_width &lt;dbl&gt; 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9…\n$ inner_width &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…\n$ ll          &lt;dbl&gt; 64.87028, 62.84453, 61.28324, 61.40978, 61.65842, 61.46755…\n$ l           &lt;dbl&gt; 66.95325, 64.86351, 63.28902, 63.46770, 63.64949, 63.46092…\n$ m           &lt;dbl&gt; 68.37181, 66.19737, 64.62360, 64.81006, 64.99056, 64.81988…\n$ h           &lt;dbl&gt; 69.72746, 67.53690, 65.96373, 66.16710, 66.34426, 66.18309…\n$ hh          &lt;dbl&gt; 71.80631, 69.54626, 67.94110, 68.18508, 68.40763, 68.18462…\n\nplot_data %&gt;%\n  gf_ribbon(ll + hh ~ x, fill = \"steelblue\") %&gt;%\n  gf_ribbon(l + h ~ x, fill = \"steelblue\") %&gt;%\n  gf_line(m ~ x, color = \"steelblue\") %&gt;%\n  gf_point(y_obs ~ x, alpha = 0.5)\n\n\n\n\n\n\n\nplot_data %&gt;%\n  gf_smooth(ll ~ x, color = \"steelblue\") %&gt;%\n  gf_smooth(hh ~ x, color= \"steelblue\") %&gt;%\n  gf_smooth(m ~ x, color= \"steelblue\") %&gt;%\n  gf_point(y_obs ~ x, alpha = 0.5)\n\n`geom_smooth()` using method = 'loess'\n`geom_smooth()` using method = 'loess'\n`geom_smooth()` using method = 'loess'\n\n\n\n\n\n\n\n\n\n\n\n\n6.2.4 Ajuste de modelos con Stan\nCentrar (o estandarizar) es suficiente para hacer que JAGS sea lo suficientemente eficiente como para usarlo. Pero también podemos usar Stan, y dado que Stan no se ve afectado por la correlación en el posterior de la manera en que lo hace JAGS, Stan funciona bien incluso sin reparametrizar el modelo.\nEl código correspondiente del modelo anterior está en el archivo galton.stan\n\nmodelo_galton &lt;- stan_model(file = 'galton.stan',verbose = T)\n\n\nTRANSLATING MODEL '' FROM Stan CODE TO C++ CODE NOW.\nOS: x86_64, linux-gnu; rstan: 2.32.5; Rcpp: 1.0.12; inline: 0.3.19 \n &gt;&gt; setting environment variables: \nPKG_LIBS =  '/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/rstan/lib//libStanServices.a' -L'/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/lib/' -lStanHeaders -L'/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppParallel/lib/' -ltbb \nPKG_CPPFLAGS =   -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/Rcpp/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppEigen/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppEigen/include/unsupported\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/BH/include\" -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/src/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppParallel/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1 \n &gt;&gt; Program source :\n\n   1 : \n   2 : // includes from the plugin\n   3 : // [[Rcpp::plugins(cpp14)]]\n   4 : \n   5 : \n   6 : // user includes\n   7 : #include &lt;Rcpp.h&gt;\n   8 : using namespace Rcpp;\n   9 : #ifndef MODELS_HPP\n  10 : #define MODELS_HPP\n  11 : #define STAN__SERVICES__COMMAND_HPP\n  12 : #include &lt;rstan/rstaninc.hpp&gt;\n  13 : #ifndef USE_STANC3\n  14 : #define USE_STANC3\n  15 : #endif\n  16 : // Code generated by stanc v2.32.2\n  17 : #include &lt;stan/model/model_header.hpp&gt;\n  18 : namespace model1f47162ba74f__namespace {\n  19 : using stan::model::model_base_crtp;\n  20 : using namespace stan::math;\n  21 : stan::math::profile_map profiles__;\n  22 : static constexpr std::array&lt;const char*, 17&gt; locations_array__ =\n  23 :   {\" (found before start of program)\",\n  24 :   \" (in 'anon_model', line 20, column 2 to column 13)\",\n  25 :   \" (in 'anon_model', line 21, column 2 to column 13)\",\n  26 :   \" (in 'anon_model', line 22, column 2 to column 22)\",\n  27 :   \" (in 'anon_model', line 23, column 2 to column 27)\",\n  28 :   \" (in 'anon_model', line 26, column 2 to column 19)\",\n  29 :   \" (in 'anon_model', line 27, column 2 to column 22)\",\n  30 :   \" (in 'anon_model', line 33, column 2 to column 46)\",\n  31 :   \" (in 'anon_model', line 34, column 2 to column 25)\",\n  32 :   \" (in 'anon_model', line 35, column 2 to column 23)\",\n  33 :   \" (in 'anon_model', line 36, column 2 to column 44)\",\n  34 :   \" (in 'anon_model', line 37, column 2 to column 35)\",\n  35 :   \" (in 'anon_model', line 13, column 2 to column 17)\",\n  36 :   \" (in 'anon_model', line 14, column 9 to column 10)\",\n  37 :   \" (in 'anon_model', line 14, column 2 to column 14)\",\n  38 :   \" (in 'anon_model', line 15, column 9 to column 10)\",\n  39 :   \" (in 'anon_model', line 15, column 2 to column 14)\"};\n  40 : class model1f47162ba74f_ final : public model_base_crtp&lt;model1f47162ba74f_&gt; {\n  41 : private:\n  42 :   int N;\n  43 :   Eigen::Matrix&lt;double,-1,1&gt; y_data__;\n  44 :   Eigen::Matrix&lt;double,-1,1&gt; x_data__;\n  45 :   Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt; y{nullptr, 0};\n  46 :   Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt; x{nullptr, 0};\n  47 : public:\n  48 :   ~model1f47162ba74f_() {}\n  49 :   model1f47162ba74f_(stan::io::var_context& context__, unsigned int\n  50 :                      random_seed__ = 0, std::ostream* pstream__ = nullptr)\n  51 :       : model_base_crtp(0) {\n  52 :     int current_statement__ = 0;\n  53 :     using local_scalar_t__ = double;\n  54 :     boost::ecuyer1988 base_rng__ =\n  55 :       stan::services::util::create_rng(random_seed__, 0);\n  56 :     // suppress unused var warning\n  57 :     (void) base_rng__;\n  58 :     static constexpr const char* function__ =\n  59 :       \"model1f47162ba74f__namespace::model1f47162ba74f_\";\n  60 :     // suppress unused var warning\n  61 :     (void) function__;\n  62 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n  63 :     // suppress unused var warning\n  64 :     (void) DUMMY_VAR__;\n  65 :     try {\n  66 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n  67 :       pos__ = 1;\n  68 :       current_statement__ = 12;\n  69 :       context__.validate_dims(\"data initialization\", \"N\", \"int\",\n  70 :         std::vector&lt;size_t&gt;{});\n  71 :       N = std::numeric_limits&lt;int&gt;::min();\n  72 :       current_statement__ = 12;\n  73 :       N = context__.vals_i(\"N\")[(1 - 1)];\n  74 :       current_statement__ = 12;\n  75 :       stan::math::check_greater_or_equal(function__, \"N\", N, 0);\n  76 :       current_statement__ = 13;\n  77 :       stan::math::validate_non_negative_index(\"y\", \"N\", N);\n  78 :       current_statement__ = 14;\n  79 :       context__.validate_dims(\"data initialization\", \"y\", \"double\",\n  80 :         std::vector&lt;size_t&gt;{static_cast&lt;size_t&gt;(N)});\n  81 :       y_data__ = Eigen::Matrix&lt;double,-1,1&gt;::Constant(N,\n  82 :                    std::numeric_limits&lt;double&gt;::quiet_NaN());\n  83 :       new (&y) Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(y_data__.data(), N);\n  84 :       {\n  85 :         std::vector&lt;local_scalar_t__&gt; y_flat__;\n  86 :         current_statement__ = 14;\n  87 :         y_flat__ = context__.vals_r(\"y\");\n  88 :         current_statement__ = 14;\n  89 :         pos__ = 1;\n  90 :         current_statement__ = 14;\n  91 :         for (int sym1__ = 1; sym1__ &lt;= N; ++sym1__) {\n  92 :           current_statement__ = 14;\n  93 :           stan::model::assign(y, y_flat__[(pos__ - 1)],\n  94 :             \"assigning variable y\", stan::model::index_uni(sym1__));\n  95 :           current_statement__ = 14;\n  96 :           pos__ = (pos__ + 1);\n  97 :         }\n  98 :       }\n  99 :       current_statement__ = 15;\n 100 :       stan::math::validate_non_negative_index(\"x\", \"N\", N);\n 101 :       current_statement__ = 16;\n 102 :       context__.validate_dims(\"data initialization\", \"x\", \"double\",\n 103 :         std::vector&lt;size_t&gt;{static_cast&lt;size_t&gt;(N)});\n 104 :       x_data__ = Eigen::Matrix&lt;double,-1,1&gt;::Constant(N,\n 105 :                    std::numeric_limits&lt;double&gt;::quiet_NaN());\n 106 :       new (&x) Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(x_data__.data(), N);\n 107 :       {\n 108 :         std::vector&lt;local_scalar_t__&gt; x_flat__;\n 109 :         current_statement__ = 16;\n 110 :         x_flat__ = context__.vals_r(\"x\");\n 111 :         current_statement__ = 16;\n 112 :         pos__ = 1;\n 113 :         current_statement__ = 16;\n 114 :         for (int sym1__ = 1; sym1__ &lt;= N; ++sym1__) {\n 115 :           current_statement__ = 16;\n 116 :           stan::model::assign(x, x_flat__[(pos__ - 1)],\n 117 :             \"assigning variable x\", stan::model::index_uni(sym1__));\n 118 :           current_statement__ = 16;\n 119 :           pos__ = (pos__ + 1);\n 120 :         }\n 121 :       }\n 122 :     } catch (const std::exception& e) {\n 123 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 124 :     }\n 125 :     num_params_r__ = 1 + 1 + 1 + 1;\n 126 :   }\n 127 :   inline std::string model_name() const final {\n 128 :     return \"model1f47162ba74f_\";\n 129 :   }\n 130 :   inline std::vector&lt;std::string&gt; model_compile_info() const noexcept {\n 131 :     return std::vector&lt;std::string&gt;{\"stanc_version = stanc3 v2.32.2\",\n 132 :              \"stancflags = --\"};\n 133 :   }\n 134 :   template &lt;bool propto__, bool jacobian__, typename VecR, typename VecI,\n 135 :             stan::require_vector_like_t&lt;VecR&gt;* = nullptr,\n 136 :             stan::require_vector_like_vt&lt;std::is_integral, VecI&gt;* = nullptr&gt;\n 137 :   inline stan::scalar_type_t&lt;VecR&gt;\n 138 :   log_prob_impl(VecR& params_r__, VecI& params_i__, std::ostream*\n 139 :                 pstream__ = nullptr) const {\n 140 :     using T__ = stan::scalar_type_t&lt;VecR&gt;;\n 141 :     using local_scalar_t__ = T__;\n 142 :     T__ lp__(0.0);\n 143 :     stan::math::accumulator&lt;T__&gt; lp_accum__;\n 144 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 145 :     int current_statement__ = 0;\n 146 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 147 :     // suppress unused var warning\n 148 :     (void) DUMMY_VAR__;\n 149 :     static constexpr const char* function__ =\n 150 :       \"model1f47162ba74f__namespace::log_prob\";\n 151 :     // suppress unused var warning\n 152 :     (void) function__;\n 153 :     try {\n 154 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 155 :       current_statement__ = 1;\n 156 :       beta0 = in__.template read&lt;local_scalar_t__&gt;();\n 157 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 158 :       current_statement__ = 2;\n 159 :       beta1 = in__.template read&lt;local_scalar_t__&gt;();\n 160 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 161 :       current_statement__ = 3;\n 162 :       sigma = in__.template read_constrain_lb&lt;local_scalar_t__,\n 163 :                 jacobian__&gt;(0, lp__);\n 164 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 165 :       current_statement__ = 4;\n 166 :       nuMinusOne = in__.template read_constrain_lb&lt;local_scalar_t__,\n 167 :                      jacobian__&gt;(0, lp__);\n 168 :       local_scalar_t__ nu = DUMMY_VAR__;\n 169 :       current_statement__ = 6;\n 170 :       nu = (nuMinusOne + 1);\n 171 :       current_statement__ = 5;\n 172 :       stan::math::check_greater_or_equal(function__, \"nu\", nu, 0);\n 173 :       {\n 174 :         current_statement__ = 7;\n 175 :         lp_accum__.add(stan::math::student_t_lpdf&lt;propto__&gt;(y, nu,\n 176 :                          stan::math::add(beta0,\n 177 :                            stan::math::multiply(beta1, x)), sigma));\n 178 :         current_statement__ = 8;\n 179 :         lp_accum__.add(stan::math::normal_lpdf&lt;propto__&gt;(beta0, 0, 100));\n 180 :         current_statement__ = 9;\n 181 :         lp_accum__.add(stan::math::normal_lpdf&lt;propto__&gt;(beta1, 0, 4));\n 182 :         current_statement__ = 10;\n 183 :         lp_accum__.add(stan::math::uniform_lpdf&lt;propto__&gt;(sigma, (6.0 /\n 184 :                          100.0), (6.0 * 100.0)));\n 185 :         current_statement__ = 11;\n 186 :         lp_accum__.add(stan::math::exponential_lpdf&lt;propto__&gt;(nuMinusOne, (1\n 187 :                          / 29.0)));\n 188 :       }\n 189 :     } catch (const std::exception& e) {\n 190 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 191 :     }\n 192 :     lp_accum__.add(lp__);\n 193 :     return lp_accum__.sum();\n 194 :   }\n 195 :   template &lt;typename RNG, typename VecR, typename VecI, typename VecVar,\n 196 :             stan::require_vector_like_vt&lt;std::is_floating_point,\n 197 :             VecR&gt;* = nullptr, stan::require_vector_like_vt&lt;std::is_integral,\n 198 :             VecI&gt;* = nullptr, stan::require_vector_vt&lt;std::is_floating_point,\n 199 :             VecVar&gt;* = nullptr&gt;\n 200 :   inline void\n 201 :   write_array_impl(RNG& base_rng__, VecR& params_r__, VecI& params_i__,\n 202 :                    VecVar& vars__, const bool\n 203 :                    emit_transformed_parameters__ = true, const bool\n 204 :                    emit_generated_quantities__ = true, std::ostream*\n 205 :                    pstream__ = nullptr) const {\n 206 :     using local_scalar_t__ = double;\n 207 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 208 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 209 :     static constexpr bool propto__ = true;\n 210 :     // suppress unused var warning\n 211 :     (void) propto__;\n 212 :     double lp__ = 0.0;\n 213 :     // suppress unused var warning\n 214 :     (void) lp__;\n 215 :     int current_statement__ = 0;\n 216 :     stan::math::accumulator&lt;double&gt; lp_accum__;\n 217 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 218 :     // suppress unused var warning\n 219 :     (void) DUMMY_VAR__;\n 220 :     constexpr bool jacobian__ = false;\n 221 :     static constexpr const char* function__ =\n 222 :       \"model1f47162ba74f__namespace::write_array\";\n 223 :     // suppress unused var warning\n 224 :     (void) function__;\n 225 :     try {\n 226 :       double beta0 = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 227 :       current_statement__ = 1;\n 228 :       beta0 = in__.template read&lt;local_scalar_t__&gt;();\n 229 :       double beta1 = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 230 :       current_statement__ = 2;\n 231 :       beta1 = in__.template read&lt;local_scalar_t__&gt;();\n 232 :       double sigma = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 233 :       current_statement__ = 3;\n 234 :       sigma = in__.template read_constrain_lb&lt;local_scalar_t__,\n 235 :                 jacobian__&gt;(0, lp__);\n 236 :       double nuMinusOne = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 237 :       current_statement__ = 4;\n 238 :       nuMinusOne = in__.template read_constrain_lb&lt;local_scalar_t__,\n 239 :                      jacobian__&gt;(0, lp__);\n 240 :       double nu = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 241 :       out__.write(beta0);\n 242 :       out__.write(beta1);\n 243 :       out__.write(sigma);\n 244 :       out__.write(nuMinusOne);\n 245 :       if (stan::math::logical_negation(\n 246 :             (stan::math::primitive_value(emit_transformed_parameters__) ||\n 247 :             stan::math::primitive_value(emit_generated_quantities__)))) {\n 248 :         return ;\n 249 :       }\n 250 :       current_statement__ = 6;\n 251 :       nu = (nuMinusOne + 1);\n 252 :       current_statement__ = 5;\n 253 :       stan::math::check_greater_or_equal(function__, \"nu\", nu, 0);\n 254 :       if (emit_transformed_parameters__) {\n 255 :         out__.write(nu);\n 256 :       }\n 257 :       if (stan::math::logical_negation(emit_generated_quantities__)) {\n 258 :         return ;\n 259 :       }\n 260 :     } catch (const std::exception& e) {\n 261 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 262 :     }\n 263 :   }\n 264 :   template &lt;typename VecVar, typename VecI,\n 265 :             stan::require_vector_t&lt;VecVar&gt;* = nullptr,\n 266 :             stan::require_vector_like_vt&lt;std::is_integral, VecI&gt;* = nullptr&gt;\n 267 :   inline void\n 268 :   unconstrain_array_impl(const VecVar& params_r__, const VecI& params_i__,\n 269 :                          VecVar& vars__, std::ostream* pstream__ = nullptr) const {\n 270 :     using local_scalar_t__ = double;\n 271 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 272 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 273 :     int current_statement__ = 0;\n 274 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 275 :     // suppress unused var warning\n 276 :     (void) DUMMY_VAR__;\n 277 :     try {\n 278 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n 279 :       pos__ = 1;\n 280 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 281 :       current_statement__ = 1;\n 282 :       beta0 = in__.read&lt;local_scalar_t__&gt;();\n 283 :       out__.write(beta0);\n 284 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 285 :       current_statement__ = 2;\n 286 :       beta1 = in__.read&lt;local_scalar_t__&gt;();\n 287 :       out__.write(beta1);\n 288 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 289 :       current_statement__ = 3;\n 290 :       sigma = in__.read&lt;local_scalar_t__&gt;();\n 291 :       out__.write_free_lb(0, sigma);\n 292 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 293 :       current_statement__ = 4;\n 294 :       nuMinusOne = in__.read&lt;local_scalar_t__&gt;();\n 295 :       out__.write_free_lb(0, nuMinusOne);\n 296 :     } catch (const std::exception& e) {\n 297 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 298 :     }\n 299 :   }\n 300 :   template &lt;typename VecVar, stan::require_vector_t&lt;VecVar&gt;* = nullptr&gt;\n 301 :   inline void\n 302 :   transform_inits_impl(const stan::io::var_context& context__, VecVar&\n 303 :                        vars__, std::ostream* pstream__ = nullptr) const {\n 304 :     using local_scalar_t__ = double;\n 305 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 306 :     int current_statement__ = 0;\n 307 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 308 :     // suppress unused var warning\n 309 :     (void) DUMMY_VAR__;\n 310 :     try {\n 311 :       current_statement__ = 1;\n 312 :       context__.validate_dims(\"parameter initialization\", \"beta0\", \"double\",\n 313 :         std::vector&lt;size_t&gt;{});\n 314 :       current_statement__ = 2;\n 315 :       context__.validate_dims(\"parameter initialization\", \"beta1\", \"double\",\n 316 :         std::vector&lt;size_t&gt;{});\n 317 :       current_statement__ = 3;\n 318 :       context__.validate_dims(\"parameter initialization\", \"sigma\", \"double\",\n 319 :         std::vector&lt;size_t&gt;{});\n 320 :       current_statement__ = 4;\n 321 :       context__.validate_dims(\"parameter initialization\", \"nuMinusOne\",\n 322 :         \"double\", std::vector&lt;size_t&gt;{});\n 323 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n 324 :       pos__ = 1;\n 325 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 326 :       current_statement__ = 1;\n 327 :       beta0 = context__.vals_r(\"beta0\")[(1 - 1)];\n 328 :       out__.write(beta0);\n 329 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 330 :       current_statement__ = 2;\n 331 :       beta1 = context__.vals_r(\"beta1\")[(1 - 1)];\n 332 :       out__.write(beta1);\n 333 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 334 :       current_statement__ = 3;\n 335 :       sigma = context__.vals_r(\"sigma\")[(1 - 1)];\n 336 :       out__.write_free_lb(0, sigma);\n 337 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 338 :       current_statement__ = 4;\n 339 :       nuMinusOne = context__.vals_r(\"nuMinusOne\")[(1 - 1)];\n 340 :       out__.write_free_lb(0, nuMinusOne);\n 341 :     } catch (const std::exception& e) {\n 342 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 343 :     }\n 344 :   }\n 345 :   inline void\n 346 :   get_param_names(std::vector&lt;std::string&gt;& names__, const bool\n 347 :                   emit_transformed_parameters__ = true, const bool\n 348 :                   emit_generated_quantities__ = true) const {\n 349 :     names__ = std::vector&lt;std::string&gt;{\"beta0\", \"beta1\", \"sigma\",\n 350 :                 \"nuMinusOne\"};\n 351 :     if (emit_transformed_parameters__) {\n 352 :       std::vector&lt;std::string&gt; temp{\"nu\"};\n 353 :       names__.reserve(names__.size() + temp.size());\n 354 :       names__.insert(names__.end(), temp.begin(), temp.end());\n 355 :     }\n 356 :     if (emit_generated_quantities__) {}\n 357 :   }\n 358 :   inline void\n 359 :   get_dims(std::vector&lt;std::vector&lt;size_t&gt;&gt;& dimss__, const bool\n 360 :            emit_transformed_parameters__ = true, const bool\n 361 :            emit_generated_quantities__ = true) const {\n 362 :     dimss__ = std::vector&lt;std::vector&lt;size_t&gt;&gt;{std::vector&lt;size_t&gt;{},\n 363 :                 std::vector&lt;size_t&gt;{}, std::vector&lt;size_t&gt;{},\n 364 :                 std::vector&lt;size_t&gt;{}};\n 365 :     if (emit_transformed_parameters__) {\n 366 :       std::vector&lt;std::vector&lt;size_t&gt;&gt; temp{std::vector&lt;size_t&gt;{}};\n 367 :       dimss__.reserve(dimss__.size() + temp.size());\n 368 :       dimss__.insert(dimss__.end(), temp.begin(), temp.end());\n 369 :     }\n 370 :     if (emit_generated_quantities__) {}\n 371 :   }\n 372 :   inline void\n 373 :   constrained_param_names(std::vector&lt;std::string&gt;& param_names__, bool\n 374 :                           emit_transformed_parameters__ = true, bool\n 375 :                           emit_generated_quantities__ = true) const final {\n 376 :     param_names__.emplace_back(std::string() + \"beta0\");\n 377 :     param_names__.emplace_back(std::string() + \"beta1\");\n 378 :     param_names__.emplace_back(std::string() + \"sigma\");\n 379 :     param_names__.emplace_back(std::string() + \"nuMinusOne\");\n 380 :     if (emit_transformed_parameters__) {\n 381 :       param_names__.emplace_back(std::string() + \"nu\");\n 382 :     }\n 383 :     if (emit_generated_quantities__) {}\n 384 :   }\n 385 :   inline void\n 386 :   unconstrained_param_names(std::vector&lt;std::string&gt;& param_names__, bool\n 387 :                             emit_transformed_parameters__ = true, bool\n 388 :                             emit_generated_quantities__ = true) const final {\n 389 :     param_names__.emplace_back(std::string() + \"beta0\");\n 390 :     param_names__.emplace_back(std::string() + \"beta1\");\n 391 :     param_names__.emplace_back(std::string() + \"sigma\");\n 392 :     param_names__.emplace_back(std::string() + \"nuMinusOne\");\n 393 :     if (emit_transformed_parameters__) {\n 394 :       param_names__.emplace_back(std::string() + \"nu\");\n 395 :     }\n 396 :     if (emit_generated_quantities__) {}\n 397 :   }\n 398 :   inline std::string get_constrained_sizedtypes() const {\n 399 :     return std::string(\"[{\\\"name\\\":\\\"beta0\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta1\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"sigma\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nuMinusOne\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"}]\");\n 400 :   }\n 401 :   inline std::string get_unconstrained_sizedtypes() const {\n 402 :     return std::string(\"[{\\\"name\\\":\\\"beta0\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta1\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"sigma\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nuMinusOne\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"}]\");\n 403 :   }\n 404 :   // Begin method overload boilerplate\n 405 :   template &lt;typename RNG&gt; inline void\n 406 :   write_array(RNG& base_rng, Eigen::Matrix&lt;double,-1,1&gt;& params_r,\n 407 :               Eigen::Matrix&lt;double,-1,1&gt;& vars, const bool\n 408 :               emit_transformed_parameters = true, const bool\n 409 :               emit_generated_quantities = true, std::ostream*\n 410 :               pstream = nullptr) const {\n 411 :     const size_t num_params__ = (((1 + 1) + 1) + 1);\n 412 :     const size_t num_transformed = emit_transformed_parameters * (1);\n 413 :     const size_t num_gen_quantities = emit_generated_quantities * (0);\n 414 :     const size_t num_to_write = num_params__ + num_transformed +\n 415 :       num_gen_quantities;\n 416 :     std::vector&lt;int&gt; params_i;\n 417 :     vars = Eigen::Matrix&lt;double,-1,1&gt;::Constant(num_to_write,\n 418 :              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 419 :     write_array_impl(base_rng, params_r, params_i, vars,\n 420 :       emit_transformed_parameters, emit_generated_quantities, pstream);\n 421 :   }\n 422 :   template &lt;typename RNG&gt; inline void\n 423 :   write_array(RNG& base_rng, std::vector&lt;double&gt;& params_r, std::vector&lt;int&gt;&\n 424 :               params_i, std::vector&lt;double&gt;& vars, bool\n 425 :               emit_transformed_parameters = true, bool\n 426 :               emit_generated_quantities = true, std::ostream*\n 427 :               pstream = nullptr) const {\n 428 :     const size_t num_params__ = (((1 + 1) + 1) + 1);\n 429 :     const size_t num_transformed = emit_transformed_parameters * (1);\n 430 :     const size_t num_gen_quantities = emit_generated_quantities * (0);\n 431 :     const size_t num_to_write = num_params__ + num_transformed +\n 432 :       num_gen_quantities;\n 433 :     vars = std::vector&lt;double&gt;(num_to_write,\n 434 :              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 435 :     write_array_impl(base_rng, params_r, params_i, vars,\n 436 :       emit_transformed_parameters, emit_generated_quantities, pstream);\n 437 :   }\n 438 :   template &lt;bool propto__, bool jacobian__, typename T_&gt; inline T_\n 439 :   log_prob(Eigen::Matrix&lt;T_,-1,1&gt;& params_r, std::ostream* pstream = nullptr) const {\n 440 :     Eigen::Matrix&lt;int,-1,1&gt; params_i;\n 441 :     return log_prob_impl&lt;propto__, jacobian__&gt;(params_r, params_i, pstream);\n 442 :   }\n 443 :   template &lt;bool propto__, bool jacobian__, typename T_&gt; inline T_\n 444 :   log_prob(std::vector&lt;T_&gt;& params_r, std::vector&lt;int&gt;& params_i,\n 445 :            std::ostream* pstream = nullptr) const {\n 446 :     return log_prob_impl&lt;propto__, jacobian__&gt;(params_r, params_i, pstream);\n 447 :   }\n 448 :   inline void\n 449 :   transform_inits(const stan::io::var_context& context,\n 450 :                   Eigen::Matrix&lt;double,-1,1&gt;& params_r, std::ostream*\n 451 :                   pstream = nullptr) const final {\n 452 :     std::vector&lt;double&gt; params_r_vec(params_r.size());\n 453 :     std::vector&lt;int&gt; params_i;\n 454 :     transform_inits(context, params_i, params_r_vec, pstream);\n 455 :     params_r = Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(params_r_vec.data(),\n 456 :                  params_r_vec.size());\n 457 :   }\n 458 :   inline void\n 459 :   transform_inits(const stan::io::var_context& context, std::vector&lt;int&gt;&\n 460 :                   params_i, std::vector&lt;double&gt;& vars, std::ostream*\n 461 :                   pstream__ = nullptr) const {\n 462 :     vars.resize(num_params_r__);\n 463 :     transform_inits_impl(context, vars, pstream__);\n 464 :   }\n 465 :   inline void\n 466 :   unconstrain_array(const std::vector&lt;double&gt;& params_constrained,\n 467 :                     std::vector&lt;double&gt;& params_unconstrained, std::ostream*\n 468 :                     pstream = nullptr) const {\n 469 :     const std::vector&lt;int&gt; params_i;\n 470 :     params_unconstrained = std::vector&lt;double&gt;(num_params_r__,\n 471 :                              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 472 :     unconstrain_array_impl(params_constrained, params_i,\n 473 :       params_unconstrained, pstream);\n 474 :   }\n 475 :   inline void\n 476 :   unconstrain_array(const Eigen::Matrix&lt;double,-1,1&gt;& params_constrained,\n 477 :                     Eigen::Matrix&lt;double,-1,1&gt;& params_unconstrained,\n 478 :                     std::ostream* pstream = nullptr) const {\n 479 :     const std::vector&lt;int&gt; params_i;\n 480 :     params_unconstrained = Eigen::Matrix&lt;double,-1,1&gt;::Constant(num_params_r__,\n 481 :                              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 482 :     unconstrain_array_impl(params_constrained, params_i,\n 483 :       params_unconstrained, pstream);\n 484 :   }\n 485 : };\n 486 : }\n 487 : using stan_model = model1f47162ba74f__namespace::model1f47162ba74f_;\n 488 : #ifndef USING_R\n 489 : // Boilerplate\n 490 : stan::model::model_base&\n 491 : new_model(stan::io::var_context& data_context, unsigned int seed,\n 492 :           std::ostream* msg_stream) {\n 493 :   stan_model* m = new stan_model(data_context, seed, msg_stream);\n 494 :   return *m;\n 495 : }\n 496 : stan::math::profile_map& get_stan_profile_data() {\n 497 :   return model1f47162ba74f__namespace::profiles__;\n 498 : }\n 499 : #endif\n 500 : #endif\n 501 : \n 502 : RCPP_MODULE(stan_fit4model1f47162ba74f__mod) {\n 503 :   class_&lt;rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt; &gt;(\n 504 :       \"stan_fit4model1f47162ba74f_\")\n 505 : \n 506 :       .constructor&lt;SEXP, SEXP, SEXP&gt;()\n 507 : \n 508 :       .method(\n 509 :           \"call_sampler\",\n 510 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::call_sampler)\n 511 :       .method(\n 512 :           \"param_names\",\n 513 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::param_names)\n 514 :       .method(\"param_names_oi\",\n 515 :               &rstan::stan_fit&lt;stan_model,\n 516 :                                boost::random::ecuyer1988&gt;::param_names_oi)\n 517 :       .method(\"param_fnames_oi\",\n 518 :               &rstan::stan_fit&lt;stan_model,\n 519 :                                boost::random::ecuyer1988&gt;::param_fnames_oi)\n 520 :       .method(\n 521 :           \"param_dims\",\n 522 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::param_dims)\n 523 :       .method(\"param_dims_oi\",\n 524 :               &rstan::stan_fit&lt;stan_model,\n 525 :                                boost::random::ecuyer1988&gt;::param_dims_oi)\n 526 :       .method(\"update_param_oi\",\n 527 :               &rstan::stan_fit&lt;stan_model,\n 528 :                                boost::random::ecuyer1988&gt;::update_param_oi)\n 529 :       .method(\"param_oi_tidx\",\n 530 :               &rstan::stan_fit&lt;stan_model,\n 531 :                                boost::random::ecuyer1988&gt;::param_oi_tidx)\n 532 :       .method(\"grad_log_prob\",\n 533 :               &rstan::stan_fit&lt;stan_model,\n 534 :                                boost::random::ecuyer1988&gt;::grad_log_prob)\n 535 :       .method(\"log_prob\",\n 536 :               &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::log_prob)\n 537 :       .method(\"unconstrain_pars\",\n 538 :               &rstan::stan_fit&lt;stan_model,\n 539 :                                boost::random::ecuyer1988&gt;::unconstrain_pars)\n 540 :       .method(\"constrain_pars\",\n 541 :               &rstan::stan_fit&lt;stan_model,\n 542 :                                boost::random::ecuyer1988&gt;::constrain_pars)\n 543 :       .method(\n 544 :           \"num_pars_unconstrained\",\n 545 :           &rstan::stan_fit&lt;stan_model,\n 546 :                            boost::random::ecuyer1988&gt;::num_pars_unconstrained)\n 547 :       .method(\n 548 :           \"unconstrained_param_names\",\n 549 :           &rstan::stan_fit&lt;\n 550 :               stan_model, boost::random::ecuyer1988&gt;::unconstrained_param_names)\n 551 :       .method(\n 552 :           \"constrained_param_names\",\n 553 :           &rstan::stan_fit&lt;stan_model,\n 554 :                            boost::random::ecuyer1988&gt;::constrained_param_names)\n 555 :       .method(\"standalone_gqs\",\n 556 :               &rstan::stan_fit&lt;stan_model,\n 557 :                                boost::random::ecuyer1988&gt;::standalone_gqs);\n 558 : }\n 559 : \n 560 : \n 561 : // declarations\n 562 : extern \"C\" {\n 563 : SEXP file1f4759baef57( ) ;\n 564 : }\n 565 : \n 566 : // definition\n 567 : SEXP file1f4759baef57() {\n 568 :  return Rcpp::wrap(\"anon_model\");\n 569 : }\n\nmodelo_galton\n\nS4 class stanmodel 'anon_model' coded as follows:\n//\n// This Stan program defines a simple model, with a\n// vector of values 'y' modeled as normally distributed\n// with mean 'mu' and standard deviation 'sigma'.\n//\n// Learn more about model development with Stan at:\n//\n//    http://mc-stan.org/users/interfaces/rstan.html\n//    https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started\n//\n// The input data is a vector 'y' of length 'N'.\ndata {\n  int&lt;lower=0&gt; N;     // N es un entero no negativo\n  vector[N] y;          // y es un vector de longitud N de números reales\n  vector[N] x;          // x es un vector de longitud N de números reales\n}\n// The parameters accepted by the model. Our model\n// accepts two parameters 'mu' and 'sigma'.\nparameters {\n  real beta0;\n  real beta1;\n  real&lt;lower=0&gt; sigma;\n  real&lt;lower=0&gt; nuMinusOne;\n}\ntransformed parameters{\n  real&lt;lower=0&gt; nu;\n  nu = nuMinusOne + 1;\n}\n// The model to be estimated. We model the output\n// 'y' to be normally distributed with mean 'mu'\n// and standard deviation 'sigma'.\nmodel {\n  y ~ student_t(nu, beta0 + beta1 * x, sigma);\n  beta0 ~ normal(0, 100);\n  beta1 ~ normal(0, 4);\n  sigma ~ uniform(6.0 / 100.0, 6.0 * 100.0);\n  nuMinusOne ~ exponential(1/29.0);\n} \n\n\nY ajustamos el modelo:\n\nlibrary(rstan)\ngalton_stanfit &lt;-\n  sampling(\n    modelo_galton,\n    data = list(\n      N = nrow(GaltonW),\n      x = GaltonW$midparent,\n      y = GaltonW$height\n    ),\n    chains = 4,\n    iter = 2000,\n    warmup = 1000\n  )  \n\nTen en cuenta que los parámetros de pendiente e intercepción siguen estando correlacionados en el posterior, pero esto no molesta a Stan de la manera en que molesta a JAGS.\n\ngalton_stanfit\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff\nbeta0        17.19    0.16  5.87    5.99   13.27   17.18   21.12   28.68  1392\nbeta1         0.70    0.00  0.09    0.53    0.64    0.70    0.76    0.87  1388\nsigma         1.94    0.00  0.13    1.69    1.86    1.94    2.03    2.19  1828\nnuMinusOne   36.37    0.64 28.76    6.47   15.99   27.81   48.33  111.69  1995\nnu           37.37    0.64 28.76    7.47   16.99   28.81   49.33  112.69  1995\nlp__       -257.49    0.04  1.43 -261.22 -258.15 -257.16 -256.46 -255.75  1285\n           Rhat\nbeta0         1\nbeta1         1\nsigma         1\nnuMinusOne    1\nnu            1\nlp__          1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:23:57 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\ngf_point(beta1 ~ beta0, data = posterior(galton_stanfit), alpha = 0.5)\n\n\n\n\n\n\n\n\n\nmcmc_combo(as.mcmc.list(galton_stanfit), \n           pars = c(\"beta0\", \"beta1\", \"sigma\", \"nu\"))\n\n\n\n\n\n\n\n\n\n\n6.2.5 Modelo con dos interceptos\nEn el ejemplo anterior, hemos trabajado solo con las mujeres, pero podemos construir un modelo que maneje hombres y mujeres al mismo tiempo. Uno de estos modelos es el modelo de “múltiples interceptos”. En este modelo, ambos grupos (hombres y mujeres) tendrán la misma pendiente, pero los interceptos pueden diferir.\n\nlibrary(rstan)\nset.seed(12345)\nmodelo_galton2 &lt;- stan_model(file = 'galton2.stan',verbose = T)\n\n\nTRANSLATING MODEL '' FROM Stan CODE TO C++ CODE NOW.\nOS: x86_64, linux-gnu; rstan: 2.32.5; Rcpp: 1.0.12; inline: 0.3.19 \n &gt;&gt; setting environment variables: \nPKG_LIBS =  '/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/rstan/lib//libStanServices.a' -L'/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/lib/' -lStanHeaders -L'/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppParallel/lib/' -ltbb \nPKG_CPPFLAGS =   -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/Rcpp/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppEigen/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppEigen/include/unsupported\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/BH/include\" -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/src/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/RcppParallel/include/\"  -I\"/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/rstan/include\" -DEIGEN_NO_DEBUG  -DBOOST_DISABLE_ASSERTS  -DBOOST_PENDING_INTEGER_LOG2_HPP  -DSTAN_THREADS  -DUSE_STANC3 -DSTRICT_R_HEADERS  -DBOOST_PHOENIX_NO_VARIADIC_EXPRESSION  -D_HAS_AUTO_PTR_ETC=0  -include '/home/luis/R/x86_64-redhat-linux-gnu-library/4.3/StanHeaders/include/stan/math/prim/fun/Eigen.hpp'  -D_REENTRANT -DRCPP_PARALLEL_USE_TBB=1 \n &gt;&gt; Program source :\n\n   1 : \n   2 : // includes from the plugin\n   3 : // [[Rcpp::plugins(cpp14)]]\n   4 : \n   5 : \n   6 : // user includes\n   7 : #include &lt;Rcpp.h&gt;\n   8 : using namespace Rcpp;\n   9 : #ifndef MODELS_HPP\n  10 : #define MODELS_HPP\n  11 : #define STAN__SERVICES__COMMAND_HPP\n  12 : #include &lt;rstan/rstaninc.hpp&gt;\n  13 : #ifndef USE_STANC3\n  14 : #define USE_STANC3\n  15 : #endif\n  16 : // Code generated by stanc v2.32.2\n  17 : #include &lt;stan/model/model_header.hpp&gt;\n  18 : namespace model1f476f9515fc__namespace {\n  19 : using stan::model::model_base_crtp;\n  20 : using namespace stan::math;\n  21 : stan::math::profile_map profiles__;\n  22 : static constexpr std::array&lt;const char*, 25&gt; locations_array__ =\n  23 :   {\" (found before start of program)\",\n  24 :   \" (in 'anon_model', line 21, column 2 to column 13)\",\n  25 :   \" (in 'anon_model', line 22, column 2 to column 13)\",\n  26 :   \" (in 'anon_model', line 23, column 2 to column 13)\",\n  27 :   \" (in 'anon_model', line 24, column 2 to column 22)\",\n  28 :   \" (in 'anon_model', line 25, column 2 to column 27)\",\n  29 :   \" (in 'anon_model', line 28, column 2 to column 24)\",\n  30 :   \" (in 'anon_model', line 29, column 2 to column 19)\",\n  31 :   \" (in 'anon_model', line 30, column 2 to column 22)\",\n  32 :   \" (in 'anon_model', line 31, column 2 to column 22)\",\n  33 :   \" (in 'anon_model', line 38, column 4 to column 69)\",\n  34 :   \" (in 'anon_model', line 37, column 17 to line 39, column 3)\",\n  35 :   \" (in 'anon_model', line 37, column 2 to line 39, column 3)\",\n  36 :   \" (in 'anon_model', line 40, column 2 to column 25)\",\n  37 :   \" (in 'anon_model', line 41, column 2 to column 23)\",\n  38 :   \" (in 'anon_model', line 42, column 2 to column 23)\",\n  39 :   \" (in 'anon_model', line 43, column 2 to column 44)\",\n  40 :   \" (in 'anon_model', line 44, column 2 to column 35)\",\n  41 :   \" (in 'anon_model', line 13, column 2 to column 17)\",\n  42 :   \" (in 'anon_model', line 14, column 9 to column 10)\",\n  43 :   \" (in 'anon_model', line 14, column 2 to column 14)\",\n  44 :   \" (in 'anon_model', line 15, column 9 to column 10)\",\n  45 :   \" (in 'anon_model', line 15, column 2 to column 14)\",\n  46 :   \" (in 'anon_model', line 16, column 17 to column 18)\",\n  47 :   \" (in 'anon_model', line 16, column 2 to column 20)\"};\n  48 : class model1f476f9515fc_ final : public model_base_crtp&lt;model1f476f9515fc_&gt; {\n  49 : private:\n  50 :   int N;\n  51 :   Eigen::Matrix&lt;double,-1,1&gt; y_data__;\n  52 :   Eigen::Matrix&lt;double,-1,1&gt; x_data__;\n  53 :   std::vector&lt;int&gt; g;\n  54 :   Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt; y{nullptr, 0};\n  55 :   Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt; x{nullptr, 0};\n  56 : public:\n  57 :   ~model1f476f9515fc_() {}\n  58 :   model1f476f9515fc_(stan::io::var_context& context__, unsigned int\n  59 :                      random_seed__ = 0, std::ostream* pstream__ = nullptr)\n  60 :       : model_base_crtp(0) {\n  61 :     int current_statement__ = 0;\n  62 :     using local_scalar_t__ = double;\n  63 :     boost::ecuyer1988 base_rng__ =\n  64 :       stan::services::util::create_rng(random_seed__, 0);\n  65 :     // suppress unused var warning\n  66 :     (void) base_rng__;\n  67 :     static constexpr const char* function__ =\n  68 :       \"model1f476f9515fc__namespace::model1f476f9515fc_\";\n  69 :     // suppress unused var warning\n  70 :     (void) function__;\n  71 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n  72 :     // suppress unused var warning\n  73 :     (void) DUMMY_VAR__;\n  74 :     try {\n  75 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n  76 :       pos__ = 1;\n  77 :       current_statement__ = 18;\n  78 :       context__.validate_dims(\"data initialization\", \"N\", \"int\",\n  79 :         std::vector&lt;size_t&gt;{});\n  80 :       N = std::numeric_limits&lt;int&gt;::min();\n  81 :       current_statement__ = 18;\n  82 :       N = context__.vals_i(\"N\")[(1 - 1)];\n  83 :       current_statement__ = 18;\n  84 :       stan::math::check_greater_or_equal(function__, \"N\", N, 0);\n  85 :       current_statement__ = 19;\n  86 :       stan::math::validate_non_negative_index(\"y\", \"N\", N);\n  87 :       current_statement__ = 20;\n  88 :       context__.validate_dims(\"data initialization\", \"y\", \"double\",\n  89 :         std::vector&lt;size_t&gt;{static_cast&lt;size_t&gt;(N)});\n  90 :       y_data__ = Eigen::Matrix&lt;double,-1,1&gt;::Constant(N,\n  91 :                    std::numeric_limits&lt;double&gt;::quiet_NaN());\n  92 :       new (&y) Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(y_data__.data(), N);\n  93 :       {\n  94 :         std::vector&lt;local_scalar_t__&gt; y_flat__;\n  95 :         current_statement__ = 20;\n  96 :         y_flat__ = context__.vals_r(\"y\");\n  97 :         current_statement__ = 20;\n  98 :         pos__ = 1;\n  99 :         current_statement__ = 20;\n 100 :         for (int sym1__ = 1; sym1__ &lt;= N; ++sym1__) {\n 101 :           current_statement__ = 20;\n 102 :           stan::model::assign(y, y_flat__[(pos__ - 1)],\n 103 :             \"assigning variable y\", stan::model::index_uni(sym1__));\n 104 :           current_statement__ = 20;\n 105 :           pos__ = (pos__ + 1);\n 106 :         }\n 107 :       }\n 108 :       current_statement__ = 21;\n 109 :       stan::math::validate_non_negative_index(\"x\", \"N\", N);\n 110 :       current_statement__ = 22;\n 111 :       context__.validate_dims(\"data initialization\", \"x\", \"double\",\n 112 :         std::vector&lt;size_t&gt;{static_cast&lt;size_t&gt;(N)});\n 113 :       x_data__ = Eigen::Matrix&lt;double,-1,1&gt;::Constant(N,\n 114 :                    std::numeric_limits&lt;double&gt;::quiet_NaN());\n 115 :       new (&x) Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(x_data__.data(), N);\n 116 :       {\n 117 :         std::vector&lt;local_scalar_t__&gt; x_flat__;\n 118 :         current_statement__ = 22;\n 119 :         x_flat__ = context__.vals_r(\"x\");\n 120 :         current_statement__ = 22;\n 121 :         pos__ = 1;\n 122 :         current_statement__ = 22;\n 123 :         for (int sym1__ = 1; sym1__ &lt;= N; ++sym1__) {\n 124 :           current_statement__ = 22;\n 125 :           stan::model::assign(x, x_flat__[(pos__ - 1)],\n 126 :             \"assigning variable x\", stan::model::index_uni(sym1__));\n 127 :           current_statement__ = 22;\n 128 :           pos__ = (pos__ + 1);\n 129 :         }\n 130 :       }\n 131 :       current_statement__ = 23;\n 132 :       stan::math::validate_non_negative_index(\"g\", \"N\", N);\n 133 :       current_statement__ = 24;\n 134 :       context__.validate_dims(\"data initialization\", \"g\", \"int\",\n 135 :         std::vector&lt;size_t&gt;{static_cast&lt;size_t&gt;(N)});\n 136 :       g = std::vector&lt;int&gt;(N, std::numeric_limits&lt;int&gt;::min());\n 137 :       current_statement__ = 24;\n 138 :       g = context__.vals_i(\"g\");\n 139 :       current_statement__ = 24;\n 140 :       stan::math::check_greater_or_equal(function__, \"g\", g, 0);\n 141 :     } catch (const std::exception& e) {\n 142 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 143 :     }\n 144 :     num_params_r__ = 1 + 1 + 1 + 1 + 1;\n 145 :   }\n 146 :   inline std::string model_name() const final {\n 147 :     return \"model1f476f9515fc_\";\n 148 :   }\n 149 :   inline std::vector&lt;std::string&gt; model_compile_info() const noexcept {\n 150 :     return std::vector&lt;std::string&gt;{\"stanc_version = stanc3 v2.32.2\",\n 151 :              \"stancflags = --\"};\n 152 :   }\n 153 :   template &lt;bool propto__, bool jacobian__, typename VecR, typename VecI,\n 154 :             stan::require_vector_like_t&lt;VecR&gt;* = nullptr,\n 155 :             stan::require_vector_like_vt&lt;std::is_integral, VecI&gt;* = nullptr&gt;\n 156 :   inline stan::scalar_type_t&lt;VecR&gt;\n 157 :   log_prob_impl(VecR& params_r__, VecI& params_i__, std::ostream*\n 158 :                 pstream__ = nullptr) const {\n 159 :     using T__ = stan::scalar_type_t&lt;VecR&gt;;\n 160 :     using local_scalar_t__ = T__;\n 161 :     T__ lp__(0.0);\n 162 :     stan::math::accumulator&lt;T__&gt; lp_accum__;\n 163 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 164 :     int current_statement__ = 0;\n 165 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 166 :     // suppress unused var warning\n 167 :     (void) DUMMY_VAR__;\n 168 :     static constexpr const char* function__ =\n 169 :       \"model1f476f9515fc__namespace::log_prob\";\n 170 :     // suppress unused var warning\n 171 :     (void) function__;\n 172 :     try {\n 173 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 174 :       current_statement__ = 1;\n 175 :       beta0 = in__.template read&lt;local_scalar_t__&gt;();\n 176 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 177 :       current_statement__ = 2;\n 178 :       beta1 = in__.template read&lt;local_scalar_t__&gt;();\n 179 :       local_scalar_t__ beta2 = DUMMY_VAR__;\n 180 :       current_statement__ = 3;\n 181 :       beta2 = in__.template read&lt;local_scalar_t__&gt;();\n 182 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 183 :       current_statement__ = 4;\n 184 :       sigma = in__.template read_constrain_lb&lt;local_scalar_t__,\n 185 :                 jacobian__&gt;(0, lp__);\n 186 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 187 :       current_statement__ = 5;\n 188 :       nuMinusOne = in__.template read_constrain_lb&lt;local_scalar_t__,\n 189 :                      jacobian__&gt;(0, lp__);\n 190 :       local_scalar_t__ log10nu = DUMMY_VAR__;\n 191 :       local_scalar_t__ nu = DUMMY_VAR__;\n 192 :       current_statement__ = 8;\n 193 :       nu = (nuMinusOne + 1);\n 194 :       current_statement__ = 9;\n 195 :       log10nu = stan::math::log10(nu);\n 196 :       current_statement__ = 6;\n 197 :       stan::math::check_greater_or_equal(function__, \"log10nu\", log10nu, 0);\n 198 :       current_statement__ = 7;\n 199 :       stan::math::check_greater_or_equal(function__, \"nu\", nu, 0);\n 200 :       {\n 201 :         current_statement__ = 12;\n 202 :         for (int i = 1; i &lt;= N; ++i) {\n 203 :           current_statement__ = 10;\n 204 :           lp_accum__.add(stan::math::student_t_lpdf&lt;propto__&gt;(\n 205 :                            stan::model::rvalue(y, \"y\",\n 206 :                              stan::model::index_uni(i)), nu, ((beta0 + (beta1\n 207 :                            *\n 208 :                            stan::model::rvalue(x, \"x\",\n 209 :                              stan::model::index_uni(i)))) + (beta2 *\n 210 :                            stan::model::rvalue(g, \"g\",\n 211 :                              stan::model::index_uni(i)))), sigma));\n 212 :         }\n 213 :         current_statement__ = 13;\n 214 :         lp_accum__.add(stan::math::normal_lpdf&lt;propto__&gt;(beta0, 0, 100));\n 215 :         current_statement__ = 14;\n 216 :         lp_accum__.add(stan::math::normal_lpdf&lt;propto__&gt;(beta1, 0, 4));\n 217 :         current_statement__ = 15;\n 218 :         lp_accum__.add(stan::math::normal_lpdf&lt;propto__&gt;(beta2, 0, 4));\n 219 :         current_statement__ = 16;\n 220 :         lp_accum__.add(stan::math::uniform_lpdf&lt;propto__&gt;(sigma, (6.0 /\n 221 :                          100.0), (6.0 * 100.0)));\n 222 :         current_statement__ = 17;\n 223 :         lp_accum__.add(stan::math::exponential_lpdf&lt;propto__&gt;(nuMinusOne, (1\n 224 :                          / 29.0)));\n 225 :       }\n 226 :     } catch (const std::exception& e) {\n 227 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 228 :     }\n 229 :     lp_accum__.add(lp__);\n 230 :     return lp_accum__.sum();\n 231 :   }\n 232 :   template &lt;typename RNG, typename VecR, typename VecI, typename VecVar,\n 233 :             stan::require_vector_like_vt&lt;std::is_floating_point,\n 234 :             VecR&gt;* = nullptr, stan::require_vector_like_vt&lt;std::is_integral,\n 235 :             VecI&gt;* = nullptr, stan::require_vector_vt&lt;std::is_floating_point,\n 236 :             VecVar&gt;* = nullptr&gt;\n 237 :   inline void\n 238 :   write_array_impl(RNG& base_rng__, VecR& params_r__, VecI& params_i__,\n 239 :                    VecVar& vars__, const bool\n 240 :                    emit_transformed_parameters__ = true, const bool\n 241 :                    emit_generated_quantities__ = true, std::ostream*\n 242 :                    pstream__ = nullptr) const {\n 243 :     using local_scalar_t__ = double;\n 244 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 245 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 246 :     static constexpr bool propto__ = true;\n 247 :     // suppress unused var warning\n 248 :     (void) propto__;\n 249 :     double lp__ = 0.0;\n 250 :     // suppress unused var warning\n 251 :     (void) lp__;\n 252 :     int current_statement__ = 0;\n 253 :     stan::math::accumulator&lt;double&gt; lp_accum__;\n 254 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 255 :     // suppress unused var warning\n 256 :     (void) DUMMY_VAR__;\n 257 :     constexpr bool jacobian__ = false;\n 258 :     static constexpr const char* function__ =\n 259 :       \"model1f476f9515fc__namespace::write_array\";\n 260 :     // suppress unused var warning\n 261 :     (void) function__;\n 262 :     try {\n 263 :       double beta0 = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 264 :       current_statement__ = 1;\n 265 :       beta0 = in__.template read&lt;local_scalar_t__&gt;();\n 266 :       double beta1 = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 267 :       current_statement__ = 2;\n 268 :       beta1 = in__.template read&lt;local_scalar_t__&gt;();\n 269 :       double beta2 = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 270 :       current_statement__ = 3;\n 271 :       beta2 = in__.template read&lt;local_scalar_t__&gt;();\n 272 :       double sigma = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 273 :       current_statement__ = 4;\n 274 :       sigma = in__.template read_constrain_lb&lt;local_scalar_t__,\n 275 :                 jacobian__&gt;(0, lp__);\n 276 :       double nuMinusOne = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 277 :       current_statement__ = 5;\n 278 :       nuMinusOne = in__.template read_constrain_lb&lt;local_scalar_t__,\n 279 :                      jacobian__&gt;(0, lp__);\n 280 :       double log10nu = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 281 :       double nu = std::numeric_limits&lt;double&gt;::quiet_NaN();\n 282 :       out__.write(beta0);\n 283 :       out__.write(beta1);\n 284 :       out__.write(beta2);\n 285 :       out__.write(sigma);\n 286 :       out__.write(nuMinusOne);\n 287 :       if (stan::math::logical_negation(\n 288 :             (stan::math::primitive_value(emit_transformed_parameters__) ||\n 289 :             stan::math::primitive_value(emit_generated_quantities__)))) {\n 290 :         return ;\n 291 :       }\n 292 :       current_statement__ = 8;\n 293 :       nu = (nuMinusOne + 1);\n 294 :       current_statement__ = 9;\n 295 :       log10nu = stan::math::log10(nu);\n 296 :       current_statement__ = 6;\n 297 :       stan::math::check_greater_or_equal(function__, \"log10nu\", log10nu, 0);\n 298 :       current_statement__ = 7;\n 299 :       stan::math::check_greater_or_equal(function__, \"nu\", nu, 0);\n 300 :       if (emit_transformed_parameters__) {\n 301 :         out__.write(log10nu);\n 302 :         out__.write(nu);\n 303 :       }\n 304 :       if (stan::math::logical_negation(emit_generated_quantities__)) {\n 305 :         return ;\n 306 :       }\n 307 :     } catch (const std::exception& e) {\n 308 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 309 :     }\n 310 :   }\n 311 :   template &lt;typename VecVar, typename VecI,\n 312 :             stan::require_vector_t&lt;VecVar&gt;* = nullptr,\n 313 :             stan::require_vector_like_vt&lt;std::is_integral, VecI&gt;* = nullptr&gt;\n 314 :   inline void\n 315 :   unconstrain_array_impl(const VecVar& params_r__, const VecI& params_i__,\n 316 :                          VecVar& vars__, std::ostream* pstream__ = nullptr) const {\n 317 :     using local_scalar_t__ = double;\n 318 :     stan::io::deserializer&lt;local_scalar_t__&gt; in__(params_r__, params_i__);\n 319 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 320 :     int current_statement__ = 0;\n 321 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 322 :     // suppress unused var warning\n 323 :     (void) DUMMY_VAR__;\n 324 :     try {\n 325 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n 326 :       pos__ = 1;\n 327 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 328 :       current_statement__ = 1;\n 329 :       beta0 = in__.read&lt;local_scalar_t__&gt;();\n 330 :       out__.write(beta0);\n 331 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 332 :       current_statement__ = 2;\n 333 :       beta1 = in__.read&lt;local_scalar_t__&gt;();\n 334 :       out__.write(beta1);\n 335 :       local_scalar_t__ beta2 = DUMMY_VAR__;\n 336 :       current_statement__ = 3;\n 337 :       beta2 = in__.read&lt;local_scalar_t__&gt;();\n 338 :       out__.write(beta2);\n 339 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 340 :       current_statement__ = 4;\n 341 :       sigma = in__.read&lt;local_scalar_t__&gt;();\n 342 :       out__.write_free_lb(0, sigma);\n 343 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 344 :       current_statement__ = 5;\n 345 :       nuMinusOne = in__.read&lt;local_scalar_t__&gt;();\n 346 :       out__.write_free_lb(0, nuMinusOne);\n 347 :     } catch (const std::exception& e) {\n 348 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 349 :     }\n 350 :   }\n 351 :   template &lt;typename VecVar, stan::require_vector_t&lt;VecVar&gt;* = nullptr&gt;\n 352 :   inline void\n 353 :   transform_inits_impl(const stan::io::var_context& context__, VecVar&\n 354 :                        vars__, std::ostream* pstream__ = nullptr) const {\n 355 :     using local_scalar_t__ = double;\n 356 :     stan::io::serializer&lt;local_scalar_t__&gt; out__(vars__);\n 357 :     int current_statement__ = 0;\n 358 :     local_scalar_t__ DUMMY_VAR__(std::numeric_limits&lt;double&gt;::quiet_NaN());\n 359 :     // suppress unused var warning\n 360 :     (void) DUMMY_VAR__;\n 361 :     try {\n 362 :       current_statement__ = 1;\n 363 :       context__.validate_dims(\"parameter initialization\", \"beta0\", \"double\",\n 364 :         std::vector&lt;size_t&gt;{});\n 365 :       current_statement__ = 2;\n 366 :       context__.validate_dims(\"parameter initialization\", \"beta1\", \"double\",\n 367 :         std::vector&lt;size_t&gt;{});\n 368 :       current_statement__ = 3;\n 369 :       context__.validate_dims(\"parameter initialization\", \"beta2\", \"double\",\n 370 :         std::vector&lt;size_t&gt;{});\n 371 :       current_statement__ = 4;\n 372 :       context__.validate_dims(\"parameter initialization\", \"sigma\", \"double\",\n 373 :         std::vector&lt;size_t&gt;{});\n 374 :       current_statement__ = 5;\n 375 :       context__.validate_dims(\"parameter initialization\", \"nuMinusOne\",\n 376 :         \"double\", std::vector&lt;size_t&gt;{});\n 377 :       int pos__ = std::numeric_limits&lt;int&gt;::min();\n 378 :       pos__ = 1;\n 379 :       local_scalar_t__ beta0 = DUMMY_VAR__;\n 380 :       current_statement__ = 1;\n 381 :       beta0 = context__.vals_r(\"beta0\")[(1 - 1)];\n 382 :       out__.write(beta0);\n 383 :       local_scalar_t__ beta1 = DUMMY_VAR__;\n 384 :       current_statement__ = 2;\n 385 :       beta1 = context__.vals_r(\"beta1\")[(1 - 1)];\n 386 :       out__.write(beta1);\n 387 :       local_scalar_t__ beta2 = DUMMY_VAR__;\n 388 :       current_statement__ = 3;\n 389 :       beta2 = context__.vals_r(\"beta2\")[(1 - 1)];\n 390 :       out__.write(beta2);\n 391 :       local_scalar_t__ sigma = DUMMY_VAR__;\n 392 :       current_statement__ = 4;\n 393 :       sigma = context__.vals_r(\"sigma\")[(1 - 1)];\n 394 :       out__.write_free_lb(0, sigma);\n 395 :       local_scalar_t__ nuMinusOne = DUMMY_VAR__;\n 396 :       current_statement__ = 5;\n 397 :       nuMinusOne = context__.vals_r(\"nuMinusOne\")[(1 - 1)];\n 398 :       out__.write_free_lb(0, nuMinusOne);\n 399 :     } catch (const std::exception& e) {\n 400 :       stan::lang::rethrow_located(e, locations_array__[current_statement__]);\n 401 :     }\n 402 :   }\n 403 :   inline void\n 404 :   get_param_names(std::vector&lt;std::string&gt;& names__, const bool\n 405 :                   emit_transformed_parameters__ = true, const bool\n 406 :                   emit_generated_quantities__ = true) const {\n 407 :     names__ = std::vector&lt;std::string&gt;{\"beta0\", \"beta1\", \"beta2\", \"sigma\",\n 408 :                 \"nuMinusOne\"};\n 409 :     if (emit_transformed_parameters__) {\n 410 :       std::vector&lt;std::string&gt; temp{\"log10nu\", \"nu\"};\n 411 :       names__.reserve(names__.size() + temp.size());\n 412 :       names__.insert(names__.end(), temp.begin(), temp.end());\n 413 :     }\n 414 :     if (emit_generated_quantities__) {}\n 415 :   }\n 416 :   inline void\n 417 :   get_dims(std::vector&lt;std::vector&lt;size_t&gt;&gt;& dimss__, const bool\n 418 :            emit_transformed_parameters__ = true, const bool\n 419 :            emit_generated_quantities__ = true) const {\n 420 :     dimss__ = std::vector&lt;std::vector&lt;size_t&gt;&gt;{std::vector&lt;size_t&gt;{},\n 421 :                 std::vector&lt;size_t&gt;{}, std::vector&lt;size_t&gt;{},\n 422 :                 std::vector&lt;size_t&gt;{}, std::vector&lt;size_t&gt;{}};\n 423 :     if (emit_transformed_parameters__) {\n 424 :       std::vector&lt;std::vector&lt;size_t&gt;&gt;\n 425 :         temp{std::vector&lt;size_t&gt;{}, std::vector&lt;size_t&gt;{}};\n 426 :       dimss__.reserve(dimss__.size() + temp.size());\n 427 :       dimss__.insert(dimss__.end(), temp.begin(), temp.end());\n 428 :     }\n 429 :     if (emit_generated_quantities__) {}\n 430 :   }\n 431 :   inline void\n 432 :   constrained_param_names(std::vector&lt;std::string&gt;& param_names__, bool\n 433 :                           emit_transformed_parameters__ = true, bool\n 434 :                           emit_generated_quantities__ = true) const final {\n 435 :     param_names__.emplace_back(std::string() + \"beta0\");\n 436 :     param_names__.emplace_back(std::string() + \"beta1\");\n 437 :     param_names__.emplace_back(std::string() + \"beta2\");\n 438 :     param_names__.emplace_back(std::string() + \"sigma\");\n 439 :     param_names__.emplace_back(std::string() + \"nuMinusOne\");\n 440 :     if (emit_transformed_parameters__) {\n 441 :       param_names__.emplace_back(std::string() + \"log10nu\");\n 442 :       param_names__.emplace_back(std::string() + \"nu\");\n 443 :     }\n 444 :     if (emit_generated_quantities__) {}\n 445 :   }\n 446 :   inline void\n 447 :   unconstrained_param_names(std::vector&lt;std::string&gt;& param_names__, bool\n 448 :                             emit_transformed_parameters__ = true, bool\n 449 :                             emit_generated_quantities__ = true) const final {\n 450 :     param_names__.emplace_back(std::string() + \"beta0\");\n 451 :     param_names__.emplace_back(std::string() + \"beta1\");\n 452 :     param_names__.emplace_back(std::string() + \"beta2\");\n 453 :     param_names__.emplace_back(std::string() + \"sigma\");\n 454 :     param_names__.emplace_back(std::string() + \"nuMinusOne\");\n 455 :     if (emit_transformed_parameters__) {\n 456 :       param_names__.emplace_back(std::string() + \"log10nu\");\n 457 :       param_names__.emplace_back(std::string() + \"nu\");\n 458 :     }\n 459 :     if (emit_generated_quantities__) {}\n 460 :   }\n 461 :   inline std::string get_constrained_sizedtypes() const {\n 462 :     return std::string(\"[{\\\"name\\\":\\\"beta0\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta1\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta2\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"sigma\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nuMinusOne\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"log10nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"},{\\\"name\\\":\\\"nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"}]\");\n 463 :   }\n 464 :   inline std::string get_unconstrained_sizedtypes() const {\n 465 :     return std::string(\"[{\\\"name\\\":\\\"beta0\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta1\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"beta2\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"sigma\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"nuMinusOne\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"parameters\\\"},{\\\"name\\\":\\\"log10nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"},{\\\"name\\\":\\\"nu\\\",\\\"type\\\":{\\\"name\\\":\\\"real\\\"},\\\"block\\\":\\\"transformed_parameters\\\"}]\");\n 466 :   }\n 467 :   // Begin method overload boilerplate\n 468 :   template &lt;typename RNG&gt; inline void\n 469 :   write_array(RNG& base_rng, Eigen::Matrix&lt;double,-1,1&gt;& params_r,\n 470 :               Eigen::Matrix&lt;double,-1,1&gt;& vars, const bool\n 471 :               emit_transformed_parameters = true, const bool\n 472 :               emit_generated_quantities = true, std::ostream*\n 473 :               pstream = nullptr) const {\n 474 :     const size_t num_params__ = ((((1 + 1) + 1) + 1) + 1);\n 475 :     const size_t num_transformed = emit_transformed_parameters * ((1 + 1));\n 476 :     const size_t num_gen_quantities = emit_generated_quantities * (0);\n 477 :     const size_t num_to_write = num_params__ + num_transformed +\n 478 :       num_gen_quantities;\n 479 :     std::vector&lt;int&gt; params_i;\n 480 :     vars = Eigen::Matrix&lt;double,-1,1&gt;::Constant(num_to_write,\n 481 :              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 482 :     write_array_impl(base_rng, params_r, params_i, vars,\n 483 :       emit_transformed_parameters, emit_generated_quantities, pstream);\n 484 :   }\n 485 :   template &lt;typename RNG&gt; inline void\n 486 :   write_array(RNG& base_rng, std::vector&lt;double&gt;& params_r, std::vector&lt;int&gt;&\n 487 :               params_i, std::vector&lt;double&gt;& vars, bool\n 488 :               emit_transformed_parameters = true, bool\n 489 :               emit_generated_quantities = true, std::ostream*\n 490 :               pstream = nullptr) const {\n 491 :     const size_t num_params__ = ((((1 + 1) + 1) + 1) + 1);\n 492 :     const size_t num_transformed = emit_transformed_parameters * ((1 + 1));\n 493 :     const size_t num_gen_quantities = emit_generated_quantities * (0);\n 494 :     const size_t num_to_write = num_params__ + num_transformed +\n 495 :       num_gen_quantities;\n 496 :     vars = std::vector&lt;double&gt;(num_to_write,\n 497 :              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 498 :     write_array_impl(base_rng, params_r, params_i, vars,\n 499 :       emit_transformed_parameters, emit_generated_quantities, pstream);\n 500 :   }\n 501 :   template &lt;bool propto__, bool jacobian__, typename T_&gt; inline T_\n 502 :   log_prob(Eigen::Matrix&lt;T_,-1,1&gt;& params_r, std::ostream* pstream = nullptr) const {\n 503 :     Eigen::Matrix&lt;int,-1,1&gt; params_i;\n 504 :     return log_prob_impl&lt;propto__, jacobian__&gt;(params_r, params_i, pstream);\n 505 :   }\n 506 :   template &lt;bool propto__, bool jacobian__, typename T_&gt; inline T_\n 507 :   log_prob(std::vector&lt;T_&gt;& params_r, std::vector&lt;int&gt;& params_i,\n 508 :            std::ostream* pstream = nullptr) const {\n 509 :     return log_prob_impl&lt;propto__, jacobian__&gt;(params_r, params_i, pstream);\n 510 :   }\n 511 :   inline void\n 512 :   transform_inits(const stan::io::var_context& context,\n 513 :                   Eigen::Matrix&lt;double,-1,1&gt;& params_r, std::ostream*\n 514 :                   pstream = nullptr) const final {\n 515 :     std::vector&lt;double&gt; params_r_vec(params_r.size());\n 516 :     std::vector&lt;int&gt; params_i;\n 517 :     transform_inits(context, params_i, params_r_vec, pstream);\n 518 :     params_r = Eigen::Map&lt;Eigen::Matrix&lt;double,-1,1&gt;&gt;(params_r_vec.data(),\n 519 :                  params_r_vec.size());\n 520 :   }\n 521 :   inline void\n 522 :   transform_inits(const stan::io::var_context& context, std::vector&lt;int&gt;&\n 523 :                   params_i, std::vector&lt;double&gt;& vars, std::ostream*\n 524 :                   pstream__ = nullptr) const {\n 525 :     vars.resize(num_params_r__);\n 526 :     transform_inits_impl(context, vars, pstream__);\n 527 :   }\n 528 :   inline void\n 529 :   unconstrain_array(const std::vector&lt;double&gt;& params_constrained,\n 530 :                     std::vector&lt;double&gt;& params_unconstrained, std::ostream*\n 531 :                     pstream = nullptr) const {\n 532 :     const std::vector&lt;int&gt; params_i;\n 533 :     params_unconstrained = std::vector&lt;double&gt;(num_params_r__,\n 534 :                              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 535 :     unconstrain_array_impl(params_constrained, params_i,\n 536 :       params_unconstrained, pstream);\n 537 :   }\n 538 :   inline void\n 539 :   unconstrain_array(const Eigen::Matrix&lt;double,-1,1&gt;& params_constrained,\n 540 :                     Eigen::Matrix&lt;double,-1,1&gt;& params_unconstrained,\n 541 :                     std::ostream* pstream = nullptr) const {\n 542 :     const std::vector&lt;int&gt; params_i;\n 543 :     params_unconstrained = Eigen::Matrix&lt;double,-1,1&gt;::Constant(num_params_r__,\n 544 :                              std::numeric_limits&lt;double&gt;::quiet_NaN());\n 545 :     unconstrain_array_impl(params_constrained, params_i,\n 546 :       params_unconstrained, pstream);\n 547 :   }\n 548 : };\n 549 : }\n 550 : using stan_model = model1f476f9515fc__namespace::model1f476f9515fc_;\n 551 : #ifndef USING_R\n 552 : // Boilerplate\n 553 : stan::model::model_base&\n 554 : new_model(stan::io::var_context& data_context, unsigned int seed,\n 555 :           std::ostream* msg_stream) {\n 556 :   stan_model* m = new stan_model(data_context, seed, msg_stream);\n 557 :   return *m;\n 558 : }\n 559 : stan::math::profile_map& get_stan_profile_data() {\n 560 :   return model1f476f9515fc__namespace::profiles__;\n 561 : }\n 562 : #endif\n 563 : #endif\n 564 : \n 565 : RCPP_MODULE(stan_fit4model1f476f9515fc__mod) {\n 566 :   class_&lt;rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt; &gt;(\n 567 :       \"stan_fit4model1f476f9515fc_\")\n 568 : \n 569 :       .constructor&lt;SEXP, SEXP, SEXP&gt;()\n 570 : \n 571 :       .method(\n 572 :           \"call_sampler\",\n 573 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::call_sampler)\n 574 :       .method(\n 575 :           \"param_names\",\n 576 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::param_names)\n 577 :       .method(\"param_names_oi\",\n 578 :               &rstan::stan_fit&lt;stan_model,\n 579 :                                boost::random::ecuyer1988&gt;::param_names_oi)\n 580 :       .method(\"param_fnames_oi\",\n 581 :               &rstan::stan_fit&lt;stan_model,\n 582 :                                boost::random::ecuyer1988&gt;::param_fnames_oi)\n 583 :       .method(\n 584 :           \"param_dims\",\n 585 :           &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::param_dims)\n 586 :       .method(\"param_dims_oi\",\n 587 :               &rstan::stan_fit&lt;stan_model,\n 588 :                                boost::random::ecuyer1988&gt;::param_dims_oi)\n 589 :       .method(\"update_param_oi\",\n 590 :               &rstan::stan_fit&lt;stan_model,\n 591 :                                boost::random::ecuyer1988&gt;::update_param_oi)\n 592 :       .method(\"param_oi_tidx\",\n 593 :               &rstan::stan_fit&lt;stan_model,\n 594 :                                boost::random::ecuyer1988&gt;::param_oi_tidx)\n 595 :       .method(\"grad_log_prob\",\n 596 :               &rstan::stan_fit&lt;stan_model,\n 597 :                                boost::random::ecuyer1988&gt;::grad_log_prob)\n 598 :       .method(\"log_prob\",\n 599 :               &rstan::stan_fit&lt;stan_model, boost::random::ecuyer1988&gt;::log_prob)\n 600 :       .method(\"unconstrain_pars\",\n 601 :               &rstan::stan_fit&lt;stan_model,\n 602 :                                boost::random::ecuyer1988&gt;::unconstrain_pars)\n 603 :       .method(\"constrain_pars\",\n 604 :               &rstan::stan_fit&lt;stan_model,\n 605 :                                boost::random::ecuyer1988&gt;::constrain_pars)\n 606 :       .method(\n 607 :           \"num_pars_unconstrained\",\n 608 :           &rstan::stan_fit&lt;stan_model,\n 609 :                            boost::random::ecuyer1988&gt;::num_pars_unconstrained)\n 610 :       .method(\n 611 :           \"unconstrained_param_names\",\n 612 :           &rstan::stan_fit&lt;\n 613 :               stan_model, boost::random::ecuyer1988&gt;::unconstrained_param_names)\n 614 :       .method(\n 615 :           \"constrained_param_names\",\n 616 :           &rstan::stan_fit&lt;stan_model,\n 617 :                            boost::random::ecuyer1988&gt;::constrained_param_names)\n 618 :       .method(\"standalone_gqs\",\n 619 :               &rstan::stan_fit&lt;stan_model,\n 620 :                                boost::random::ecuyer1988&gt;::standalone_gqs);\n 621 : }\n 622 : \n 623 : \n 624 : // declarations\n 625 : extern \"C\" {\n 626 : SEXP file1f471a3afc56( ) ;\n 627 : }\n 628 : \n 629 : // definition\n 630 : SEXP file1f471a3afc56() {\n 631 :  return Rcpp::wrap(\"anon_model\");\n 632 : }\n\nGaltonBoth &lt;- mosaicData::Galton %&gt;% \n  mutate(midparent = (father + mother)/2,\n         group = as.numeric(factor(sex)) - 1) %&gt;%   # 0s y 1s\n  group_by(family) %&gt;% \n  sample_n(1)\n\ngalton2_stanfit &lt;-\n  sampling(\n    modelo_galton2,\n    data = list(\n      N = nrow(GaltonBoth),\n      x = GaltonBoth$midparent,\n      y = GaltonBoth$height,\n      g = GaltonBoth$group        # 0s y 1s\n    ),\n    chains = 4,\n    iter = 2000,\n    warmup = 1000\n  )  \n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 6.8e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.68 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 10.727 seconds (Warm-up)\nChain 1:                10.21 seconds (Sampling)\nChain 1:                20.937 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 6.8e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.68 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 9.988 seconds (Warm-up)\nChain 2:                10.272 seconds (Sampling)\nChain 2:                20.26 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 5.4e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.54 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 10.436 seconds (Warm-up)\nChain 3:                8.342 seconds (Sampling)\nChain 3:                18.778 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 5.6e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.56 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 10.717 seconds (Warm-up)\nChain 4:                10.258 seconds (Sampling)\nChain 4:                20.975 seconds (Total)\nChain 4: \n\n\n\ngalton2_stanfit\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n              mean se_mean    sd    2.5%     25%     50%     75%   97.5% n_eff\nbeta0        18.00    0.14  5.80    6.80   14.24   17.85   21.84   29.44  1712\nbeta1         0.69    0.00  0.09    0.52    0.63    0.69    0.75    0.86  1716\nbeta2         4.84    0.01  0.31    4.24    4.64    4.84    5.05    5.47  2762\nsigma         2.17    0.00  0.12    1.95    2.08    2.16    2.24    2.41  2567\nnuMinusOne   48.37    0.62 31.38   10.70   25.33   40.47   63.36  131.25  2564\nlog10nu       1.61    0.01  0.27    1.07    1.42    1.62    1.81    2.12  2188\nnu           49.37    0.62 31.38   11.70   26.33   41.47   64.36  132.25  2564\nlp__       -321.22    0.04  1.56 -324.97 -321.99 -320.89 -320.08 -319.19  1543\n           Rhat\nbeta0         1\nbeta1         1\nbeta2         1\nsigma         1\nnuMinusOne    1\nlog10nu       1\nnu            1\nlp__          1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:27:02 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\ngalton2_mcmc &lt;- as.mcmc.list(galton2_stanfit)\nPost_galton2 &lt;- posterior(galton2_stanfit)\nmcmc_combo(galton2_mcmc, regex_pars = c(\"beta\", \"sigma\", \"log10nu\"))\n\n\n\n\n\n\n\nplot_post(Post_galton2$beta2, xlab = \"beta2\", hdi_prob = 0.95)\n\n\n\n\n\n\n\n\n$posterior\n         ESS     mean   median    mode\nvar1 2689.49 4.842483 4.839496 4.78823\n\n$hdi\n  prob       lo       hi\n1 0.95 4.253709 5.470268\n\n\n\nmcmc_areas(galton2_mcmc, regex_pars = \"beta2\", prob = 0.95)\n\n\n\n\n\n\n\nmcmc_areas(galton2_mcmc, regex_pars = \"log10nu\", prob = 0.95)\n\n\n\n\n\n\n\n\n\nhead(GaltonBoth, 3) \n\n# A tibble: 3 × 8\n# Groups:   family [3]\n  family father mother sex   height nkids midparent group\n  &lt;fct&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;  &lt;dbl&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 1        78.5   67   F       69.2     4      72.8     0\n2 10       74     65.5 F       65.5     1      69.8     0\n3 100      69     66   M       71       3      67.5     1\n\nyind &lt;-\n  posterior_calc(\n    galton2_stanfit, \n    yind ~ beta0 + beta1 * midparent + beta2 * group + \n           rt(nrow(GaltonBoth), df = nu) * sigma,\n    data = GaltonBoth\n  )\nppc_intervals_grouped(\n  GaltonBoth$height, yind, group = GaltonBoth$sex, \n  x = GaltonBoth$midparent) \n\n\n\n\n\n\n\nppc_data &lt;-\n  ppc_intervals_data(\n  GaltonBoth$height, yind, group = GaltonBoth$sex, \n  x = GaltonBoth$midparent)\n\nglimpse(ppc_data)\n\nRows: 197\nColumns: 11\n$ y_id        &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,…\n$ y_obs       &lt;dbl&gt; 69.2, 65.5, 71.0, 68.5, 68.5, 61.0, 64.5, 68.5, 65.5, 65.5…\n$ group       &lt;fct&gt; F, F, M, M, M, F, F, F, F, F, F, F, M, M, F, M, F, M, F, F…\n$ x           &lt;dbl&gt; 72.75, 69.75, 67.50, 67.85, 67.50, 67.75, 68.00, 67.75, 67…\n$ outer_width &lt;dbl&gt; 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9…\n$ inner_width &lt;dbl&gt; 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5…\n$ ll          &lt;dbl&gt; 64.65196, 62.68861, 65.99708, 66.06591, 65.82074, 61.33906…\n$ l           &lt;dbl&gt; 66.83026, 64.79340, 68.09751, 68.28307, 68.08200, 63.43360…\n$ m           &lt;dbl&gt; 68.37563, 66.25828, 69.60212, 69.80352, 69.59443, 64.90686…\n$ h           &lt;dbl&gt; 69.98837, 67.80330, 71.07960, 71.33653, 71.10201, 66.42513…\n$ hh          &lt;dbl&gt; 72.26733, 69.97070, 73.30426, 73.58624, 73.37297, 68.64609…\n\ngf_ribbon(ll + hh ~ x, fill = ~ group, data = ppc_data) %&gt;%\n  gf_ribbon(l + h ~ x, fill = ~ group, data = ppc_data) %&gt;%\n  gf_point(y_obs ~ x, color =  ~ group, data = ppc_data) %&gt;%\n  gf_facet_grid(group ~ .)\n\n\n\n\n\n\n\n\nEntonces, ¿qué aprendemos de todos los resultados anteriores?\n\nLos diagnósticos sugieren que el modelo está convergiendo adecuadamente.\nLas comprobaciones de predicción posterior no muestran discrepancias importantes entre el modelo y los datos. (Por lo tanto, nuestra restricción de que las pendientes de las líneas sean iguales para hombres y mujeres parece estar bien).\nLa “distribución del ruido” parece estar bien aproximada con una distribución normal (La mayoría de la distribución posterior para \\(\\log_{10}(\\nu)\\) está por encima de 1.5.)\n\n\nhdi(posterior(galton2_stanfit), regex_pars = \"nu\", prob = 0.90)\n\n         par       lo        hi      mode prob\n1 nuMinusOne 7.761967 91.333268 22.897250  0.9\n2    log10nu 1.157328  2.051937  1.562134  0.9\n3         nu 8.761967 92.333268 23.897250  0.9\n\n\n\nLa nueva característica de este modelo es \\(\\beta_2\\), que cuantifica la diferencia en las alturas promedio de hombres y mujeres cuyos padres tienen las mismas alturas. Aquí está el HDI del 95% para \\(\\beta_2\\) (junto con la pendiente y el intercepto):\n\n\nhdi(posterior(galton2_stanfit), regex_pars = \"beta\")\n\n    par        lo         hi       mode prob\n1 beta0 7.4417524 29.9278400 14.6711459 0.95\n2 beta1 0.5277311  0.8643556  0.7419232 0.95\n3 beta2 4.2537094  5.4702680  4.7873137 0.95",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 2)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos2.html#regresión-lineal-múltiple",
    "href": "estimacion_modelos2.html#regresión-lineal-múltiple",
    "title": "6  Estimación de Modelos Bayesianos (Parte 2)",
    "section": "6.3 Regresión Lineal Múltiple",
    "text": "6.3 Regresión Lineal Múltiple\n\n6.3.1 Ejemplo: SAT\n¿Gastar más en educación resulta en puntajes SAT más altos? La prueba SAT es un examen estandarizado utilizado para la admisión a universidades en los Estados Unidos, que evalúa habilidades en lectura crítica, matemáticas y escritura. Datos de 1999 pueden usarse para explorar esta pregunta. Entre otras cosas, los datos incluyen el puntaje SAT promedio total (en una escala de 400 a 1600) y la cantidad de dinero gastado en educación (en miles de dólares por estudiante) en cada estado de Estados Unidos.\nComo primer intento, podríamos ajustar un modelo lineal (sat vs expend). Usando centrado, el núcleo del modelo se ve así:\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x))\n  }\nalpha1 mide cuánto mejora el rendimiento en el SAT por cada $1000 gastados en educación en un estado. Para ajustar el modelo, necesitamos priors para nuestros cuatro parámetros:\n\nnu: Podemos usar nuestro exponencial desplazado habitual.\nsigma: {Unif}(?, ?)\nalpha0: {Norm}(?, ?)\nalpha1: {Norm}(0, ?)\n\nLas interrogaciones dependen de la escala de nuestras covariables.\n\nsat_model &lt;- function() {\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- alpha0 + alpha1 * (x[i] - mean(x))\n  }\n  nuMinusOne ~ dexp(1/29.0)\n  nu        &lt;- nuMinusOne + 1\n  alpha0     ~ dnorm(alpha0mean, 1 / alpha0sd^2) \n  alpha1     ~ dnorm(0, 1 / alpha1sd^2)\n  sigma      ~ dunif(sigma_lo, sigma_hi * 1000)\n  log10nu   &lt;- log(nu) / log(10)    # log10(nu)\n  beta0     &lt;- alpha0 - mean(x) * alpha1          # intercepto verdadero\n}\n\nEntonces, ¿cómo llenamos los signos de interrogación para este conjunto de datos?\n\nsigma: {Unif}(?,?)\nEsto cuantifica la cantidad de variación de un estado a otro entre estados que tienen el mismo gasto por estudiante. La escala del SAT varía de 400 a 1600. Los promedios estatales no estarán cerca de los extremos de esta escala. Una ventana de 6 órdenes de magnitud alrededor de 1 da {Unif}(0.001, 1000), ambos extremos de los cuales están bastante lejos de lo que creemos razonable.\nalpha0: {Norm}(?, ?)\nalpha0 mide el puntaje SAT promedio para los estados que gastan una cantidad promedio. Dado que los SAT promedio están alrededor de 1000, algo como {Norm}(1000, 100) parece razonable.\nalpha1: {Norm}(0, ?)\nEste es el más complicado. La pendiente de una línea de regresión no puede ser mucho más que \\(\\frac{SD_y}{SD_x}\\), por lo que podemos estimar esa relación o calcularla a partir de nuestros datos para guiar nuestra elección de prior.\n\n\nsat_jags &lt;- \n  jags(\n    model = sat_model,\n    data = list(\n      y = SAT$sat,\n      x = SAT$expend,\n      alpha0mean = 1000,    # SAT scores are roughly 500 + 500\n      alpha0sd   = 100,     # broad prior on scale of 400 - 1600\n      alpha1sd   = 4 * sd(SAT$sat) / sd(SAT$expend),\n      sigma_lo = 0.001,     # 3 o.m. less than 1\n      sigma_hi = 1000       # 3 o.m. greater than 1\n    ),\n    parameters.to.save = c(\"nu\", \"log10nu\", \"alpha0\", \"beta0\", \"alpha1\", \"sigma\"),\n    n.iter   = 4000,\n    n.burnin = 1000,\n    n.chains = 3\n  ) \n\n\nsat_jags\n\nInference for Bugs model at \"/tmp/Rtmpff4QT1/model1f472c9bd743.txt\", fit using jags,\n 3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3\n n.sims = 3000 iterations saved\n          mu.vect sd.vect     2.5%      25%      50%      75%    97.5%  Rhat\nalpha0    966.242  10.209  946.097  959.521  966.020  972.944  986.428 1.001\nalpha1    -21.549   7.545  -36.480  -26.344  -21.595  -16.572   -6.669 1.001\nbeta0    1093.493  45.991 1002.139 1062.673 1092.818 1124.048 1185.625 1.002\nlog10nu     1.503   0.325    0.833    1.281    1.518    1.732    2.088 1.003\nnu         41.285  30.531    6.807   19.087   32.990   53.980  122.544 1.003\nsigma      70.124   7.998   56.089   64.395   69.584   75.396   87.097 1.001\ndeviance  568.593   2.710  565.317  566.633  567.943  569.892  575.463 1.001\n         n.eff\nalpha0    3000\nalpha1    2100\nbeta0     1900\nlog10nu    980\nnu         770\nsigma     3000\ndeviance  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 3.7 and DIC = 572.3\nDIC is an estimate of expected predictive error (lower deviance is better).\n\ndiag_mcmc(as.mcmc(sat_jags))\nmcmc_combo(as.mcmc(sat_jags))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNuestro interés principal es alpha1.\n\nsummary_df(sat_jags) %&gt;% filter(param == \"alpha1\")\n\n# A tibble: 1 × 10\n  param   mean    sd `2.5%` `25%` `50%` `75%` `97.5%`  Rhat n.eff\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 alpha1 -21.5  7.55  -36.5 -26.3 -21.6 -16.6   -6.67  1.00  2100\n\nplot_post(posterior(sat_jags)$alpha1, xlab = \"alpha1\", ROPE = c(-5, 5))\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 3247.167 -21.54868 -21.59495 -21.59789\n\n$hdi\n  prob        lo        hi\n1 0.95 -36.55332 -6.671171\n\n$ROPE\n  lo hi P(&lt; ROPE) P(in ROPE)    P(&gt; ROPE)\n1 -5  5 0.9863333      0.013 0.0006666667\n\nhdi(posterior(sat_jags), pars = \"alpha1\", prob = 0.95)\n\n     par        lo        hi      mode prob\n1 alpha1 -36.55332 -6.671171 -22.86641 0.95\n\n\nEsto parece extraño: ¿Realmente podemos aumentar los puntajes SAT reduciendo la financiación a las escuelas? Quizás deberíamos observar los datos en bruto con nuestro modelo superpuesto.\n\ngf_point(sat ~ expend, data = SAT) %&gt;%\n  gf_abline(slope = ~ alpha1, intercept = ~ beta0, \n            data = posterior(sat_jags) %&gt;% sample_n(2000),\n            alpha = 0.01, color = \"steelblue\")\n\n\n\n\n\n\n\n\nHay mucha dispersión, y la tendencia negativa está fuertemente influenciada por los 4 estados que gastan más (y tienen puntajes SAT relativamente bajos). Para solventar este problema vamos a incluir más covariables.\nTenemos algunos datos adicionales sobre cada estado. Vamos a ajustar un modelo con dos predictores: expend y frac.\n\nSAT %&gt;% head(4)\n\n     state expend ratio salary frac verbal math  sat\n1  Alabama  4.405  17.2 31.144    8    491  538 1029\n2   Alaska  8.963  17.6 47.951   47    445  489  934\n3  Arizona  4.778  19.3 32.175   27    448  496  944\n4 Arkansas  4.459  17.1 28.934    6    482  523 1005\n\n\n\nsat_model2 &lt;- function() {\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- alpha0 + alpha1 * (x1[i] - mean(x1)) + alpha2 * (x2[i] - mean(x2))\n  }\n  nuMinusOne ~ dexp(1/29.0)\n  nu        &lt;- nuMinusOne + 1\n  alpha0     ~ dnorm(alpha0mean, 1 / alpha0sd^2) \n  alpha1     ~ dnorm(0, 1 / alpha1sd^2)\n  alpha2     ~ dnorm(0, 1 / alpha2sd^2)\n  sigma      ~ dunif(sigma_lo, sigma_hi * 1000)\n  beta0     &lt;- alpha0 - mean(x1) * alpha1 - mean(x2) * alpha2\n  log10nu   &lt;- log(nu) / log(10)\n}\n\n\nsat2_jags &lt;- \n  jags(\n    model = sat_model2,\n    data = list(\n      y = SAT$sat,\n      x1 = SAT$expend,\n      x2 = SAT$frac,\n      alpha0mean = 1000,    # Los puntajes SAT son aproximadamente 500 + 500\n      alpha0sd   = 100,     # Prior amplio en la escala de 400 - 1600\n      alpha1sd   = 4 * sd(SAT$sat) / sd(SAT$expend),\n      alpha2sd   = 4 * sd(SAT$sat) / sd(SAT$frac),\n      sigma_lo = 0.001,\n      sigma_hi = 1000\n    ),\n    parameters.to.save = c(\"log10nu\", \"alpha0\", \"alpha1\", \"alpha2\", \"beta0\",\"sigma\"),\n    n.iter   = 4000,\n    n.burnin = 1000,\n    n.chains = 3\n  ) \n\n\nsat2_jags\n\nInference for Bugs model at \"/tmp/Rtmpff4QT1/model1f4766a81ca9.txt\", fit using jags,\n 3 chains, each with 4000 iterations (first 1000 discarded), n.thin = 3\n n.sims = 3000 iterations saved\n         mu.vect sd.vect    2.5%     25%     50%      75%    97.5%  Rhat n.eff\nalpha0   965.920   4.659 956.865 962.728 966.026  969.149  974.758 1.001  2100\nalpha1    12.862   4.509   3.927   9.869  12.874   15.858   21.955 1.001  3000\nalpha2    -2.885   0.234  -3.347  -3.043  -2.883   -2.729   -2.440 1.001  3000\nbeta0    991.621  22.846 946.274 976.400 991.427 1006.406 1037.458 1.001  3000\nlog10nu    1.367   0.370   0.633   1.107   1.380    1.637    2.039 1.001  3000\nsigma     31.488   3.918  24.249  28.834  31.256   33.890   39.656 1.001  3000\ndeviance 491.177   3.088 487.322 488.929 490.501  492.711  498.730 1.006   780\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 4.8 and DIC = 495.9\nDIC is an estimate of expected predictive error (lower deviance is better).\n\ndiag_mcmc(as.mcmc(sat2_jags))\nmcmc_combo(as.mcmc(sat2_jags))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsummary_df(sat2_jags) %&gt;% filter(param == \"alpha1\")\n\n# A tibble: 1 × 10\n  param   mean    sd `2.5%` `25%` `50%` `75%` `97.5%`  Rhat n.eff\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 alpha1  12.9  4.51   3.93  9.87  12.9  15.9    22.0  1.00  3000\n\nplot_post(posterior(sat2_jags)$alpha1, xlab = \"alpha1\", ROPE = c(-5, 5))\n\n\n\n\n\n\n\n\n$posterior\n          ESS     mean   median     mode\nvar1 2490.794 12.86232 12.87438 12.99886\n\n$hdi\n  prob       lo      hi\n1 0.95 3.447806 21.3269\n\n$ROPE\n  lo hi P(&lt; ROPE) P(in ROPE) P(&gt; ROPE)\n1 -5  5         0 0.03933333 0.9606667\n\nhdi(posterior(sat2_jags), pars = \"alpha1\", prob = 0.95)\n\n     par       lo      hi     mode prob\n1 alpha1 3.447806 21.3269 11.07646 0.95\n\n\n\nsummary_df(sat2_jags) %&gt;% filter(param == \"alpha2\")\n\n# A tibble: 1 × 10\n  param   mean    sd `2.5%` `25%` `50%` `75%` `97.5%`  Rhat n.eff\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 alpha2 -2.88 0.234  -3.35 -3.04 -2.88 -2.73   -2.44  1.00  3000\n\nplot_post(posterior(sat2_jags)$alpha2, xlab = \"alpha2\")\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 2897.033 -2.884702 -2.883404 -2.823664\n\n$hdi\n  prob        lo        hi\n1 0.95 -3.334813 -2.435674\n\nhdi(posterior(sat2_jags), pars = \"alpha2\", prob = 0.95)\n\n     par        lo        hi      mode prob\n1 alpha2 -3.334813 -2.435674 -2.895194 0.95\n\n\nLas covariables parecen estar correlacionadas:\n\ngf_point(expend ~ frac, data = SAT) \n\n\n\n\n\n\n\n\npor lo que un modelo con interacción puede ser más apropiado:\n\nsat_model3 &lt;- function() {\n  for (i in 1:length(y)) {\n    y[i]   ~ dt(mu[i], 1/sigma^2, nu)\n    mu[i] &lt;- alpha0 + alpha1 * (x1[i] - mean(x1)) + alpha2 * (x2[i] - mean(x2)) +  alpha3 * (x3[i] - mean(x3))\n  }\n  nuMinusOne ~ dexp(1/29.0)\n  nu        &lt;- nuMinusOne + 1\n  alpha0     ~ dnorm(alpha0mean, 1 / alpha0sd^2) \n  alpha1     ~ dnorm(0, 1 / alpha1sd^2)\n  alpha2     ~ dnorm(0, 1 / alpha2sd^2)\n  alpha3     ~ dnorm(0, 1 / alpha3sd^2)\n  sigma      ~ dunif(sigma_lo, sigma_hi)\n  beta0     &lt;- alpha0 - mean(x1) * alpha1 - mean(x2) * alpha2\n  log10nu   &lt;- log(nu) / log(10)\n}\n\n\nsat3_jags &lt;- \n  jags(\n    model = sat_model3,\n    data = list(\n      y = SAT$sat,\n      x1 = SAT$expend,\n      x2 = SAT$frac,\n      x3 = SAT$frac * SAT$expend,\n      alpha0mean = 1000,    # SAT scores are roughly 500 + 500\n      alpha0sd   = 100,     # broad prior on scale of 400 - 1600\n      alpha1sd   = 4 * sd(SAT$sat) / sd(SAT$expend),\n      alpha2sd   = 4 * sd(SAT$sat) / sd(SAT$frac),\n      alpha3sd   = 4 * sd(SAT$sat) / sd(SAT$frac * SAT$expend),\n      sigma_lo = 0.001,\n      sigma_hi = 1000\n    ),\n    parameters.to.save = c(\"log10nu\", \"alpha0\", \"alpha1\", \"alpha2\", \"alpha3\", \"beta0\",\"sigma\"),\n    n.iter   = 20000,\n    n.burnin = 1000,\n    n.chains = 3\n  ) \n\n\nsat3_jags\n\nInference for Bugs model at \"/tmp/Rtmpff4QT1/model1f473afc5227.txt\", fit using jags,\n 3 chains, each with 20000 iterations (first 1000 discarded), n.thin = 19\n n.sims = 3000 iterations saved\n          mu.vect sd.vect    2.5%      25%      50%      75%    97.5%  Rhat\nalpha0    965.935   4.635 956.969  962.886  966.006  968.999  975.006 1.001\nalpha1      2.270   8.183 -13.759   -3.221    2.319    7.792   17.822 1.001\nalpha2     -4.110   0.836  -5.700   -4.683   -4.115   -3.557   -2.456 1.002\nalpha3      0.212   0.139  -0.062    0.119    0.211    0.306    0.474 1.002\nbeta0    1097.368  72.897 955.671 1048.895 1097.161 1147.277 1236.971 1.001\nlog10nu     1.405   0.361   0.665    1.159    1.420    1.661    2.062 1.002\nsigma      31.178   3.853  24.235   28.502   30.941   33.590   39.466 1.001\ndeviance  489.174   3.464 484.614  486.657  488.469  490.996  497.872 1.002\n         n.eff\nalpha0    3000\nalpha1    3000\nalpha2    1800\nalpha3    1700\nbeta0     3000\nlog10nu   1700\nsigma     3000\ndeviance  1900\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 6.0 and DIC = 495.2\nDIC is an estimate of expected predictive error (lower deviance is better).\n\ndiag_mcmc(as.mcmc(sat3_jags))\nmcmc_combo(as.mcmc(sat3_jags))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmcmc_pairs(as.mcmc(sat3_jags), regex_pars = \"alpha\")",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 2)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos2.html#ajuste-de-un-modelo-lineal-con-brms",
    "href": "estimacion_modelos2.html#ajuste-de-un-modelo-lineal-con-brms",
    "title": "6  Estimación de Modelos Bayesianos (Parte 2)",
    "section": "6.4 Ajuste de un modelo lineal con brms",
    "text": "6.4 Ajuste de un modelo lineal con brms\nEl paquete brms proporciona una forma simplificada de describir modelos lineales generalizados y ajustarlos con Stan. La función brm() convierte una descripción concisa del modelo en código Stan, lo compila y lo ejecuta. Aquí hay un modelo lineal con sat como respuesta, y expend, frac, y una interacción como predictores.\n\nlibrary(brms)  \nsat3_brm &lt;- brm(sat ~ expend * frac, data = SAT)\n\nCompiling Stan program...\n\n\nStart sampling\n\nsat3_stan &lt;- stanfit(sat3_brm)\n\nStan maneja mejor los parámetros correlacionados que JAGS.\n\nsat3_stan\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n                 mean se_mean    sd    2.5%     25%     50%     75%   97.5%\nb_Intercept   1057.07    1.14 42.99  973.33 1028.43 1057.12 1086.24 1142.70\nb_expend         0.59    0.21  8.02  -15.09   -4.92    0.62    6.03   16.24\nb_frac          -4.23    0.02  0.84   -5.91   -4.78   -4.22   -3.67   -2.61\nb_expend:frac    0.24    0.00  0.14   -0.03    0.14    0.24    0.33    0.51\nsigma           32.50    0.07  3.36   26.78   30.14   32.19   34.52   39.92\nIntercept      965.78    0.09  4.75  956.61  962.63  965.74  968.94  975.06\nlprior         -10.32    0.00  0.03  -10.38  -10.34  -10.32  -10.30  -10.28\nlp__          -251.30    0.04  1.68 -255.53 -252.15 -250.92 -250.08 -249.11\n              n_eff Rhat\nb_Intercept    1432    1\nb_expend       1492    1\nb_frac         1288    1\nb_expend:frac  1240    1\nsigma          2192    1\nIntercept      2802    1\nlprior         2509    1\nlp__           1593    1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:30:07 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nmcmc_combo(as.mcmc.list(sat3_stan))\n\n\n\n\n\n\n\n\nPodemos usar stancode() para extraer el código Stan utilizado para ajustar el modelo.\n\nstancode(sat3_brm)\n\n// generated with brms 2.21.0\nfunctions {\n}\ndata {\n  int&lt;lower=1&gt; N;  // total number of observations\n  vector[N] Y;  // response variable\n  int&lt;lower=1&gt; K;  // number of population-level effects\n  matrix[N, K] X;  // population-level design matrix\n  int&lt;lower=1&gt; Kc;  // number of population-level effects after centering\n  int prior_only;  // should the likelihood be ignored?\n}\ntransformed data {\n  matrix[N, Kc] Xc;  // centered version of X without an intercept\n  vector[Kc] means_X;  // column means of X before centering\n  for (i in 2:K) {\n    means_X[i - 1] = mean(X[, i]);\n    Xc[, i - 1] = X[, i] - means_X[i - 1];\n  }\n}\nparameters {\n  vector[Kc] b;  // regression coefficients\n  real Intercept;  // temporary intercept for centered predictors\n  real&lt;lower=0&gt; sigma;  // dispersion parameter\n}\ntransformed parameters {\n  real lprior = 0;  // prior contributions to the log posterior\n  lprior += student_t_lpdf(Intercept | 3, 945.5, 84.5);\n  lprior += student_t_lpdf(sigma | 3, 0, 84.5)\n    - 1 * student_t_lccdf(0 | 3, 0, 84.5);\n}\nmodel {\n  // likelihood including constants\n  if (!prior_only) {\n    target += normal_id_glm_lpdf(Y | Xc, Intercept, b, sigma);\n  }\n  // priors including constants\n  target += lprior;\n}\ngenerated quantities {\n  // actual population-level intercept\n  real b_Intercept = Intercept - dot_product(means_X, b);\n}\n\n\nPodemos usar standata() para mostrar los datos que brm() pasa a Stan.\n\nstandata(sat3_brm) %&gt;% \n  lapply(head)  # trunca la salida para ahorrar espacio\n\n$N\n[1] 50\n\n$Y\n[1] 1029  934  944 1005  902  980\n\n$K\n[1] 4\n\n$Kc\n[1] 3\n\n$X\n  Intercept expend frac expend:frac\n1         1  4.405    8      35.240\n2         1  8.963   47     421.261\n3         1  4.778   27     129.006\n4         1  4.459    6      26.754\n5         1  4.992   45     224.640\n6         1  5.443   29     157.847\n\n$prior_only\n[1] 0\n\n\nSupongamos que queremos construir un modelo que tenga el mismo prior y verosimilitud que nuestro modelo JAGS. Aquí están algunos valores que necesitaremos.\n\n4 * sd(SAT$sat) / sd(SAT$expend)\n\n[1] 219.6073\n\n4 * sd(SAT$sat) / sd(SAT$frac)\n\n[1] 11.18293\n\n4 * sd(SAT$sat) / sd(SAT$frac * SAT$expend)\n\n[1] 1.45156\n\n\nPara usar una distribución t para la respuesta, usamos family = student(). Para establecer los priors, es útil saber cuáles serán los nombres de los parámetros y cuáles serían los priors predeterminados si no hacemos nada. (Si no se lista ningún prior, se usará un prior plano impropio.)\n\nget_prior(\n  sat ~ expend * frac, data = SAT,\n  family = student()   # distribución para la variable de respuesta\n)\n\n                     prior     class        coef group resp dpar nlpar lb ub\n                    (flat)         b                                        \n                    (flat)         b      expend                            \n                    (flat)         b expend:frac                            \n                    (flat)         b        frac                            \n student_t(3, 945.5, 84.5) Intercept                                        \n             gamma(2, 0.1)        nu                                    1   \n     student_t(3, 0, 84.5)     sigma                                    0   \n       source\n      default\n (vectorized)\n (vectorized)\n (vectorized)\n      default\n      default\n      default\n\n\nPodemos comunicar los priors a brm() de la siguiente manera:\n\nsat3a_brm &lt;- \n  brm(\n    sat ~ expend * frac, data = SAT,\n    family = student(),\n    prior = c(\n        set_prior(\"normal(0,220)\", coef = \"expend\"),\n        set_prior(\"normal(0,11)\", coef = \"frac\"),\n        set_prior(\"normal(0,1.5)\", coef = \"expend:frac\"),\n        set_prior(\"normal(1000, 100)\", class = \"Intercept\"),\n        set_prior(\"exponential(1/30.0)\", class = \"nu\"),\n        set_prior(\"uniform(0.001,1000)\", class = \"sigma\")\n    )\n  )\n\nWarning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.\nIf this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.\nWarning occurred for prior \n&lt;lower=0&gt; sigma ~ uniform(0.001,1000)\n\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 1.6e-05 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.16 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.352 seconds (Warm-up)\nChain 1:                0.213 seconds (Sampling)\nChain 1:                0.565 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1.1e-05 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.31 seconds (Warm-up)\nChain 2:                0.214 seconds (Sampling)\nChain 2:                0.524 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1.1e-05 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.29 seconds (Warm-up)\nChain 3:                0.197 seconds (Sampling)\nChain 3:                0.487 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 1.1e-05 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0.11 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.264 seconds (Warm-up)\nChain 4:                0.201 seconds (Sampling)\nChain 4:                0.465 seconds (Total)\nChain 4: \n\nsat3a_stan &lt;- stanfit(sat3a_brm)\n\n\nsat3a_stan\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n                 mean se_mean    sd    2.5%     25%     50%     75%   97.5%\nb_Intercept   1050.14    1.06 43.42  961.46 1020.46 1050.15 1080.20 1133.73\nb_expend         2.02    0.20  8.12  -13.72   -3.55    1.90    7.68   18.31\nb_frac          -4.16    0.02  0.85   -5.77   -4.75   -4.16   -3.56   -2.51\nb_expend:frac    0.22    0.00  0.14   -0.06    0.12    0.22    0.32    0.49\nsigma           31.13    0.08  3.84   24.14   28.55   30.92   33.45   39.14\nnu              34.61    0.55 30.22    4.51   13.55   25.16   46.20  117.32\nIntercept      965.85    0.08  4.64  957.06  962.74  965.90  968.93  975.13\nlprior         -28.06    0.02  1.01  -30.86  -28.44  -27.74  -27.35  -27.04\nlp__          -266.12    0.05  1.81 -270.61 -267.10 -265.80 -264.78 -263.60\n              n_eff Rhat\nb_Intercept    1684    1\nb_expend       1719    1\nb_frac         1553    1\nb_expend:frac  1463    1\nsigma          2144    1\nnu             3038    1\nIntercept      3158    1\nlprior         2997    1\nlp__           1361    1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:32:21 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nmcmc_combo(as.mcmc.list(sat3a_stan))",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 2)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos3.html",
    "href": "estimacion_modelos3.html",
    "title": "7  Estimación de Modelos Bayesianos (Parte 3)",
    "section": "",
    "text": "7.1 ANOVA de una vía\nLa especie estudiada fue la mosca de la fruta, Drosophila melanogaster (Hanley & Shapiro, 1994), conocida porque las hembras recién inseminadas no se aparean nuevamente durante al menos dos días y los machos no cortejan activamente a las hembras embarazadas. Para ilustrar el uso del modelo, se estudió la duración de la vida de los machos en función de su actividad sexual. En el experimento, se manipuló la actividad sexual suministrando a los machos individuales hembras vírgenes receptivas a una tasa de una u ocho vírgenes por día. La longevidad de estos machos se registró y se comparó con la de dos grupos de control: uno con machos mantenidos con hembras recién inseminadas en igual número que las hembras vírgenes y otro con machos sin hembras. El objetivo era determinar si la actividad sexual de los machos reducía su vida, ya que esto ya estaba establecido para las hembras. Un efecto perjudicial de la actividad sexual en machos sería sorprendente, dado que se presume que los costos fisiológicos de la actividad sexual son menores en machos que en hembras. Cada grupo experimental y de control constaba de 25 moscas macho.\ngf_violin(longevity ~ group, data = FruitflyReduced) %&gt;%\n  gf_jitter(width = 0.2, height = 0, alpha = 0.5) %&gt;%\n  gf_point(stat = \"summary\", color = \"red\", size = 3, alpha = 0.5, fun = mean)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 3)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos3.html#anova-de-una-vía",
    "href": "estimacion_modelos3.html#anova-de-una-vía",
    "title": "7  Estimación de Modelos Bayesianos (Parte 3)",
    "section": "",
    "text": "7.1.1 Modelo 1\nEs bastante fácil pedirle a brm() que ajuste un modelo para nosotros. Solo proporcionemos nuestras variables explicativas y de respuesta y veamos qué sucede.\n\nflies_brm &lt;- brm(longevity ~ group, data = FruitflyReduced)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nflies_stan &lt;- stanfit(flies_brm)\nflies_stan\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n                    mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat\nb_Intercept        63.52    0.06 2.93   57.66   61.55   63.55   65.44   69.26  2555    1\nb_groupPregnant1    1.29    0.08 4.16   -6.93   -1.49    1.35    4.17    9.29  2816    1\nb_groupPregnant8   -0.09    0.08 4.19   -8.39   -2.84   -0.10    2.66    8.24  2882    1\nb_groupVirgin1     -6.71    0.08 4.14  -14.91   -9.45   -6.70   -3.94    1.25  2797    1\nb_groupVirgin8    -24.78    0.07 4.17  -32.98  -27.45  -24.77  -21.97  -16.70  3131    1\nsigma              14.88    0.02 0.96   13.16   14.21   14.85   15.50   16.88  3274    1\nIntercept          57.46    0.02 1.30   54.94   56.61   57.45   58.34   60.00  4535    1\nlprior             -7.49    0.00 0.05   -7.60   -7.52   -7.49   -7.46   -7.40  3197    1\nlp__             -519.50    0.04 1.73 -523.79 -520.38 -519.17 -518.21 -517.12  1922    1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:02:05 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\nmcmc_combo(as.mcmc.list(flies_stan))\n\n\n\n\n\n\n\nmcmc_areas_ridges(as.mcmc.list(flies_stan), regex_pars = \"b_g\")\n\n\n\n\n\n\n\n\nAnalicemos la codificación que usa STAN en la variable categórica:\n\nstandata(flies_brm) %&gt;% lapply(head)\n\n$N\n[1] 125\n\n$Y\n[1] 35 37 49 46 63 39\n\n$K\n[1] 5\n\n$Kc\n[1] 4\n\n$X\n  Intercept groupPregnant1 groupPregnant8 groupVirgin1 groupVirgin8\n1         1              0              1            0            0\n2         1              0              1            0            0\n3         1              0              1            0            0\n4         1              0              1            0            0\n5         1              0              1            0            0\n6         1              0              1            0            0\n\n$prior_only\n[1] 0\n\n\nEl modelo resulta ser en este caso:\n[ = _0 + _1 x_1 + _2 x_2 + _3 x_3 + _4 x_4 + \\ = _0 + _1 x_1 + _2 x_2 + _3 x_3 + _4 x_4 + {Norm}(0, ) ]\ndonde, por ejemplo,\n[ x_1 = [![ = ]!] \\ =\n\\[\\begin{cases}\n          1 & \\mbox{si group}   =  \\mbox{Pregnant1} \\\\\n          0 & \\mbox{si group} \\neq \\mbox{Pregnant1}\n       \\end{cases}\\]\n]\nEn otras palabras, la distribución de la longevidad es\n\n\\({\\sf Norm}(\\beta_0, \\sigma)\\) para el grupo None0\n\\({\\sf Norm}(\\beta_0 + \\beta_1, \\sigma)\\) para el grupo Pregnant1\n\\({\\sf Norm}(\\beta_0 + \\beta_2, \\sigma)\\) para el grupo Pregnant2\n\\({\\sf Norm}(\\beta_0 + \\beta_3, \\sigma)\\) para el grupo Virgin1\n\\({\\sf Norm}(\\beta_0 + \\beta_4, \\sigma)\\) para el grupo Virgin2\n\nAquí están las distribuciones previas predeterminadas:\n\nprior_summary(flies_brm)\n\n                  prior     class           coef group resp dpar nlpar lb ub       source\n                 (flat)         b                                                 default\n                 (flat)         b groupPregnant1                             (vectorized)\n                 (flat)         b groupPregnant8                             (vectorized)\n                 (flat)         b   groupVirgin1                             (vectorized)\n                 (flat)         b   groupVirgin8                             (vectorized)\n student_t(3, 58, 17.8) Intercept                                                 default\n  student_t(3, 0, 17.8)     sigma                                       0         default\n\n\n\nPrevias planas e impropias para los parámetros b_.\nDistribución t con 3 grados de libertad para el intercepto (colas más pesadas que una distribución normal).\n\nNota: Esto es realmente una previa para \\(\\alpha_0\\) (efecto medio de toda la población), no \\(\\beta_0\\), ya que usualmente es más fácil especificar una previa para \\(\\alpha_0\\). Si por alguna razón quisiéramos especificar una previa para \\(\\beta_0\\) en su lugar, hay un pequeño truco: usar la fórmula longevity ~ 0 + intercept + group.\nSi tienes curiosidad sobre de dónde vienen los valores 58 y 18, aquí hay una buena suposición:\n\n\ndf_stats(~ longevity, data = FruitflyReduced, mean, sd)\n\n   response  mean       sd\n1 longevity 57.44 17.56389\n\n\n“T” para sigma.\n\n\n\n7.1.2 Modelo 2: Previas personalizadas\nEl modelo anterior difiere del modelo básico en el Kruschke.\nPodemos acercarnos más al modelo de DBDA usando esto:\n\nflies2_brm &lt;- \n  brm(longevity ~ group, data = FruitflyReduced,\n      prior = c(\n        set_prior(class = \"Intercept\", \"normal(60, 100)\"),  # 100 = 5 * 20\n        set_prior(class = \"b\", \"normal(0, 10)\"),  # group = \"b\" es el valor predeterminado; se podría omitir\n        set_prior(class = \"sigma\", \"uniform(20.0/1000.0, 20.0 * 1000.0)\")\n      )\n  )\n\nWarning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.\nIf this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.\nWarning occurred for prior \n&lt;lower=0&gt; sigma ~ uniform(20.0/1000.0, 20.0 * 1000.0)\n\n\nCompiling Stan program...\n\n\nStart sampling\n\nprior_summary(flies2_brm)\nstancode(flies2_brm)\n\nEsto todavía no es exactamente igual al modelo utilizado por Kruschke. Resulta que hay múltiples maneras de codificar los \\(\\beta\\)s. Un tercero es utilizado por Kruschke y requiere un poco más de trabajo para ajustarse usando brm():\n\n\n7.1.3 Modelo 3\nSi eliminamos el intercepto en el modelo brm(), obtenemos un modelo con un \\(\\beta_i\\) para cada media de grupo en lugar de un \\(\\beta_0\\) para el primer grupo y un \\(\\beta_i\\) para la diferencia en las medias de los grupos cuando \\(i &gt; 0\\):\n\nflies3_brm &lt;- \n  brm(\n    longevity ~ 0 + group, data = FruitflyReduced,\n    prior = c(\n      set_prior(class = \"b\", \"normal(60, 10)\"),  # group = \"b\" es el valor predeterminado; se podría omitir\n      set_prior(class = \"sigma\", \"uniform(20.0/1000.0, 20.0 * 1000.0)\")\n    ),\n    sample_prior = TRUE\n  )\n\nWarning: It appears as if you have specified an upper bounded prior on a parameter that has no natural upper bound.\nIf this is really what you want, please specify argument 'ub' of 'set_prior' appropriately.\nWarning occurred for prior \n&lt;lower=0&gt; sigma ~ uniform(20.0/1000.0, 20.0 * 1000.0)\n\n\nCompiling Stan program...\n\n\nStart sampling\n\nprior_summary(flies3_brm)\nstancode(flies3_brm)\n\nEsto es equivalente a\n[ = _0 x_0 + _1 x_1 + _2 x_2 + _3 x_3 + _4 x_4 + = _0 x_0 + _1 x_1 + _2 x_2 + _3 x_3 + _4 x_4 + {Norm}(0, ) ]\ndonde, por ejemplo,\n[ x_1 = [![ = ]!] \\ =\n\\[\\begin{cases}\n          1 & \\mbox{si group}   =  \\mbox{Pregnant1} \\\\\n          0 & \\mbox{si group} \\neq \\mbox{Pregnant1}\n       \\end{cases}\\]\n]\nEn otras palabras, la distribución de la longevidad es\n\n\\({\\sf Norm}(\\beta_0, \\sigma)\\) para el grupo None0\n\\({\\sf Norm}(\\beta_1, \\sigma)\\) para el grupo Pregnant1\n\\({\\sf Norm}(\\beta_2, \\sigma)\\) para el grupo Pregnant2\n\\({\\sf Norm}(\\beta_3, \\sigma)\\) para el grupo Virgin1\n\\({\\sf Norm}(\\beta_4, \\sigma)\\) para el grupo Virgin2\n\n\n\n7.1.4 Comparando grupos\n\n7.1.4.1 Comparación con el “grupo de referencia”\nUsamos el modelo 2:\n\nstanfit(flies2_brm)\n\nInference for Stan model: anon_model.\n4 chains, each with iter=2000; warmup=1000; thin=1; \npost-warmup draws per chain=1000, total post-warmup draws=4000.\n\n                    mean se_mean   sd    2.5%     25%     50%     75%   97.5% n_eff Rhat\nb_Intercept        61.72    0.05 2.48   56.91   60.07   61.71   63.41   66.62  3027    1\nb_groupPregnant1    2.81    0.06 3.68   -4.21    0.25    2.74    5.25   10.19  3874    1\nb_groupPregnant8    1.50    0.06 3.63   -5.79   -0.87    1.53    3.94    8.48  4068    1\nb_groupVirgin1     -4.53    0.06 3.66  -11.85   -6.98   -4.49   -2.17    2.71  3667    1\nb_groupVirgin8    -21.11    0.06 3.61  -28.17  -23.58  -21.16  -18.67  -14.01  3874    1\nsigma              14.97    0.02 0.98   13.23   14.29   14.91   15.58   17.06  4221    1\nIntercept          57.45    0.02 1.32   54.86   56.54   57.49   58.37   60.00  4806    1\nlprior            -30.96    0.01 0.81  -32.80  -31.46  -30.88  -30.38  -29.62  3555    1\nlp__             -543.16    0.04 1.74 -547.45 -544.09 -542.79 -541.89 -540.81  1974    1\n\nSamples were drawn using NUTS(diag_e) at Sat Jun 22 22:04:26 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nEn este modelo, un grupo corresponde al intercepto del modelo, y las comparaciones de otros grupos con este grupo implican investigar la distribución posterior de uno de los otros \\(\\beta\\)s.\n\nflies_post &lt;- posterior(flies_stan)\nnames(flies_post)\n\n [1] \"b_Intercept\"      \"b_groupPregnant1\" \"b_groupPregnant8\" \"b_groupVirgin1\"   \"b_groupVirgin8\"  \n [6] \"sigma\"            \"Intercept\"        \"lprior\"           \"lp__\"             \"chain\"           \n[11] \"iter\"            \n\n\n\nplot_post(flies_post$b_groupPregnant1)\n\n\n\n\n\n\n\n\n$posterior\n      ESS     mean   median     mode\nvar1 2880 1.288035 1.346441 1.688973\n\n$hdi\n  prob        lo       hi\n1 0.95 -6.686603 9.430803\n\nhdi(flies_post$b_groupPregnant1)\n\n   par        lo       hi      mode prob\n1 var1 -6.686603 9.430803 0.9314014 0.95\n\nplot_post(flies_post$b_groupVirgin1)\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean   median      mode\nvar1 2964.378 -6.714818 -6.70026 -5.776553\n\n$hdi\n  prob        lo       hi\n1 0.95 -14.83658 1.274635\n\nmcmc_areas(as.mcmc.list(flies_stan), pars = \"b_groupVirgin1\", prob = 0.95)\n\n\n\n\n\n\n\nhdi(flies_post$b_groupVirgin1)\n\n   par        lo       hi      mode prob\n1 var1 -14.83658 1.274635 -4.381462 0.95\n\n\n\n\n7.1.4.2 Comparación de otros pares de grupos\n¿Qué pasa si queremos comparar los grupos Virgin1 y Virgin8? Podemos usar la identidad \\(\\beta_0 + \\beta_i - (\\beta_0 + \\beta_j) = \\beta_i - \\beta_j\\) para simplificar el álgebra y hacerlo de esta manera.\n\nflies_post &lt;-\n  flies_post %&gt;% mutate(dVirgin = b_groupVirgin8 - b_groupVirgin1)\nplot_post(flies_post$dVirgin, xlab = \"Virgin8 - Virgin1\")\n\n\n\n\n\n\n\n\n$posterior\n          ESS     mean    median      mode\nvar1 5166.695 -18.0649 -18.04029 -19.36771\n\n$hdi\n  prob       lo       hi\n1 0.95 -26.6462 -9.91304\n\n\n\n\n7.1.4.3 Contrastes: Comparación de “grupos de grupos”\n¿Qué pasa si queremos comparar los dos grupos de vírgenes con los otros 3 grupos? Esto es un poco más fácil de hacer usando el modelo sin un término de intercepto.\n\nflies3_post &lt;- posterior(flies3_brm)\n\nWarning: Method 'posterior_samples' is deprecated. Please see ?as_draws for recommended\nalternatives.\n\nnames(flies3_post)\n\n [1] \"b_groupNone0\"     \"b_groupPregnant1\" \"b_groupPregnant8\" \"b_groupVirgin1\"   \"b_groupVirgin8\"  \n [6] \"sigma\"            \"prior_b\"          \"prior_sigma\"      \"lprior\"           \"lp__\"            \n\nflies3_post &lt;-\n  flies3_post %&gt;% \n  mutate(\n    contrast = \n      (b_groupVirgin8 + b_groupVirgin1)/2 - \n      (b_groupPregnant1 + b_groupPregnant8 + b_groupNone0) / 3\n)\nplot_post(flies3_post$contrast, xlab = \"Virgin vs non-virgin groups\")\n\n\n\n\n\n\n\n\n$posterior\n         ESS      mean    median      mode\nvar1 5070.07 -14.79242 -14.81572 -14.41102\n\n$hdi\n  prob        lo        hi\n1 0.95 -19.99495 -9.614157\n\n\nLa expresión\n[ - = - _0 - _1 - _2 + _3 + _4 ]\nes un ejemplo de un contraste. Un contraste es simplemente una combinación lineal de las medias de los grupos tal que la suma de los coeficientes sea 0. Muchas relaciones interesantes pueden investigarse usando contrastes, y el paquete brms incluye la función hypothesis() para ayudarnos a hacer esto. (Nota: debido a que incluimos sample_prior = TRUE en la llamada a brm() para este modelo, el gráfico a continuación muestra tanto las distribuciones previas como las posteriores para el contraste.)\n\nh &lt;-\n  hypothesis(\n    flies3_brm,\n    \"(groupVirgin8 + groupVirgin1) / 2 &lt; \n      (groupPregnant1 + groupPregnant8 + groupNone0) / 3\"\n  )\nh\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1 ((groupVirgin8+gr... &lt; 0   -14.79      2.67   -19.07   -10.39        Inf         1    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nplot(h)\n\n\n\n\n\n\n\n\n\n\n7.1.4.4 Múltiples hipótesis a la vez\nIncluso podemos probar múltiples hipótesis a la vez.\n\nh2 &lt;-\n  hypothesis(\n    flies3_brm,\n    c(\"groupVirgin1 &lt; (groupPregnant1 + groupPregnant8 + groupNone0) / 3\",\n      \"groupVirgin8 &lt; (groupPregnant1 + groupPregnant8 + groupNone0) / 3\")\n  )\nh2\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1 (groupVirgin1)-((... &lt; 0    -6.52      3.32   -11.93    -0.92      35.36      0.97    *\n2 (groupVirgin8)-((... &lt; 0   -23.06      3.34   -28.61   -17.51        Inf      1.00    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nplot(h2)\n\n\n\n\n\n\n\n\n\n\n7.1.4.5 ¿Igualdad o desigualdad?\nEn el ejemplo anterior, expresamos nuestro contraste como una desigualdad. También podemos expresarlo como una igualdad. El resultado que obtenemos de hypothesis() es un poco diferente si lo hacemos así.\n\nh3 &lt;-\n  hypothesis(\n    flies3_brm,\n    c(\"groupVirgin1 = (groupPregnant1 + groupPregnant8 + groupNone0) / 3\",\n      \"groupVirgin8 = (groupPregnant1 + groupPregnant8 + groupNone0) / 3\")\n  )\nh3\n\nHypothesis Tests for class b:\n                Hypothesis Estimate Est.Error CI.Lower CI.Upper Evid.Ratio Post.Prob Star\n1 (groupVirgin1)-((... = 0    -6.52      3.32   -12.90     0.18        0.6      0.38     \n2 (groupVirgin8)-((... = 0   -23.06      3.34   -29.68   -16.39        0.0      0.00    *\n---\n'CI': 90%-CI for one-sided and 95%-CI for two-sided hypotheses.\n'*': For one-sided hypotheses, the posterior probability exceeds 95%;\nfor two-sided hypotheses, the value tested against lies outside the 95%-CI.\nPosterior probabilities of point hypotheses assume equal prior probabilities.\n\nplot(h3)\n\n\n\n\n\n\n\n\n\nEl IC es bidireccional en lugar de unidireccional.\nLa Ratio de Evidencia se define de manera diferente.\n\nPara las desigualdades, esta es la razón de las probabilidades posteriores de que la desigualdad sea verdadera vs. falsa.\nPara las igualdades, esta es la razón de la densidad posterior (de la igualdad sostenida) a la densidad previa (Factor de Bayes). (Esto solo funciona si sample_prior = TRUE, ya que se requieren muestras previas para hacer el cálculo.)",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 3)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos3.html#anova-de-varias-vías",
    "href": "estimacion_modelos3.html#anova-de-varias-vías",
    "title": "7  Estimación de Modelos Bayesianos (Parte 3)",
    "section": "7.2 ANOVA de varias vías",
    "text": "7.2 ANOVA de varias vías\n\n7.2.1 Rendimiento de Cultivo según el Método de Labranza y Fertilizante\nLos datos en CalvinBayes::SplitPlotAgri provienen de un estudio agrícola en el que se utilizaron diferentes métodos de labranza y diferentes fertilizantes, y posteriormente se midió el rendimiento del cultivo (en bushels por acre).\n\ngf_point(Yield ~ Fert | ~ Till, data = SplitPlotAgri, alpha = 0.4, size = 4)\n\n\n\n\n\n\n\n\nAjustamos dos modelos: sin/con interacción entre fertilizante y labranza. Estamos interesados en la pregunta: ¿Cómo usarías cada modelo para estimar el rendimiento medio al usar labranza de contorno (ridge) y fertilizante profundo (deep)?\n\nfert1_brm &lt;-\n  brm(Yield ~ Till + Fert, data = SplitPlotAgri)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nfert2_brm &lt;-     \n  brm(Yield ~ Till * Fert, data = SplitPlotAgri)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nfert1_brm  \n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Yield ~ Till + Fert \n   Data: SplitPlotAgri (Number of observations: 99) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept     120.41      2.87   114.86   126.19 1.00     4357     2743\nTillMoldbrd    16.08      3.27     9.70    22.42 1.00     3896     2453\nTillRidge      15.71      3.12     9.57    21.80 1.00     4271     3005\nFertDeep       15.76      3.25     9.41    22.10 1.00     4134     3133\nFertSurface    12.59      3.25     6.15    18.94 1.00     4480     3303\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    13.12      0.95    11.44    15.13 1.00     3745     2849\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nNota que este modelo implica que la diferencia en rendimiento entre el uso de dos fertilizantes es la misma para cada uno de los tres métodos de labranza y la diferencia debida a los métodos de labranza es la misma para cada uno de los tres fertilizantes. Esto puede no ser una suposición razonable. Tal vez algunos fertilizantes funcionen mejor con ciertos métodos de labranza que con otros. El modelo 2 permite esto.\n\nfert2_brm  \n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Yield ~ Till * Fert \n   Data: SplitPlotAgri (Number of observations: 99) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept                 124.23      3.72   117.04   131.45 1.00     1898     2074\nTillMoldbrd                16.57      5.35     6.03    26.76 1.00     1985     2560\nTillRidge                   3.73      5.38    -6.42    14.27 1.00     1900     2557\nFertDeep                    9.55      5.27    -0.60    20.11 1.00     2027     2602\nFertSurface                 7.14      5.15    -2.84    17.11 1.00     1974     2835\nTillMoldbrd:FertDeep        0.63      7.67   -14.34    15.87 1.00     2173     2826\nTillRidge:FertDeep         18.04      7.57     2.94    32.74 1.00     2055     2734\nTillMoldbrd:FertSurface    -1.98      7.62   -16.70    13.11 1.00     2057     2670\nTillRidge:FertSurface      18.10      7.40     3.56    32.76 1.00     2131     2520\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    12.70      0.95    11.01    14.73 1.00     4091     2968\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nComo antes, podemos optar por ajustar el modelo sin una intersección. Esto produce una diferente parametrización del mismo modelo.\n\nfert2a_brm &lt;-   \n  brm(Yield ~ 0 + Till * Fert, data = SplitPlotAgri)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\n\nfert2a_brm\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Yield ~ 0 + Till * Fert \n   Data: SplitPlotAgri (Number of observations: 99) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nTillChisel                124.36      3.79   117.14   132.00 1.00     1686     2259\nTillMoldbrd               140.85      3.99   133.13   148.72 1.00     3371     2580\nTillRidge                 128.03      3.83   120.74   135.56 1.00     3107     2710\nFertDeep                    9.39      5.22    -0.82    19.43 1.00     1546     2872\nFertSurface                 6.97      5.33    -3.65    17.45 1.00     1606     2377\nTillMoldbrd:FertDeep        0.78      7.86   -14.53    16.44 1.00     2013     2594\nTillRidge:FertDeep         17.99      7.61     2.82    33.26 1.00     1718     2658\nTillMoldbrd:FertSurface    -1.82      7.81   -17.10    13.32 1.00     1866     2352\nTillRidge:FertSurface      18.14      7.72     3.32    33.43 1.00     1544     2225\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma    12.70      0.97    11.02    14.75 1.00     3415     2432\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n7.2.2 Diseño de Parcela Dividida\nEl estudio utilizó 33 campos diferentes. Cada campo se dividió en 3 secciones y se aplicó un fertilizante diferente a cada una de las tres secciones. (Qué fertilizante se utilizó en qué sección se determinó al azar). Esto se llama un “diseño de parcela dividida” (incluso si se aplica a cosas que no son campos de cultivo).\nHubiera sido posible dividir cada campo en 9 subparcelas y usar todas las combinaciones de labranza y fertilizante, pero ese no fue el enfoque de este estudio. El método de labranza fue el mismo para todo el campo, probablemente porque era mucho más eficiente arar los campos de esta manera.\nEl gráfico a continuación indica que diferentes campos parecen tener rendimientos base diferentes, ya que los puntos asociados con un campo tienden a estar cerca de la parte superior o inferior de cada uno de los grupos de fertilizantes. Podemos agregar una variable adicional a nuestro modelo para manejar esta situación.\n\ngf_point(Yield ~ Fert | ~ Till, data = SplitPlotAgri, alpha = 0.4, size = 4) %&gt;%\n  gf_line(group = ~Field)\n\n\n\n\n\n\n\n\n\nfert3_brm &lt;-\n  # el uso de factor() es importante aquí porque los ids de campo son números\n  # factor convierte esto en un factor (es decir, una variable nominal)\n  brm(Yield ~ Till * Fert + factor(Field), data = SplitPlotAgri)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\nWarning: There were 3994 transitions after warmup that exceeded the maximum treedepth. Increase max_treedepth above 10. See\nhttps://mc-stan.org/misc/warnings.html#maximum-treedepth-exceeded\n\n\nWarning: Examine the pairs() plot to diagnose sampling problems\n\n\nWarning: The largest R-hat is 3.09, indicating chains have not mixed.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#r-hat\n\n\nWarning: Bulk Effective Samples Size (ESS) is too low, indicating posterior means and medians may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#bulk-ess\n\n\nWarning: Tail Effective Samples Size (ESS) is too low, indicating posterior variances and tail quantiles may be unreliable.\nRunning the chains for more iterations may help. See\nhttps://mc-stan.org/misc/warnings.html#tail-ess\n\n\n\nfert3_brm\n\nWarning: Parts of the model have not converged (some Rhats are &gt; 1.05). Be careful when analysing\nthe results! We recommend running more iterations and/or setting stronger priors.\n\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Yield ~ Till * Fert + factor(Field) \n   Data: SplitPlotAgri (Number of observations: 99) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nRegression Coefficients:\n                        Estimate Est.Error  l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept                 118.62      3.64    111.42   125.64 1.16       21       52\nTillMoldbrd             -3993.97   5617.77 -15275.81  5024.52 2.83        5       15\nTillRidge                 846.24   7487.03  -8079.22 15129.64 3.09        5       12\nFertDeep                   10.06      2.22      5.75    14.91 1.07       46       76\nFertSurface                 7.93      2.26      3.94    12.75 1.13       23       35\nfactorField2               14.92      5.09      5.20    25.84 1.11       30       74\nfactorField3               17.76      5.32      7.21    27.91 1.15       21       36\nfactorField4                5.64      5.03     -3.70    15.59 1.12       25       64\nfactorField5               15.61      5.04      5.39    25.26 1.09       36       84\nfactorField6               -1.20      5.21    -11.49    10.17 1.11       34       56\nfactorField7               -7.90      4.85    -17.36     2.00 1.12       31       77\nfactorField8              -10.61      4.78    -19.83    -1.17 1.10       32       88\nfactorField9               -0.39      4.90     -9.76    10.20 1.14       23       39\nfactorField10              17.20      4.93      7.23    27.42 1.10       34       49\nfactorField11              14.69      4.56      6.03    24.60 1.08       40       51\nfactorField12              -1.96      4.63    -10.90     7.66 1.09       40       51\nfactorField13            4020.43   5617.52  -5001.67 15300.17 2.83        5       15\nfactorField14            4025.06   5617.54  -4991.98 15311.47 2.83        5       15\nfactorField15            4006.35   5617.56  -5005.94 15289.72 2.83        5       15\nfactorField16            4037.82   5617.58  -4979.57 15321.00 2.83        5       15\nfactorField17            4013.62   5617.56  -5004.07 15299.69 2.83        5       15\nfactorField18            4006.04   5617.58  -5010.49 15289.48 2.83        5       15\nfactorField19            4015.75   5617.69  -4996.78 15300.58 2.83        5       15\nfactorField20            4024.04   5617.54  -4992.59 15306.36 2.83        5       15\nfactorField21            4002.01   5617.56  -5018.61 15292.34 2.83        5       15\nfactorField22            4012.03   5617.58  -5003.78 15300.71 2.83        5       15\nfactorField23            -847.07   7485.88 -15127.18  8082.54 3.09        5       12\nfactorField24            -814.03   7485.82 -15097.40  8107.76 3.09        5       12\nfactorField25            -845.72   7485.88 -15126.80  8080.23 3.09        5       12\nfactorField26            -853.68   7485.90 -15134.72  8071.49 3.09        5       12\nfactorField27            -836.49   7485.92 -15117.38  8088.86 3.09        5       12\nfactorField28            -837.29   7485.89 -15120.52  8088.57 3.09        5       12\nfactorField29            -849.05   7485.87 -15131.84  8074.98 3.09        5       12\nfactorField30            -846.03   7486.02 -15127.26  8077.18 3.09        5       12\nfactorField31            -819.32   7485.91 -15101.48  8110.30 3.09        5       12\nfactorField32            -835.36   7485.78 -15114.69  8093.58 3.09        5       12\nfactorField33            -817.37   7485.90 -15103.69  8110.13 3.09        5       12\nTillMoldbrd:FertDeep        0.18      3.21     -6.92     5.71 1.06       52      121\nTillRidge:FertDeep         17.02      3.10     10.90    23.02 1.06       50      149\nTillMoldbrd:FertSurface    -2.83      3.27     -9.40     3.70 1.07       52       59\nTillRidge:FertSurface      16.86      3.51      9.02    23.05 1.16       20       38\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.77      0.54     4.79     6.87 1.03       65      145\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAfortunadamente, en realidad no queremos este modelo. Ahora tenemos un ajuste para cada campo, y hubo 33 campos. Pero realmente no estamos interesados en predecir el rendimiento para un campo dado. Nuestro interés principal es en qué fertilizantes y métodos de labranza funcionan bien.\nSi pensamos que la calidad del campo podría describirse mediante una distribución normal (u otra distribución), podríamos estar más interesados en los parámetros de esa distribución que en las estimaciones específicas para los campos particulares en este estudio. El tipo de modelo que queremos para esto se llama un modelo jerárquico o multinivel, y brm() facilita la descripción de dicho modelo.\nAquí hay una manera de pensar sobre tal modelo\n\nCada campo tiene una productividad base.\nLas productividades base son normales con alguna media y desviación estándar que nos dicen sobre la distribución de la productividad entre campos. Nuestros 33 campos deberían ayudarnos a estimar esta distribución.\nEsa productividad base puede ajustarse hacia arriba o hacia abajo dependiendo del método de labranza y fertilizante utilizado.\n\nEn la jerga de brm(), el efecto del campo es ajustar la intersección, así que podemos escribirlo así:\n\nfert4_brm &lt;-\n  brm(Yield ~ Till * Fert + (1 | Field), data = SplitPlotAgri)\n\nCompiling Stan program...\n\n\nStart sampling\n\n\nPodemos ver en la salida a continuación que la variabilidad de parcela a parcela se estima con una desviación estándar de aproximadamente 8 a 15. Las estimaciones individuales de los campos están ocultas en este informe, pero puedes verlas si escribes stanfit(fert_brm).\n\nfert4_brm\n\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: Yield ~ Till * Fert + (1 | Field) \n   Data: SplitPlotAgri (Number of observations: 99) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~Field (Number of levels: 33) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)    11.56      1.66     8.80    15.32 1.01      635     1168\n\nRegression Coefficients:\n                        Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept                 124.12      3.65   117.18   131.36 1.01      629     1356\nTillMoldbrd                16.72      5.41     6.03    26.96 1.00      721     1379\nTillRidge                   3.91      5.47    -6.98    14.40 1.01      602     1195\nFertDeep                    9.48      2.32     4.84    14.00 1.00     1752     1972\nFertSurface                 7.13      2.35     2.44    11.71 1.00     1978     2308\nTillMoldbrd:FertDeep        0.76      3.47    -6.04     7.65 1.00     2009     2683\nTillRidge:FertDeep         17.99      3.27    11.64    24.62 1.00     1986     2424\nTillMoldbrd:FertSurface    -1.87      3.48    -8.79     5.12 1.00     2138     2550\nTillRidge:FertSurface      18.03      3.38    11.48    24.79 1.00     2088     2590\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     5.71      0.53     4.76     6.82 1.00     1669     2644\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\n\n\n7.2.3 Comparación de modelos\n\n\n7.2.4 Medición de un Modelo – Error de Predicción\n\n7.2.4.1 Predicción vs. Observación\nUna forma de medir qué tan bien está funcionando un modelo es comparar las predicciones que el modelo hace para la variable de respuesta \\(\\hat y_i\\) con los valores de respuesta observados en los datos \\(y_i\\). Para simplificar las cosas, nos gustaría convertir estas \\(n\\) predicciones y \\(n\\) observaciones en un solo número.\nEsto se puede realizar simplemente a través de: Suma de Errores Cuadrados (SSE) o el Error Cuadrático Medio (MSE).\n\\[\\begin{align*}\nSSE & = \\sum_{i = 1}^n (y_i - \\hat y_i)^2 \\\\\nMSE & = \\frac{1}{n} SSE = \\frac{1}{n} \\sum_{i = 1}^n (y_i - \\hat y_i)^2\n\\end{align*}\\]\nTambién a través del \\(r^2\\):\n\\[\\begin{align*}\nSSE &= \\sum_{i = 1}^n (y_i - \\hat y_i)^2 \\\\\nSST &= \\sum_{i = 1}^n (y_i - \\overline{y})^2 \\\\\nr^2 &= 1 - \\frac{SSE}{SST}\n\\end{align*}\\]\nEstamos trabajando con modelos bayesianos, por lo que el \\(SSE\\), \\(MSE\\) y \\(r^2\\) tienen distribuciones posteriores, ya que dependen de (la distribución posterior de) \\(\\theta\\).\nJuntando todo eso para resaltar la dependencia de \\(\\theta\\), obtenemos\n\\[MSE = \\frac{1}{n} \\sum_{i = 1}^n (y_i - E(y_i \\mid \\theta))^2\\]\n\n\n7.2.4.2 Densidad predictiva (logarítmica)\nOtra opción es calcular la densidad predictiva logarítmica (lpd):\n\\[\\mathrm{lpd}(\\theta; y) = \\log p(y \\mid \\theta)\\]\nUna vez más, \\(y\\) está fijado, por lo que esto es una función de \\(\\theta\\). De hecho, es simplemente la función de verosimilitud logarítmica. Para un valor dado de \\(\\theta\\), la lpd mide (en una escala logarítmica) la probabilidad de observar los datos. Un valor más grande indica un mejor ajuste. Nuevamente, debido a que la lpd es una función de \\(\\theta\\), también tiene una distribución posterior.\nAsumiendo que los valores de \\(y\\) son independientes dados los parámetros (y los valores predictores \\(x\\)), esto se puede escribir como\n\\[\n\\mathrm{lpd}(\\theta; y)\n= \\log p(y \\mid \\theta)\n= \\log \\prod_{i = 1}^n p(y_i \\mid \\theta)\n= \\sum_{i = 1}^n \\log p(y_i \\mid \\theta)\n\\]\nEn este caso, podemos calcular la densidad posterior logarítmica punto por punto y sumar. En la práctica, esto se hace a menudo incluso cuando no se cumple la independencia. Por lo tanto, técnicamente estamos trabajando con la densidad posterior logarítmica punto por punto:\n\\[\n\\mathrm{lppd}(\\theta; y)\n= \\sum_{i = 1}^n \\log p(y_i \\mid \\theta)\n\\]\nAl igual que el \\(SSE\\), el \\(MSE\\) y el \\(r^2\\), esto asigna una puntuación a cada \\(i\\) y luego suma esas puntuaciones.\nPara modelos lineales con ruido normal y priors uniformes, la lpd es proporcional al \\(MSE\\) (y al \\(SSE\\)).\n\n\n7.2.4.3 Predictores\nEn la notación anterior, hemos estado ocultando el papel de los predictores \\(x\\) (y continuaremos haciéndolo a continuación). Un modelo con predictores hace diferentes predicciones dependiendo de los valores de los predictores:\n\\[\n\\mathrm{lpd}(\\theta; y, x)\n= \\log p(y \\mid \\theta, x)\n\\]\n\n\n7.2.4.4 Números a partir de distribuciones\nPodemos convertir una medida \\(\\mathrm{lpd}(\\theta; y)\\), que depende de \\(\\theta\\), en un solo número de varias maneras. Ilustraremos esto a continuación:\n\nPodríamos reemplazar \\(\\theta\\) con un número particular \\(\\hat \\theta\\). (\\(\\hat \\theta\\) podría ser la media, la mediana o la moda de la distribución posterior, o la moda de la función de verosimilitud, por ejemplo). Si hacemos esto, obtenemos el número\n\n\\[\n\\mathrm{lpd}(\\hat \\theta; y)\n= \\log p(y \\mid \\hat\\theta)\n= \\sum_{i = 1}^n \\log p(y_i \\mid \\hat \\theta)\n\\] Esto a veces se llama una estimación “plug-in” ya que estamos insertando un solo número para \\(\\theta\\).\n\nEn lugar de resumir \\(\\theta\\) con un solo número, podríamos resumir \\(p(y_i \\mid \\theta)\\) con un solo número promediando sobre los valores de la muestra posterior \\(p(y_i \\mid \\theta^s)\\). (\\(\\theta^s\\) denota el valor de \\(\\theta\\) en la fila \\(s\\) de nuestras \\(S\\) muestras posteriores). Si sumamos sobre \\(i\\), obtenemos la densidad de verosimilitud posterior puntual logarítmica (lppd):\n\n\\[\\begin{align}\n\\mathrm{lppd}  \n&\\approx\n\\sum_{i = 1}^n \\log \\left( \\frac{1}{S} \\sum_{s = 1}^S  p(y_i \\mid \\theta^s)\\right)\n\\end{align}\\]\nEsto es una aproximación porque nuestras muestras posteriores son solo una aproximación a la verdadera distribución posterior. Pero si el tamaño efectivo de la muestra de la posterior es grande, esta aproximación debería ser muy buena.\nDesafortunadamente, ambas medidas (\\(MSE\\) y densidad predictiva logarítmica) tienen un problema. Miden qué tan bien el modelo se ajusta a los datos utilizados para ajustar el modelo, pero estamos más interesados en qué tan bien el modelo podría ajustarse a nuevos datos (generados por el mismo proceso aleatorio que generó los datos actuales). Esto lleva a sobreajuste y prefiere modelos más grandes y complejos, ya que la flexibilidad adicional de estos modelos hace que sea más fácil para ellos “ajustar los datos”.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 3)</span>"
    ]
  },
  {
    "objectID": "pensamiento.html",
    "href": "pensamiento.html",
    "title": "1  Pensamiento Bayesiano",
    "section": "",
    "text": "1.1 Ejemplo 1\np &lt;- seq(0.05,0.95,by = 0.1)\nprevia &lt;- c(1,5.2,8,7.2,4.6,2.1,0.7,0.1,0,0)\nprevia &lt;- previa / sum(previa)\nplot(p, previa, type = \"h\", ylab=\"Probabilidad previa\")\ndatos_sleep &lt;- c(11, 16)\ndatos_tot &lt;- data.frame(p = p, previa = previa)\ndatos_tot &lt;- datos_tot %&gt;% mutate(posterior = previa* p^(11)*(1-p)^(16)) %&gt;%\n  mutate(posterior = posterior/sum(posterior)) \nround(datos_tot,2)\n\n      p previa posterior\n1  0.05   0.03      0.00\n2  0.15   0.18      0.00\n3  0.25   0.28      0.13\n4  0.35   0.25      0.48\n5  0.45   0.16      0.33\n6  0.55   0.07      0.06\n7  0.65   0.02      0.00\n8  0.75   0.00      0.00\n9  0.85   0.00      0.00\n10 0.95   0.00      0.00\nComparación:\ndatos_tot_long &lt;- datos_tot %&gt;%\n  pivot_longer(previa:posterior,names_to = 'Type',values_to = 'Probability')\n\nggplot(datos_tot_long, aes(x = p, y = Probability, group = Type, color = Type)) +\n  geom_line(linewidth = 3) +\n  facet_wrap(~ Type, nrow =  2) +\n  theme_minimal()\nSegunda escogencia de previa \\(g(p)\\)\nEscogencia de los parámetros de la Beta:\nquantile1 &lt;- list(p = .5,x=.3)\nquantile2 &lt;- list(p=.9,x=.5)\nbeta.select(quantile1,quantile2)\n\n[1] 3.26 7.19\nComparación de densidades:\na &lt;- 3.26\nb &lt;- 7.19\ns &lt;- 11\nf &lt;- 16\n\nx_values &lt;- seq(0, 1, length.out = 1000)\ndf &lt;- data.frame(x = x_values,\n                 Prior = dbeta(x_values, a, b),\n                 Likelihood = dbeta(x_values, s + 1, f + 1),\n                 Posterior = dbeta(x_values, a + s, b + f))\n\n\nggplot(df, aes(x)) +\n  geom_line(aes(y = Prior), linetype = \"dashed\", size = 1.5, color = \"blue\") +\n  geom_line(aes(y = Likelihood), linetype = \"dotted\", size = 1.5, color = \"green\") +\n  geom_line(aes(y = Posterior), size = 1.5, color = \"red\") +\n  labs(x = \"p\", y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"blue\", \"green\", \"red\")) +\n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(title = \"Density\"))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\nPara responder parcialmente la pregunta de investigación:\n1 - pbeta(0.5, a + s, b + f)\n\n[1] 0.0690226\nes decir hay una probabilidad aproximadamente de 7% de que más de la mitad de los estudiantes universitarios duerman más de 8 horas diarias. O bien, si se quiere calcular la probabilidad de que la proporción de estudiantes sea mayor a lo observado:\n1 - pbeta(11/27, a + s, b + f)\n\n[1] 0.3603559\nIntervalo de credibilidad para \\(p\\):\nqbeta(c(0.05, 0.95), a + s, b + f)\n\n[1] 0.2555267 0.5133608\nen donde se infiere que \\(p\\) tiene una probabilidad del 95% de estar ubicado entre esos dos valores. El resultado anterior que es exacto, se puede aproximar usando simulación:\nps &lt;- rbeta(1000, a + s, b + f)\nhist(ps,xlab=\"p\",main=\"\")\ny la probabilidad de que \\(p&gt;0.5|\\text{datos}\\) se puede aproximar empíricamente:\nsum(ps &gt;= 0.5)/1000\n\n[1] 0.08\ny el intervalo de credibilidad correspondiente:\nquantile(ps, c(0.05, 0.95))\n\n       5%       95% \n0.2516540 0.5205972",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Pensamiento Bayesiano</span>"
    ]
  },
  {
    "objectID": "unparametro.html",
    "href": "unparametro.html",
    "title": "2  Modelos de un parámetro",
    "section": "",
    "text": "2.1 Ejemplo 1\nAnálisis del ejemplo de la página 37 del Gelman.\nUn estudio alemán concluyó que de un total de 980 nacimientos con condición de placenta previa, 437 nacieron niñas.\nPregunta de investigación: Qué tan evidente es la afirmación de que en la población de nacimientos de placenta previa, la proporción de nacimientos femeninos sea menor a 0.485?",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Modelos de un parámetro</span>"
    ]
  }
]
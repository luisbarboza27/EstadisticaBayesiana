[
  {
    "objectID": "variosparametros.html#ejemplo-1.-página-66-gelman.",
    "href": "variosparametros.html#ejemplo-1.-página-66-gelman.",
    "title": "3  Modelos de varios parámetros",
    "section": "3.1 Ejemplo 1. Página 66, Gelman.",
    "text": "3.1 Ejemplo 1. Página 66, Gelman.\nCargamos la librería MASS, que contiene los datos del experimento de Simon Newcomb en 1882:\n\nlibrary(MASS)\ndata(\"newcomb\")\n\nRecuerden que se busca estimar la velocidad media en la que la luz viaja en una distancia de 7442 metros.\nHistograma de los datos observados por Newcomb:\n\nhist(newcomb,breaks = 40)\n\n\n\n\ndonde se nota un cierto grado de simetría en la densidad excepto por los dos valores negativos de la serie.\nCon el fin de generar una muestra posterior multivariada de \\((\\mu,\\sigma^2)\\), primero generamos la muestra posterior de \\(\\sigma^2\\):\n\ns2 &lt;- var(newcomb)\nsigma2_pre &lt;- rchisq(n = 1000,df = 65)\nsigma2_post &lt;- sqrt(s2)/sigma2_pre\nhist(sigma2_post)\n\n\n\n\nla cual es una muestra de una variable según \\(Inv-\\chi^2(n-1,s^2)\\). La muestra de la media \\(\\mu|\\sigma^2,y\\) es:\n\nn_tot &lt;- length(newcomb)\nybar &lt;- mean(newcomb)\nmu_post &lt;- rnorm(n = 1000,mean = ybar,sd = sqrt(sigma2_post/n_tot))\nhist(mu_post)\n\n\n\n\nUn intervalo de credibilidad al 90% para \\(\\mu\\) (dado que \\(\\sigma\\) es fijo) es:\n\nquantile(mu_post,probs = c(0.05,0.95))\n\n      5%      95% \n26.13033 26.29706 \n\n\nVale la pena compararlo con un intervalo de credibilidad para \\(\\mu\\) sin considerar \\(\\sigma\\) fijo:\n\nybar + c(-1,1)*qt(0.95,df = 65)*sqrt(s2/n_tot)\n\n[1] 24.00509 28.41916\n\n\nel cual por supuesto va a ser más disperso.\nLa distribución posterior predictiva de una nueva observación del experimento, se infiere a través de una muestra:\n\ny_tilde_post &lt;- rnorm(n = 1000,mean = mu_post,sd = sqrt(sigma2_post))\nhist(y_tilde_post)\n\n\n\nquantile(y_tilde_post,probs = c(0.05,0.95))\n\n      5%      95% \n25.54431 26.87329 \n\n\ny este ultimo sería el intervalo de credibilidad al 90% para la nueva observación \\(\\tilde y\\)."
  },
  {
    "objectID": "variosparametros.html#ejemplo-2-sección-4.2-albert.",
    "href": "variosparametros.html#ejemplo-2-sección-4.2-albert.",
    "title": "3  Modelos de varios parámetros",
    "section": "3.2 Ejemplo 2: sección 4.2, Albert.",
    "text": "3.2 Ejemplo 2: sección 4.2, Albert.\nDatos de tiempos (en minutos) de corredores de maratón con edades entre 20 y 29 años:\n\nlibrary(LearnBayes)\ndata(\"marathontimes\")\nattach(marathontimes)\nhist(time)\n\n\n\n\n\n\n\n\nAsimismo se puede graficar una figura de contorno:\n\nd = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab=\"mean\",ylab=\"variance\")\n\n\n\n\n\n\n\n\nPor otro lado generamos una muestra posterior de los dos parámetros de interés, para incorporarlos en el gráfico anterior:\n\nS &lt;- sum((time-mean(time))^2)\n\nn &lt;- length(time)\n\nsigma2_post &lt;- S/rchisq(1000,n-1)\nhist(sigma2_post)\n\n\n\n\n\n\n\nmu_post &lt;- rnorm(n = 1000,mean = mean(time),sd = sqrt(sigma2_post/n))\nhist(mu_post)\n\n\n\n\n\n\n\n\nIncorporamos la muestra en el gráfico de la log-densidad-posterior:\n\nd = mycontour(normchi2post, c(220, 330, 500, 9000), time,xlab=\"mean\",ylab=\"variance\")\npoints(mu_post,sigma2_post)\n\n\n\n\n\n\n\n\nIntervalos de credibilidad para \\(\\mu|\\sigma^2, y\\) (en horas) y para \\(\\sigma^2|y\\) son:\n\nquantile(mu_post,c(0.025,0.975))/60\n\n    2.5%    97.5% \n4.250180 5.046258 \n\nquantile(sqrt(sigma2_post),c(0.025,0.975))\n\n    2.5%    97.5% \n38.13595 71.99675",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "variosparametros.html#ejemplo-3-sección-4.3-del-albert",
    "href": "variosparametros.html#ejemplo-3-sección-4.3-del-albert",
    "title": "3  Modelos de varios parámetros",
    "section": "3.3 Ejemplo 3: sección 4.3 del Albert",
    "text": "3.3 Ejemplo 3: sección 4.3 del Albert\n1447 adultos mostraron su preferencia de voto a Bush: \\(y_1=727\\), Dukakis: \\(y_2=583\\) y \\(y_3=137\\) a otros candidatos para la elección presidencial de 1988. Se asume que \\(y_1,y_2,y_3\\) sigue una distribución multinomial con parámetros \\(\\theta_1,\\theta_2,\\theta_3\\) respectivamente. Entonces la distribución posterior de estos parámetros sigue una distribución Dirichlet, simulados de la siguiente forma:\n\nalpha &lt;- c(728,584,138)\ntheta_post &lt;- rdirichlet(1000,alpha)\n\ncon histogramas:\n\nhist(theta_post[,1])\n\n\n\n\n\n\n\nhist(theta_post[,2])\n\n\n\n\n\n\n\nhist(theta_post[,3])\n\n\n\n\n\n\n\n\nEs de interés hacer inferencia acerca de la diferencia en la probabilidad de voto de Bush vs Dukakis: \\(\\theta_1-\\theta_2\\):\n\nhist(theta_post[,1]-theta_post[,2])\n\n\n\n\n\n\n\n\ny un intervalo de credibilidad al 95% para esta diferencia es:\n\nquantile(theta_post[,1]-theta_post[,2],c(0.025,0.975))\n\n      2.5%      97.5% \n0.05140505 0.14737474 \n\n\nPor lo tanto con una probabilidad del 95% la diferencia siempre faorece al primer candidato. Es más, si estimamos la probabilidad de que el segundo candidato resulte ganador:\n\nsum(theta_post[,1]-theta_post[,2]&lt;0)/1000\n\n[1] 0\n\n\nEsta probabilidad es nula.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "variosparametros.html#evaluación-práctica-3",
    "href": "variosparametros.html#evaluación-práctica-3",
    "title": "3  Modelos de varios parámetros",
    "section": "3.4 Evaluación Práctica 3",
    "text": "3.4 Evaluación Práctica 3\nDefinición de variables:\n\ny_N &lt;- 1601\nn_N &lt;- y_N+162527\n\ny_S &lt;- 510\nn_S &lt;- y_S+412368\n\nSimulación de 1000 valores de la distribución posterior conjunta de \\((p_N,p_S)\\):\n\np_N_post &lt;- rbeta(1000,shape1 = y_N+1,shape2 = n_N-y_N+1)\n\np_S_post &lt;- rbeta(1000,shape1 = y_S+1,shape2 = n_S-y_S+1)\n\nhist(p_N_post)\n\n\n\n\n\n\n\nhist(p_S_post)\n\n\n\n\n\n\n\n\nHistograma del riesgo relativo:\n\nriesgo_rel_post &lt;- p_N_post/p_S_post\nhist(riesgo_rel_post)\n\n\n\n\n\n\n\n\nIntervalo de credibilidad al 95% para el riesgo relativo:\n\nquantile(riesgo_rel_post,probs = c(0.025,0.975))\n\n    2.5%    97.5% \n7.157067 8.717791 \n\n\nHistograma de la diferencia en riesgos:\n\ndiferencia_post &lt;- p_N_post-p_S_post\nhist(diferencia_post)\n\n\n\n\n\n\n\n\nProbabilidad posterior de que la diferencia exceda 0:\n\nmean(diferencia_post&gt;0)\n\n[1] 1",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "pensamiento.html#ejemplo-1",
    "href": "pensamiento.html#ejemplo-1",
    "title": "1  Pensamiento Bayesiano",
    "section": "1.1 Ejemplo 1",
    "text": "1.1 Ejemplo 1\n\nPregunta de investigación: ¿Qué proporción de estudiantes universitarios duermen al menos 8 horas diarias?\nNotación: \\(p\\): proporción de estudiantes que duermen al menos 8 horas diarias.\nDatos: Muestra de 27 estudiantes donde 11 sí durmieron al menos 8 horas ayer.\nModelo: \\[L(p)\\propto p^s(1-p)^f\\]\nDistribución posterior: Si \\(g(p)\\) es la densidad previa de \\(p\\), entonces: \\[g(p|\\text{datos})\\propto g(p)L(p)\\] Primera escogencia de previa \\(g(p)\\)\n\n\np &lt;- seq(0.05,0.95,by = 0.1)\nprevia &lt;- c(1,5.2,8,7.2,4.6,2.1,0.7,0.1,0,0)\nprevia &lt;- previa / sum(previa)\nplot(p, previa, type = \"h\", ylab=\"Probabilidad previa\")\n\n\n\n\n\ndatos_sleep &lt;- c(11, 16)\ndatos_tot &lt;- data.frame(p = p, previa = previa)\ndatos_tot &lt;- datos_tot %&gt;% mutate(posterior = previa* p^(11)*(1-p)^(16)) %&gt;%\n  mutate(posterior = posterior/sum(posterior)) \nround(datos_tot,2)\n\n      p previa posterior\n1  0.05   0.03      0.00\n2  0.15   0.18      0.00\n3  0.25   0.28      0.13\n4  0.35   0.25      0.48\n5  0.45   0.16      0.33\n6  0.55   0.07      0.06\n7  0.65   0.02      0.00\n8  0.75   0.00      0.00\n9  0.85   0.00      0.00\n10 0.95   0.00      0.00\n\n\nComparación:\n\ndatos_tot_long &lt;- datos_tot %&gt;%\n  pivot_longer(previa:posterior,names_to = 'Type',values_to = 'Probability')\n\nggplot(datos_tot_long, aes(x = p, y = Probability, group = Type, color = Type)) +\n  geom_line(linewidth = 3) +\n  facet_wrap(~ Type, nrow =  2) +\n  theme_minimal()\n\n\n\n\nSegunda escogencia de previa \\(g(p)\\)\nEscogencia de los parámetros de la Beta:\n\nquantile1 &lt;- list(p = .5,x=.3)\nquantile2 &lt;- list(p=.9,x=.5)\nbeta.select(quantile1,quantile2)\n\n[1] 3.26 7.19\n\n\nComparación de densidades:\n\na &lt;- 3.26\nb &lt;- 7.19\ns &lt;- 11\nf &lt;- 16\n\nx_values &lt;- seq(0, 1, length.out = 1000)\ndf &lt;- data.frame(x = x_values,\n                 Prior = dbeta(x_values, a, b),\n                 Likelihood = dbeta(x_values, s + 1, f + 1),\n                 Posterior = dbeta(x_values, a + s, b + f))\n\n\nggplot(df, aes(x)) +\n  geom_line(aes(y = Prior), linetype = \"dashed\", size = 1.5, color = \"blue\") +\n  geom_line(aes(y = Likelihood), linetype = \"dotted\", size = 1.5, color = \"green\") +\n  geom_line(aes(y = Posterior), size = 1.5, color = \"red\") +\n  labs(x = \"p\", y = \"Density\") +\n  theme_minimal() +\n  scale_color_manual(values = c(\"blue\", \"green\", \"red\")) +\n  theme(legend.position = \"top\") +\n  guides(color = guide_legend(title = \"Density\"))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\nPara responder parcialmente la pregunta de investigación:\n\n1 - pbeta(0.5, a + s, b + f)\n\n[1] 0.0690226\n\n\nes decir hay una probabilidad aproximadamente de 7% de que más de la mitad de los estudiantes universitarios duerman más de 8 horas diarias. O bien, si se quiere calcular la probabilidad de que la proporción de estudiantes sea mayor a lo observado:\n\n1 - pbeta(11/27, a + s, b + f)\n\n[1] 0.3603559\n\n\nIntervalo de credibilidad para \\(p\\):\n\nqbeta(c(0.05, 0.95), a + s, b + f)\n\n[1] 0.2555267 0.5133608\n\n\nen donde se infiere que \\(p\\) tiene una probabilidad del 95% de estar ubicado entre esos dos valores. El resultado anterior que es exacto, se puede aproximar usando simulación:\n\nps &lt;- rbeta(1000, a + s, b + f)\nhist(ps,xlab=\"p\",main=\"\")\n\n\n\n\ny la probabilidad de que \\(p&gt;0.5|\\text{datos}\\) se puede aproximar empíricamente:\n\nsum(ps &gt;= 0.5)/1000\n\n[1] 0.08\n\n\ny el intervalo de credibilidad correspondiente:\n\nquantile(ps, c(0.05, 0.95))\n\n       5%       95% \n0.2516540 0.5205972 \n\n\n\n1.1.1 Predicción\nBajo la primera previa:\n\np &lt;- seq(0.05, 0.95, by=.1)\nprior &lt;- c(1, 5.2, 8, 7.2, 4.6, 2.1, 0.7, 0.1, 0, 0)\nprior &lt;- prior/sum(prior)\nm &lt;- 20\nys &lt;- 0:20\npred &lt;- pdiscp(p, prior, m, ys)\nround(cbind(0:20,pred),3)\n\n          pred\n [1,]  0 0.020\n [2,]  1 0.044\n [3,]  2 0.069\n [4,]  3 0.092\n [5,]  4 0.106\n [6,]  5 0.112\n [7,]  6 0.110\n [8,]  7 0.102\n [9,]  8 0.089\n[10,]  9 0.074\n[11,] 10 0.059\n[12,] 11 0.044\n[13,] 12 0.031\n[14,] 13 0.021\n[15,] 14 0.013\n[16,] 15 0.007\n[17,] 16 0.004\n[18,] 17 0.002\n[19,] 18 0.001\n[20,] 19 0.000\n[21,] 20 0.000\n\n\nBajo la segunda previa (beta):\n\nfy &lt;- choose(m,ys)*beta(a+ys,b = b+m-ys)/beta(a,b)\nab &lt;- c(3.26, 7.19)\npred &lt;- pbetap(ab, m, ys)\n\nO por simulación:\n\np &lt;- rbeta(1000, 3.26, 7.19)\ny &lt;- rbinom(1000, 20, p)\ntable(y)\n\ny\n  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  18 \n 21  44  72  87 103 114 102 109  91  82  68  40  26  17  13   7   3   1 \n\n\n\nfreq &lt;- table(y)\nys &lt;- as.integer(names(freq))\npredprob &lt;- freq / sum(freq)\n\ndf &lt;- data.frame(ys = ys, predprob = predprob)\n\n\nggplot(df, aes(x = ys, y = predprob)) +\n  geom_line(stat = \"identity\", type = \"h\", color = \"blue\", size = 1.5) +\n  labs(x = \"y\", y = \"Predictive Probability\") +\n  theme_minimal()\n\nWarning in geom_line(stat = \"identity\", type = \"h\", color = \"blue\", size =\n1.5): Ignoring unknown parameters: `type`\n\n\nDon't know how to automatically pick scale for object of type &lt;table&gt;.\nDefaulting to continuous.\n\n\n\n\n\nCálculo de intervalo de credibilidad al 90% usando la probabilidad predictiva anterior:\n\ndist &lt;- cbind(ys,predprob)\ncovprob &lt;- .9\ndiscint(dist,covprob)\n\n$prob\n   11 \n0.912 \n\n$set\n 1  2  3  4  5  6  7  8  9 10 11 \n 1  2  3  4  5  6  7  8  9 10 11"
  },
  {
    "objectID": "pensamiento.html#ejemplo-2-ejercicio-5-capítulo-2-albert",
    "href": "pensamiento.html#ejemplo-2-ejercicio-5-capítulo-2-albert",
    "title": "1  Pensamiento Bayesiano",
    "section": "1.2 Ejemplo 2 (Ejercicio 5, Capítulo 2, Albert)",
    "text": "1.2 Ejemplo 2 (Ejercicio 5, Capítulo 2, Albert)\nPrevia:\n\nprevia_mu &lt;- data.frame(mu = seq(20,70,by = 10),\n                        gmu = c(.1,.15,.25,.25,.15,.1))\n\nDatos:\n\ny_snow &lt;- c(38.6,42.4,57.5,40.5,51.7,67.1,33.4,\n            60.9,64.1,40.1,40.7,6.4)\ny_bar &lt;- mean(y_snow)\n\nVerosimilitud:\n\nposterior_mu &lt;- previa_mu %&gt;%\n  mutate(like = exp(-12/(2*10^2)*(mu-y_bar)^2))\n\nPosterior:\n\nposterior_mu &lt;- posterior_mu %&gt;% \n  mutate(post = gmu*like/sum(gmu*like))\nposterior_mu\n\n  mu  gmu         like         post\n1 20 0.10 2.201480e-17 1.954479e-17\n2 30 0.15 8.192991e-07 1.091063e-06\n3 40 0.25 1.873425e-01 4.158078e-01\n4 50 0.25 2.632064e-01 5.841881e-01\n5 60 0.15 2.272076e-06 3.025731e-06\n6 70 0.10 1.205079e-16 1.069871e-16\n\n\nIntervalo de credibilidad al 80% para \\(\\mu\\):\n\ndist_mu &lt;- posterior_mu %&gt;% select(mu,post)\ncovprob &lt;- .8\ndiscint(dist_mu,covprob)\n\n$prob\n[1] 0.9999959\n\n$set\n[1] 40 50\n\n\nTambién se podría estimar el intervalo de credibilidad vía simulación:\n\nmuestra_mu &lt;- sample(dist_mu$mu,size = 1000,replace = T,prob = dist_mu$post)\nquantile(muestra_mu,probs = c(0.1,0.9))\n\n10% 90% \n 40  50"
  },
  {
    "objectID": "pensamiento.html#ejemplo-3-evaluación-práctica-1",
    "href": "pensamiento.html#ejemplo-3-evaluación-práctica-1",
    "title": "1  Pensamiento Bayesiano",
    "section": "1.3 Ejemplo 3 (Evaluación Práctica 1)",
    "text": "1.3 Ejemplo 3 (Evaluación Práctica 1)\nLos siguientes datos simulan el sexo de 200 recién nacidos, en donde 1 denota niño y 0 denota niña.\n\nrecien_n\n\n  [1] 1 1 1 0 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0\n [38] 0 0 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 0 1\n [75] 1 1 1 0 1 1 0 1 1 0 1 1 0 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0\n[112] 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 1 0 0 1 1 0 1 1 0 1 0 1 0\n[149] 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n[186] 0 0 0 0 1 1 1 1 1 0 1 0 1 0 0\n\n\nVamos a utilizar dos distintas formas de definir numéricamente la previa:\n\n1.3.1 Previa 1\nSe va a definir una previa usando una grilla de tamaño 1000 con 100000 muestras:\n\nset.seed(10)\np_prev_sample &lt;- runif(n = 100000)\nhisto_1 &lt;- hist(p_prev_sample,breaks = 1000)\n\n\n\np_post1 &lt;- data.frame(p = histo_1$breaks[-1],prev = histo_1$counts)\n\np_post1 &lt;- p_post1 %&gt;% mutate(prev = prev / sum(prev))\n\nCálculo de probabilidad posterior y valor de \\(p\\) que la maximiza:\n\ny &lt;- sum(recien_n)\nn_tot &lt;- length(recien_n)\np_post1 &lt;- p_post1 %&gt;% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %&gt;%\n  mutate(post = post / sum(post))\nplot(p_post1$p,p_post1$post,type='l')\n\n\n\n\nValor que maximiza la posterior:\n\np_post1$p[which.max(p_post1$post)]\n\n[1] 0.606\n\n\n\n\n1.3.2 Previa 2\nSe va a definir una previa usando una grilla de tamaño 10 con 1000 muestras:\n\nset.seed(10)\np_prev_sample &lt;- runif(n = 1000)\nhisto_2 &lt;- hist(p_prev_sample,breaks = 10)\n\n\n\np_post2 &lt;- data.frame(p = histo_2$breaks[-1],prev = histo_2$counts)\n\np_post2 &lt;- p_post2 %&gt;% mutate(prev = prev / sum(prev))\n\nCálculo de probabilidad posterior y valor de \\(p\\) que la maximiza:\n\np_post2 &lt;- p_post2 %&gt;% mutate(post = prev * p^y*(1-p)^(n_tot-y)) %&gt;%\n  mutate(post = post / sum(post))\nplot(p_post2$p,p_post2$post,type='l')\n\n\n\n\nValor que maximiza la posterior:\n\np_post2$p[which.max(p_post2$post)]\n\n[1] 0.6\n\n\nDe ahora en adelante se utilizará la primera previa para calcular la muestra de tamaño 10000 de la distribución posterior:\n\nmuestra_post &lt;- sample(p_post1$p,replace = T,size = 10000,prob = p_post1$post)\n\nCálculo del intervalo de credibilidad al 90%:\n\nquantile(muestra_post,probs = c(0.05,0.95))\n\n   5%   95% \n0.552 0.666 \n\n\nde donde se deduce que con una probabilidad de 90%, el parámetro \\(p\\) (proporción de niños) esté contenido en el intervalo \\((0.55,0.67)\\).\nAhora vamos a estimar la probabilidad posterior de que un recién nacido fuera de la muestra sea niño:\n\ny_post &lt;- rbinom(n = 1000,prob = muestra_post,size = 1)\n\nprob_prediccion &lt;- sum(y_post)/1000\nprob_prediccion\n\n[1] 0.609"
  },
  {
    "objectID": "unparametro.html#ejemplo-1",
    "href": "unparametro.html#ejemplo-1",
    "title": "2  Modelos de un parámetro",
    "section": "2.1 Ejemplo 1",
    "text": "2.1 Ejemplo 1\nAnálisis del ejemplo de la página 37 del Gelman.\nUn estudio alemán concluyó que de un total de 980 nacimientos con condición de placenta previa, 437 nacieron niñas.\nPregunta de investigación: Qué tan evidente es la afirmación de que en la población de nacimientos de placenta previa, la proporción de nacimientos femeninos sea menor a 0.485?"
  },
  {
    "objectID": "unparametro.html#primera-previa",
    "href": "unparametro.html#primera-previa",
    "title": "2  Modelos de un parámetro",
    "section": "2.2 Primera previa",
    "text": "2.2 Primera previa\nSuponga que \\(\\theta\\): proporción de niñas que nacieron bajo la condición de placenta previa. Usando una previa uniforme para \\(\\theta\\) en (0,1), la media posterior es \\(Beta(438,544)\\):\n\na_post &lt;- 438\nb_post &lt;- 544\n\npor lo tanto la media y la desviación posterior del parámetro \\(\\theta\\) es:\n\nmedia_post &lt;- a_post/(a_post+b_post)\nsd_post &lt;- sqrt(media_post*(1-media_post)/983)\n\nComo la posterior es beta, se puede calcular directamente que un intervalo de credibilidad al 95% es \\((0.415,0.477)\\), lo cual se puede comprobar de manera aproximada al calcular:\n\npbeta(0.477,shape1 = a_post,shape2 = b_post)-\n  pbeta(0.415,shape1 = a_post,shape2 = b_post)\n\n[1] 0.9495027\n\n\nPor la justificación vista en clase, se puede aproximar la distribución posterior con una distribución normal y calcular directamente los límites del intervalo de credibilidad a como sigue:\n\ncuantil0975_norm &lt;- media_post+qnorm(0.975)*sd_post\ncuantil025_norm &lt;- media_post-qnorm(0.975)*sd_post\nc(cuantil025_norm,cuantil0975_norm)\n\n[1] 0.4149546 0.4771025\n\n\nAsimismo, podemos obtener una muestra aleatoria de la posterior de la sifuiente forma:\n\ntheta_post &lt;- rbeta(1000,shape1 = a_post,b_post)\nhist(theta_post)\n\n\n\n\ny así calcular el mismo intervalo de credibilidad:\n\nquantile(theta_post,probs = c(0.025,0.975))\n\n     2.5%     97.5% \n0.4137056 0.4769427 \n\n\ny un estimador puntual bayesiano para \\(\\theta\\):\n\nmedian(theta_post)\n\n[1] 0.4451357\n\n\nPor otro lado también podemos usar la reparametrización \\(\\phi=\\log\\left(\\frac{\\theta}{1-\\theta}\\right)\\) para aplicar la aproximación normal sobre un parámetro totalmente definido en \\(\\mathbb R\\):\n\nphi_post &lt;- log(theta_post/(1-theta_post))\nhist(phi_post)\n\n\n\nphi_mean &lt;- mean(phi_post)\nphi_sd &lt;- sd(phi_post)\n\ny de esta forma aproximar el mismo intervalo de credibilidad para \\(\\theta\\), usando la transformación logística:\n\nlogistico &lt;- function(u){\n  exp(u)/(1+exp(u))\n}\n\nlogistico(phi_mean+qnorm(0.975)*phi_sd)\n\n[1] 0.4766789\n\nlogistico(phi_mean-qnorm(0.975)*phi_sd)\n\n[1] 0.4133679\n\n\nTambién podemos hacer inferencia sobre la razón niña/niño (\\(\\theta/(1-\\theta)\\)):\n\nrazon_post &lt;- theta_post/(1-theta_post)\nquantile(razon_post,probs = c(0.025,0.975))\n\n     2.5%     97.5% \n0.7056280 0.9118364 \n\n\nLa pregunta de investigación puede ser contestada al calcular lo siguiente e interpretarlo de forma apropiada según lo comentado en clase:\n\npbeta(0.485,shape1 = a_post,shape2 = b_post)\n\n[1] 0.992826\n\n\nAsimismo, podemos calcular el periodo de retorno del evento principal al calcular:\n\n1/pbeta(0.485,shape1 = a_post,shape2 = b_post,lower.tail = F)\n\n[1] 139.392"
  },
  {
    "objectID": "unparametro.html#ejemplo-2",
    "href": "unparametro.html#ejemplo-2",
    "title": "2  Modelos de un parámetro",
    "section": "2.3 Ejemplo 2",
    "text": "2.3 Ejemplo 2\nDesarrollamos una solución alternativa al ejemplo en la sección 3.2 del Albert:\nEn este caso se tiene datos correspondientes a las diferencias entre los resultados de partidos de fútbol americano y “point spreads”:\n\nlibrary(LearnBayes)\ndata(\"footballscores\")\nattach(footballscores)\nd &lt;- favorite-underdog-spread\n\nSi asumimos un modelo normal en las diferencias con media 0 y varianza \\(\\sigma^2\\), el estadístico suficiente respectivo es:\n\nv &lt;- sum(d^2)\nn &lt;- length(d)\nshow(v)\n\n[1] 128902\n\n\nAsumiendo una distribución previa \\(Inv-\\chi^2(v_0=1, \\sigma^2_0=1)\\), según lo visto en clase, la probabilidad posterior de \\(\\sigma^2\\) es \\(Inv-\\chi^2(v_1=n+1, \\sigma^2_1=nv+1)\\) en donde:\n\nv1 &lt;- n+1\nsigma1 &lt;- sqrt(n*v+1) \n\nSimulamos una muestra de tamaño 1000 de la distribución posterior de \\(\\sigma^2\\). Noten que la simulación usa las propiedades de una chi-cuadrado inversa.\n\nXpost &lt;- rchisq(n = 1000,df = n+1) \nZ &lt;- 1/Xpost\nsigma2_post &lt;- sigma1*Z\n\nO bien pueden usar la siguiente función que simula las muestras directamente:\n\nlibrary(LaplacesDemon)\n\n\nAttaching package: 'LaplacesDemon'\n\n\nThe following object is masked from 'package:LearnBayes':\n\n    rdirichlet\n\nsigma2_post2 &lt;- rinvchisq(n = 1000,df = v1,scale = sigma1/v1)\n\nNoten que el parametro de escala en esta función hay que dividirlo por los grados de libertad para que sea igual al que definimos en clase. En ambos casos se puede calcular un intervalo de credibilidad al 95% y un estimador puntual de \\(\\sigma^2\\):\n\nquantile(sigma2_post, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n12.50771 13.81855 15.51500 \n\nquantile(sigma2_post2, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n12.39380 13.80629 15.41711"
  },
  {
    "objectID": "unparametro.html#ejemplo-3",
    "href": "unparametro.html#ejemplo-3",
    "title": "2  Modelos de un parámetro",
    "section": "2.4 Ejemplo 3",
    "text": "2.4 Ejemplo 3\nConsidere el ejemplo de la página 45 del Gelman, en donde se modela la tasa de muerte producto del asma en una ciudad de Estados Unidos. La población de la ciudad es de 200000 personas. En un año han fallecido 3 personas, dando una tasa cruda de:\n\n3/200000\n\n[1] 1.5e-05\n\n\n1.5 muertes por 100000 habitantes. Asumimos que el conteo de muertes \\(y\\sim Poisson(2\\theta)\\) indicando que la tasa se mide en número de casos por 100000 habitantes, con una población expuesta de \\(2\\times 100000\\) habitantes. Asumiendo una previa \\(\\theta \\sim Gamma(3,5)\\) se tiene un valor esperado (previo) de la tasa de muerte de:\n\n3/5\n\n[1] 0.6\n\n\npor cada 100000 habitantes. Note que en este caso hay una probabilidad previa de más de un 97.5% de que la tasa de muerte esté por debajo de 1.44:\n\npgamma(1.5,shape = 3,rate = 5)\n\n[1] 0.9797433\n\n\nUna muestra posterior de \\(\\theta\\) asumiendo que \\(y=3\\) es:\n\ntheta_post &lt;- rgamma(n = 1000,shape = 6,rate = 7)\n\ny gráficamente:\n\nhist(theta_post)\n\n\n\n\ny un intervalo de credibilidad al 95% sería:\n\nquantile(theta_post, probs = c(0.025, 0.5, 0.975))\n\n     2.5%       50%     97.5% \n0.3243252 0.8210934 1.6520077 \n\n\nSi se observara la misma cantidad de muertes por año en la misma ciudad en un periodo de 10 años, y asumimos que la población es constante, la posterior la podemos muestrear de la siguiente forma:\n\ntheta_post2 &lt;- rgamma(n = 1000,shape = 33,rate = 25)\nhist(theta_post2)\n\n\n\n\ny el intervalo de credibilidad correspondiente para \\(\\theta\\) al 95% sería:\n\nquantile(theta_post2, probs = c(0.025, 0.5, 0.975))\n\n    2.5%      50%    97.5% \n0.931524 1.310252 1.854992"
  },
  {
    "objectID": "unparametro.html#evaluación-práctica-2",
    "href": "unparametro.html#evaluación-práctica-2",
    "title": "2  Modelos de un parámetro",
    "section": "2.5 Evaluación Práctica 2",
    "text": "2.5 Evaluación Práctica 2\nTiempo de quemado de las cinco bombillas:\n\ny &lt;- c(751,594,1213,1126,819)\n\nSimulación de la distribución posterior de \\(\\theta\\):\n\nn_tot &lt;- length(y)\ns &lt;- sum(y)\ntheta_post &lt;- rgamma(n = 1000,shape = n_tot,rate = s)\nhist(theta_post)\n\n\n\n\nMuestra posterior de \\(\\lambda\\):\n\nlambda_post &lt;- 1/theta_post\nhist(lambda_post)\n\n\n\n\nLa probabilidad posterior de que \\(\\lambda\\) exceda las 1000 horas se puede estimar:\n\nsum(lambda_post&gt;1000)/1000\n\n[1] 0.446\n\n\nLa probabilidad predictiva posterior del tiempo de quemado de una bombilla es:\n\ny_tilde &lt;- rexp(n = 1000,rate = 1/lambda_post)\ny_tilde_freq &lt;- hist(y_tilde,breaks = 20)\n\n\n\ny_tilde_x &lt;- y_tilde_freq$mids\ny_tilde_post &lt;- y_tilde_freq$counts/1000\nplot(y_tilde_x,y_tilde_post,type='l',ylab = 'Prob. Post.')\n\n\n\n\nIntervalo de credibilidad al 90% para el tiempo de quemado:\n\nquantile(y_tilde,probs = c(0.05,0.95))\n\n        5%        95% \n  44.79943 3585.42291"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Inferencia Bayesiana",
    "section": "",
    "text": "Prefacio\nNotas computacionales del curso XS0128 (Inferencia Bayesiana) para el I-2024."
  },
  {
    "objectID": "variosparametros.html",
    "href": "variosparametros.html",
    "title": "3  Modelos de varios parámetros",
    "section": "",
    "text": "3.1 Ejemplo 1. Página 66, Gelman.\nCargamos la librería MASS, que contiene los datos del experimento de Simon Newcomb en 1882:\nlibrary(MASS)\ndata(\"newcomb\")\nRecuerden que se busca estimar la velocidad media en la que la luz viaja en una distancia de 7442 metros.\nHistograma de los datos observados por Newcomb:\nhist(newcomb,breaks = 40)\ndonde se nota un cierto grado de simetría en la densidad excepto por los dos valores negativos de la serie.\nCon el fin de generar una muestra posterior multivariada de \\((\\mu,\\sigma^2)\\), primero generamos la muestra posterior de \\(\\sigma^2\\):\ns2 &lt;- var(newcomb)\nsigma2_pre &lt;- rchisq(n = 1000,df = 65)\nsigma2_post &lt;- sqrt(s2)/sigma2_pre\nhist(sigma2_post)\nla cual es una muestra de una variable según \\(Inv-\\chi^2(n-1,s^2)\\). La muestra de la media \\(\\mu|\\sigma^2,y\\) es:\nn_tot &lt;- length(newcomb)\nybar &lt;- mean(newcomb)\nmu_post &lt;- rnorm(n = 1000,mean = ybar,sd = sqrt(sigma2_post/n_tot))\nhist(mu_post)\nUn intervalo de credibilidad al 90% para \\(\\mu\\) (dado que \\(\\sigma\\) es fijo) es:\nquantile(mu_post,probs = c(0.05,0.95))\n\n      5%      95% \n26.13126 26.29339\nVale la pena compararlo con un intervalo de credibilidad para \\(\\mu\\) sin considerar \\(\\sigma\\) fijo:\nybar + c(-1,1)*qt(0.95,df = 65)*sqrt(s2/n_tot)\n\n[1] 24.00509 28.41916\nel cual por supuesto va a ser más disperso.\nLa distribución posterior predictiva de una nueva observación del experimento, se infiere a través de una muestra:\ny_tilde_post &lt;- rnorm(n = 1000,mean = mu_post,sd = sqrt(sigma2_post))\nhist(y_tilde_post)\n\n\n\n\n\n\n\nquantile(y_tilde_post,probs = c(0.05,0.95))\n\n      5%      95% \n25.56766 26.91178\ny este ultimo sería el intervalo de credibilidad al 90% para la nueva observación \\(\\tilde y\\).",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modelos de varios parámetros</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-capítulo-5-albert.",
    "href": "computacion_bayes.html#ejemplo-capítulo-5-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.1 Ejemplo Capítulo 5, Albert.",
    "text": "4.1 Ejemplo Capítulo 5, Albert.\nLibrerías:\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(LearnBayes)\n\nDatos de número de casos de cáncer de estómago en hombres en ciudades de Missouri, USA:\n\ndata(\"cancermortality\")\n\nGráfico de contorno de la logverosimilitud del modelo beta-binomial, ante la posible presencia de sobredispersión:\n\nmycontour(betabinexch0,c(.0001,.003,1,20000),cancermortality,\n          xlab=\"eta\",ylab=\"K\")\n\n\n\n\nen donde se evidencia una alta asimetría en ambos parámetros. Se reparametriza el modelo usando las transformaciones \\(\\theta_1=\\log\\left(\\frac{\\eta}{1-\\eta}\\right)\\), \\(\\theta_2=\\log K\\) y se obtiene la siguiente logverisimilitud transformada:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\n\n\n\n\nAproximamos la log-densidad posterior usando el método de Laplace:\n\nfit &lt;- laplace(betabinexch,c(-7,6),cancermortality)\n\ncon el gráfico de contorno de log-verosimilitud:\n\nnpar=list(m=fit$mode,v=fit$var)\nmycontour(lbinorm,c(-8,-4.5,3,16.5),npar,\n              xlab=\"logit eta\", ylab=\"log K\")\n\n\n\n\nPor lo tanto podemos sacar muestras posteriores de los parámetros transformados a través de una normal multivariada:\n\nset.seed(10)\nlibrary(mvtnorm)\nmu_sigma_post &lt;- rmvnorm(1000,mean = npar$m,sigma = npar$v)\n\ny graficamos los puntos sobre el gráfico de contorno:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\npoints(mu_sigma_post,add=T)\n\nWarning in plot.xy(xy.coords(x, y), type = type, ...): \"add\" is not a graphical\nparameter"
  },
  {
    "objectID": "computacion_bayes.html",
    "href": "computacion_bayes.html",
    "title": "4  Computación Bayesiana",
    "section": "",
    "text": "4.1 Ejemplo Capítulo 5, Albert.\nLibrerías:\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(LearnBayes)\nDatos de número de casos de cáncer de estómago en hombres en ciudades de Missouri, USA:\ndata(\"cancermortality\")\nGráfico de contorno de la logverosimilitud del modelo beta-binomial, ante la posible presencia de sobredispersión:\nmycontour(betabinexch0,c(.0001,.003,1,20000),cancermortality,\n          xlab=\"eta\",ylab=\"K\")\nen donde se evidencia una alta asimetría en ambos parámetros. Se reparametriza el modelo usando las transformaciones \\(\\theta_1=\\log\\left(\\frac{\\eta}{1-\\eta}\\right)\\), \\(\\theta_2=\\log K\\) y se obtiene la siguiente logverisimilitud transformada:\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\nAproximamos la log-densidad posterior usando el método de Laplace:\nfit &lt;- laplace(betabinexch,c(-7,6),cancermortality)\ncon el gráfico de contorno de log-verosimilitud:\nnpar=list(m=fit$mode,v=fit$var)\nmycontour(lbinorm,c(-8,-4.5,3,16.5),npar,\n              xlab=\"logit eta\", ylab=\"log K\")\nPor lo tanto podemos sacar muestras posteriores de los parámetros transformados a través de una normal multivariada:\nset.seed(10)\nlibrary(mvtnorm)\nmu_sigma_post &lt;- rmvnorm(1000,mean = npar$m,sigma = npar$v)\ny graficamos los puntos sobre el gráfico de contorno:\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n            xlab=\"logit eta\",ylab=\"log K\")\npoints(mu_sigma_post,add=T)\n\nWarning in plot.xy(xy.coords(x, y), type = type, ...): \"add\" is not a graphical\nparameter\nA partir de esta muestra es posible obtener un intervalo de credibilidad exacto para cada parámetro usando el supuesto de normalidad:\nnpar$m[1]+c(-1,1)*qnorm(0.975)*sqrt(npar$v[1,1])\n\n[1] -7.370559 -6.269027\n\nnpar$m[2]+c(-1,1)*qnorm(0.975)*sqrt(npar$v[2,2])\n\n[1] 5.300255 9.851966\ny por otro lado se puede calcular los intervalos de credibilidad directamente sobre la muestra:\nquantile(mu_sigma_post[,1],probs = c(0.025,0.975))\n\n     2.5%     97.5% \n-7.371918 -6.223499 \n\nquantile(mu_sigma_post[,2],probs = c(0.025,0.975))\n\n    2.5%    97.5% \n5.244524 9.866338",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-5.7-albert",
    "href": "computacion_bayes.html#ejemplo-sección-5.7-albert",
    "title": "4  Computación Bayesiana",
    "section": "4.2 Ejemplo sección 5.7, Albert",
    "text": "4.2 Ejemplo sección 5.7, Albert\nEn un ejemplo anterior se había calculado la distribución posterior de la proporción de estudiantes que dormían más de 8 horas (\\(p\\)). Si queremos calcular los estimadores Monte Carlo de la probabilidad de que dos estudiantes duerman más de 8 horas (\\(p^2\\)) sería:\n\np_posterior &lt;- rbeta(1000,14.26,23.19)\nhist(p_posterior)\n\n\n\n\n\n\n\nest_posterior &lt;- mean(p_posterior^2)\nest_posterior\n\n[1] 0.1507735\n\nse_posterior &lt;- sd(p_posterior^2)/sqrt(1000)\nse_posterior\n\n[1] 0.001911799\n\n\ny a partir de esto se aproxima (usando el Teorema del Límite Central) un intervalo de credibilidad para \\(p^2\\):\n\nest_posterior+c(-1,1)*qnorm(0.975)*se_posterior\n\n[1] 0.1470265 0.1545206",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#continuación-ejemplo-5-albert.",
    "href": "computacion_bayes.html#continuación-ejemplo-5-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.3 Continuación Ejemplo 5, Albert.",
    "text": "4.3 Continuación Ejemplo 5, Albert.\nEn este caso usaremos el algoritmo de rechazo como una forma de mejorar el proceso de muestreo obtenido a través del método de Laplace. Recuerden que para utilizar este algoritmo se necesita una distribución propuesta (\\(p(\\theta)\\)) que aproxime la distribución posterior sin tomar en cuenta la constante de normalización. Si asumimos una distribución t de Student multivariada como propuesta, entonces podemos encontrar una cota superior para la diferencia entre las log-densidades a través de:\n\nbetabinT=function(theta,datapar){\n  data=datapar$data\n  tpar=datapar$par\n  d=betabinexch(theta,data)-dmt(theta,mean=c(tpar$m),\n                                S=tpar$var,df=tpar$df,log=TRUE)\n  return(d)\n}\n\ntpar=list(m=fit$mode,var=2*fit$var,df=4)\ndatapar=list(data=cancermortality,par=tpar)\n\nstart=c(-6.9,12.4)\nfit1=laplace(betabinT,start,datapar)\n\nde donde se observa que un posible valor para la diferencia sería:\n\nbetabinT(fit1$mode,datapar)\n\n[1] -569.2829\n\n\ny usamos este valor para obtener una muestra posterior de los parámetros usando el algoritmo de rechazo:\n\nset.seed(10)\ntheta=rejectsampling(betabinexch,tpar,-569.2813,10000,\n                     cancermortality)\n\nNoten que la proporción de aceptación en la muestra es:\n\ndim(theta)[1]/10000\n\n[1] 0.2411\n\n\ny además podemos ver la mejora en la capacidad de la muestra posterior de estar localizada en regiones de alta probabilidad:\n\nmycontour(betabinexch,c(-8,-4.5,3,16.5),cancermortality,\n          xlab=\"logit eta\",ylab=\"log K\")\npoints(theta[,1],theta[,2])",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-6.2-albert.",
    "href": "computacion_bayes.html#ejemplo-sección-6.2-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.4 Ejemplo sección 6.2, Albert.",
    "text": "4.4 Ejemplo sección 6.2, Albert.\nEn este ejemplo se ilustra una cadena discreta de Markov en donde una persona se mueve aleatoriamente en un conjunto de 6 estados solamente con un paso a la vez, y puede permanecer en el mismo estado de origen en cualquier momento. Si la probabilidad de permanecer en el mismo estado es igual a la probabilidad de avanzar o retroceder una posición, y asimismo las probabilidades de avanzar o retroceder son iguales, entonces la matriz de transición de la cadena de Markov asociada a este ejemplo es:\n\nP &lt;- matrix(c(.5,.5,0,0,0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,\n           0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,0,0,.5,.5),\n         nrow=6,ncol=6,byrow=TRUE)\nP\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,] 0.50 0.50 0.00 0.00 0.00 0.00\n[2,] 0.25 0.50 0.25 0.00 0.00 0.00\n[3,] 0.00 0.25 0.50 0.25 0.00 0.00\n[4,] 0.00 0.00 0.25 0.50 0.25 0.00\n[5,] 0.00 0.00 0.00 0.25 0.50 0.25\n[6,] 0.00 0.00 0.00 0.00 0.50 0.50\n\n\nSi asumimos que la persona empieza en el estado 3 y simulamos el proceso de Markov a lo largo de 50000 pasos:\n\ns=array(0,c(50000,1))\ns[1] &lt;- 3\nset.seed(10)\n\nfor (j in 2:50000){\n  s[j]=sample(1:6,size=1,prob=P[s[j-1],])\n}\n\nGraficamente, los últimos 1000 pasos se pueden representar:\n\nplot(tail(s,1000),type='l')\n\n\n\n\n\n\n\n\nDebido a que esta cadena de Markov es irreducible y aperiódica existe una distribución estacionaria que vamos a aproximar a través del cálculo de la frecuencia relativa en cada uno de los 6 estados:\n\nm=c(500,2000,8000,50000)\n\nfor (i in 1:4){\n  print(table(s[1:m[i]])/m[i])\n}\n\n\n    1     2     3     4     5     6 \n0.118 0.178 0.144 0.222 0.234 0.104 \n\n     1      2      3      4      5      6 \n0.0570 0.1285 0.1640 0.2315 0.2770 0.1420 \n\n       1        2        3        4        5        6 \n0.088625 0.185875 0.206125 0.209750 0.204250 0.105375 \n\n      1       2       3       4       5       6 \n0.09806 0.19734 0.19652 0.20452 0.20450 0.09906 \n\n\nlo cual parece indicar de que hay convergencia a una frecuencia relativa estable por clase. La distribución estacionaria exacta se calcula a través del vector propio asociado al valor propio igual a 1 de la matriz \\(P^T\\):\n\neig_des &lt;- eigen(t(P))\neig_des$values\n\n[1]  1.000000e+00  9.045085e-01  6.545085e-01  3.454915e-01  9.549150e-02\n[6] -3.678415e-17\n\ndist_estacionaria &lt;- eig_des$vectors[,1]\ndist_estacionaria &lt;- dist_estacionaria /sum(dist_estacionaria)\nshow(dist_estacionaria)\n\n[1] 0.1 0.2 0.2 0.2 0.2 0.1",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#ejemplo-sección-6.7-albert.",
    "href": "computacion_bayes.html#ejemplo-sección-6.7-albert.",
    "title": "4  Computación Bayesiana",
    "section": "4.5 Ejemplo sección 6.7, Albert.",
    "text": "4.5 Ejemplo sección 6.7, Albert.\nUsando la siguiente tabla de datos agrupados, queremos hacer inferencia de la media \\(\\mu\\) y desviación estándar \\(\\sigma\\) de la altura en pulgadas de hombres universitarios:\n\nd=list(int.lo=c(-Inf,seq(66,74,by=2)),\n         int.hi=c(seq(66,74,by=2), Inf),\n         f=c(14,30,49,70,33,15))\nshow(d)\n\n$int.lo\n[1] -Inf   66   68   70   72   74\n\n$int.hi\n[1]  66  68  70  72  74 Inf\n\n$f\n[1] 14 30 49 70 33 15\n\n\ndonde los vectores int.hi y int.lo indican los límites superiores e inferiores de los datos agrupados (en pulgadas). El vector f indica la frecuencia de individuos por intervalo. Asumiendo una distribución normal en la altura de los individuos, y tomando la transformación \\(\\lambda=\\log(\\sigma)\\), la distribución posterior se implementaría:\n\ngroupeddatapost=function(theta,data)\n{\n  dj = function(f, int.lo, int.hi, mu, sigma)\n    f * log(pnorm(int.hi, mu, sigma) -\n              pnorm(int.lo, mu, sigma))\n  mu = theta[1]\n  sigma = exp(theta[2])\n  sum(dj(data$f, data$int.lo, data$int.hi, mu, sigma))\n}\n\nPrimero aproximamos la posterior a través de una normal multivariada con el método de Laplace. Para ello simulamos observaciones por nivel en la tabla agrupada, asumiendo que las alturas son constantes por grupo:\n\ny &lt;- c(rep(65,14),rep(67,30),rep(69,49),rep(71,70),rep(73,33),\n    rep(75,15))\n\nmean(y)\n\n[1] 70.16588\n\nlog(sd(y))\n\n[1] 0.9504117\n\n\ny a partir de lo anterior tomamos como punto inicial (70,1) en el algoritmo de Laplace:\n\nstart &lt;- c(70,1)\nfit &lt;- laplace(groupeddatapost,start,d)\n\ny recuerden que se pueden generar muestras posteriores de \\((\\mu,\\lambda)\\) con este método:\n\nmu_lambda_post &lt;- rmvnorm(5000,mean = fit$m,sigma = fit$v)\n\nUsando el cálculo anterior, tomamos como propuesta en el algoritmo de Metropolis-Hastings con caminata aleatoria una normal multivariada con escala = 2 y la misma matriz de varianza-covarianza anterior:\n\nproposal &lt;- list(var=fit$var,scale=2)\nbayesfit &lt;- rwmetrop(groupeddatapost,proposal,start,10000,d)\n\nLa muestra posterior resultante tuvo una tasa de aceptación de:\n\nbayesfit$accept\n\n[1] 0.2904\n\n\nEl paquete coda nos permite graficar los traceplots de cada muestra posterior. Antes de eso, definimos un objeto mcmc de coda:\n\nlibrary(coda)\ndimnames(bayesfit$par)[[2]]=c(\"mu\",\"log sigma\")\nmcmc_ej &lt;- mcmc(bayesfit$par[-c(1:2000),]) \n\n\nlibrary(coda)\nlibrary(lattice)\nxyplot(mcmc_ej,col=\"black\")\n\n\n\n\n\n\n\n\nNote que usamos un periodo de quemado (burn-in) del 2000 muestras. También podemos incluir un gráfico de autocorrelación:\n\npar(mfrow=c(2,1))\nautocorr.plot(mcmc_ej,auto.layout=FALSE)\n\n\n\n\n\n\n\n\ny por otro lado uno puede tener un resumen de las muestras posteriores vía MCMC:\n\nsummary(mcmc_ej)\n\n\nIterations = 1:8000\nThinning interval = 1 \nNumber of chains = 1 \nSample size per chain = 8000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n             Mean      SD  Naive SE Time-series SE\nmu        70.1678 0.19553 0.0021861       0.006537\nlog sigma  0.9799 0.05809 0.0006495       0.002016\n\n2. Quantiles for each variable:\n\n             2.5%     25%     50%    75%  97.5%\nmu        69.7960 70.0390 70.1741 70.293 70.551\nlog sigma  0.8729  0.9407  0.9784  1.019  1.095",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos.html",
    "href": "estimacion_modelos.html",
    "title": "5  Estimación de Modelos Bayesianos",
    "section": "",
    "text": "5.1 Sesgo de una moneda (Kruschke, pag 195)\nCarga de librería rjags y funciones utilitarias del Kruschke:\nlibrary(rjags)\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\nsource('DBDA2Eprograms/DBDA2E-utilities.R')\n\n\n*********************************************************************\nKruschke, J. K. (2015). Doing Bayesian Data Analysis, Second Edition:\nA Tutorial with R, JAGS, and Stan. Academic Press / Elsevier.\n*********************************************************************\nCarga de datos y definición de la estructura de datos para JAGS. Los datos se pueden entender como realizaciones de lanzamientos de una moneda (0: escudo, 1: corona; por ejemplo)\nmyData = read.csv(\"DBDA2Eprograms/z15N50.csv\") \ny = myData$y        \nNtotal = length(y)  \ndataList = list(    \n  y = y ,\n  Ntotal = Ntotal \n)\nDefinición de modelo Bernoulli(\\(\\theta\\)), con distribución previa sobre \\(\\theta\\) Beta(1,1):\nmodelString = \"\nmodel {\n  for ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\" \nwriteLines( modelString , con=\"TEMPmodel.txt\" )\nEste modelo permite contestar la pregunta de qué tan grande es el sesgo de una moneda con respecto al valor de una moneda justa (\\(\\theta=1/2\\)).\nDefinición de varios valores iniciales, usando muestreo con reemplazo para estimar un MLE de \\(\\theta\\):\ninitsList = function() {\n  resampledY = sample( y , replace=TRUE )\n  thetaInit = sum(resampledY)/length(resampledY)\n  thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n  return( list( theta=thetaInit ) )\n}\nPreprocesamiento del MCMC:\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nEjecución del MCMC:\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\nDiagnósticos:\ndiagMCMC( codaObject=codaSamples , parName=\"theta\" )\nAjuste con el paquete R2jags:\nlibrary(R2jags)\n\n\nAttaching package: 'R2jags'\n\n\nThe following object is masked from 'package:coda':\n\n    traceplot\n\nbern_model &lt;- function() {\n  for (i in 1:N) {\n    y[i] ~ dbern(theta) \n  }\n  theta ~ dbeta(1, 1)   \n}\n\nbern_jags &lt;- \n  jags(\n    data = list(y = myData$y, N = nrow(myData)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\")\n  )\n\nmodule glm loaded\n\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nResumen:\nbern_jags\n\nInference for Bugs model at \"/tmp/RtmpkZR5K9/model1c4e439f5ca9d.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.308   0.063  0.192  0.263  0.305  0.349  0.441 1.001  3000\ndeviance  62.054   1.350 61.087 61.188 61.521 62.362 66.108 1.002  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 0.9 and DIC = 63.0\nDIC is an estimate of expected predictive error (lower deviance is better).\nGráficos alternativos usando el paquete bayesplot (compatible con ggplot2):\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\nPrimero transformamos el output de JAGS a coda:\nbern_mcmc &lt;- as.mcmc(bern_jags)\nplot(bern_mcmc)\nGráfico de la distribución posterior:\nmcmc_areas(\n  bern_mcmc,            \n  pars = c(\"theta\"),     \n  prob = 0.90)\nTraceplots combinados:\nmcmc_trace(bern_mcmc, pars = \"theta\")\nTraceplots separados:\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks runjags::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(ggformula)\n\nLoading required package: scales\n\nAttaching package: 'scales'\n\nThe following object is masked from 'package:purrr':\n\n    discard\n\nThe following object is masked from 'package:readr':\n\n    col_factor\n\nLoading required package: ggridges\n\nNew to ggformula?  Try the tutorials: \n    learnr::run_tutorial(\"introduction\", package = \"ggformula\")\n    learnr::run_tutorial(\"refining\", package = \"ggformula\")\n\nmcmc_trace(bern_mcmc, pars = \"theta\") %&gt;%\n  gf_facet_grid(chain ~ .) %&gt;%\n  gf_refine(scale_color_viridis_d())\n\nScale for colour is already present.\nAdding another scale for colour, which will replace the existing scale.\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) )\n\n\n\n\n\n\n\n\n           ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 9685.291 0.3080807 0.305302 0.2872137    0.95 0.1889107 0.4364605      NA\n      pGtCompVal ROPElow ROPEhigh pLtROPE pInROPE pGtROPE\ntheta         NA      NA       NA      NA      NA      NA\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) , \n          cenTend=\"median\" , compVal=0.5 , ROPE=c(0.45,0.55) , credMass=0.90 )\n\n\n\n\n\n\n\n\n           ESS      mean   median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 9685.291 0.3080807 0.305302 0.2872137     0.9 0.2012697 0.4121144     0.5\n      pGtCompVal ROPElow ROPEhigh   pLtROPE   pInROPE pGtROPE\ntheta 0.00229954    0.45     0.55 0.9830034 0.0169966       0",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos.html#ejemplo-2",
    "href": "estimacion_modelos.html#ejemplo-2",
    "title": "5  Estimación de Modelos Bayesianos",
    "section": "5.2 Ejemplo 2",
    "text": "5.2 Ejemplo 2\n\nmyData = read.csv(\"DBDA2Eprograms/z6N8z2N7.csv\")\ny = myData$y\ns = as.numeric(factor(myData$s)) # converts character to consecutive integer levels\n\n\nNtotal = length(y)\nNsubj = length(unique(s))\ndataList = list(\ny = y ,\ns = s ,\nNtotal = Ntotal ,\nNsubj = Nsubj\n)\n\n\nmodelString = \"\n  model {\n    for ( i in 1:Ntotal ) {\n      y[i] ~ dbern( theta[s[i]] )\n    }\n    for ( sIdx in 1:Nsubj ) {\n      theta[sIdx] ~ dbeta( 2 , 2 ) # N.B.: 2,2 prior; change as appropriate.\n    }\n  }\n  \"\nwriteLines( modelString , con=\"TEMPmodel.txt\" )\n\n\ninitsList = function() {\n    thetaInit = rep(0,Nsubj)\n    for ( sIdx in 1:Nsubj ) { # for each subject\n      includeRows = ( s == sIdx ) # identify rows of this subject\n      yThisSubj = y[includeRows]  # extract data of this subject\n      resampledY = sample( yThisSubj , replace=TRUE ) # resample\n      thetaInit[sIdx] = sum(resampledY)/length(resampledY) \n    }\n    thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n    return( list( theta=thetaInit ) )\n  }\n\n\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\n\n\ndiagMCMC( codaObject=codaSamples )\n\n\n\n\n\n\n\n\nJags-Ydich-XnomSsubj-MbernBeta-Example.R",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos</span>"
    ]
  },
  {
    "objectID": "computacion_bayes.html#evaluación-práctica-4",
    "href": "computacion_bayes.html#evaluación-práctica-4",
    "title": "4  Computación Bayesiana",
    "section": "4.6 Evaluación Práctica 4",
    "text": "4.6 Evaluación Práctica 4\nLa siguiente es la implementación de una función que calcule la verosimilitud de este ejemplo:\n\nlogPoisson &lt;- function(betas,data){\n  beta0 &lt;- betas[1]\n  beta1 &lt;- betas[2]\n  month &lt;- data[,1]\n  y &lt;- data[,2]\n  vector_logvero &lt;- y*(beta0+beta1*month)-exp(beta0+beta1*month)\n  logvero &lt;- sum(vector_logvero)\n}\n\nen donde asumimos que los datos son:\n\ndataPoisson &lt;- data.frame(month = 1:18,yi = c(15,11,14,17,5,11,10,4,8,10,7,9,11,3,6,1,1,4))\n\nPara verificar, hacemos un gráfico de contorno de la logverosimilitud:\n\nmycontour(logPoisson,c(2,3.5,-0.18,0),dataPoisson,\n          xlab=\"Beta0\",ylab=\"Beta1\")\n\n\n\n\n\n\n\n\nAjustamos el método de Laplace usando como valor inicial el punto (2.6,-0.1):\n\nfit_laplace &lt;- laplace(logPoisson ,c(2.6,-0.1),dataPoisson)\nfit_laplace$mode\n\n[1]  2.80291445 -0.08373524\n\nfit_laplace$var\n\n             [,1]         [,2]\n[1,]  0.021953402 -0.002067647\n[2,] -0.002067647  0.000282176\n\n\nCon lo anterior podemos estimar la media de \\(\\beta_1\\) como:\n\nmean_laplace &lt;- fit_laplace$mode[2]\nshow(mean_laplace)\n\n[1] -0.08373524\n\n\ny su desviación estándar como:\n\nsd_laplace &lt;- sqrt(fit_laplace$var[2,2])\nshow(sd_laplace)\n\n[1] 0.0167981\n\n\nNota: También se vale hacerlo con simulación. Si no lo hicieron de esa forma, lo pueden intentar.\n\nstart &lt;- fit_laplace$mode\nproposal_poisson &lt;- list(var=fit_laplace$var,scale=2)\nbayesfit_poisson &lt;- rwmetrop(logPoisson,proposal_poisson,start,1000,dataPoisson)\n\nY con esto calculamos la media y desviación posterior usando nuestras muestras MCMC (usamos un burn-in de un 10% de la muestra):\n\nmean_mcmc &lt;- mean(bayesfit_poisson$par[100:1000,2])\nsd_mcmc &lt;- sd(bayesfit_poisson$par[100:1000,2])\n\nTraceplot de la muestra completa:\n\nplot(bayesfit_poisson$par[,2],type='l')\n\n\n\n\n\n\n\n\nLes recomiendo hacer más diagnósticos a las muestras de \\(\\beta_0\\) y \\(\\beta_1\\).\nTabla de resultados basada en la Tabla 6.2 del Albert:\n\nID_laplace &lt;- mean_laplace+c(-1,1)*qnorm(0.975)*sd_laplace\nID_mcmc &lt;- quantile(bayesfit_poisson$par[100:1000,2],probs = c(0.025,0.975))\nlaplace_row &lt;- c(NA,c(ID_laplace[1],mean_laplace,ID_laplace[2]))\nmcmc_row &lt;- c(bayesfit_poisson$accept,c(ID_mcmc[1],mean_mcmc,ID_mcmc[2]))\ntabla_res &lt;- data.frame(rbind(laplace_row,mcmc_row))\ncolnames(tabla_res) &lt;- c('Aceptacion','beta1_low','beta1_est','beta1_up')\nrownames(tabla_res) &lt;- c('Laplace','MH-Random Walk')\n\n\nlibrary(kableExtra)\n\n\nAttaching package: 'kableExtra'\n\n\nThe following object is masked from 'package:dplyr':\n\n    group_rows\n\nkable(tabla_res)\n\n\n\n\n\nAceptacion\nbeta1_low\nbeta1_est\nbeta1_up\n\n\n\n\nLaplace\nNA\n-0.1166589\n-0.0837352\n-0.0508116\n\n\nMH-Random Walk\n0.281\n-0.1211206\n-0.0848761\n-0.0548695",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Computación Bayesiana</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html",
    "href": "estimacion_modelos1.html",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "",
    "text": "5.1 Sesgo de una moneda (Kruschke, pag 195)\nCarga de librería rjags y funciones utilitarias del Kruschke:\nlibrary(rjags)\nsource('DBDA2Eprograms/DBDA2E-utilities.R')\n\n\n*********************************************************************\nKruschke, J. K. (2015). Doing Bayesian Data Analysis, Second Edition:\nA Tutorial with R, JAGS, and Stan. Academic Press / Elsevier.\n*********************************************************************\nCarga de datos y definición de la estructura de datos para JAGS. Los datos se pueden entender como realizaciones de lanzamientos de una moneda (0: escudo, 1: corona; por ejemplo)\nmyData = read.csv(\"DBDA2Eprograms/z15N50.csv\") \ny = myData$y        \nNtotal = length(y)  \ndataList = list(    \n  y = y ,\n  Ntotal = Ntotal \n)\nDefinición de modelo Bernoulli(\\(\\theta\\)), con distribución previa sobre \\(\\theta\\) Beta(1,1):\nmodelString = \"\nmodel {\n  for ( i in 1:Ntotal ) {\n    y[i] ~ dbern( theta )\n  }\n  theta ~ dbeta( 1 , 1 )\n}\n\" \nwriteLines( modelString , con=\"TEMPmodel.txt\" )\nEste modelo permite contestar la pregunta de qué tan grande es el sesgo de una moneda con respecto al valor de una moneda justa (\\(\\theta=1/2\\)).\nDefinición de varios valores iniciales, usando muestreo con reemplazo para estimar un MLE de \\(\\theta\\):\ninitsList = function() {\n  resampledY = sample( y , replace=TRUE )\n  thetaInit = sum(resampledY)/length(resampledY)\n  thetaInit = 0.001+0.998*thetaInit # keep away from 0,1\n  return( list( theta=thetaInit ) )\n}\nPreprocesamiento del MCMC:\njagsModel = jags.model( file=\"TEMPmodel.txt\" , data=dataList , inits=initsList , \n                        n.chains=3 , n.adapt=500 )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nEjecución del MCMC:\ncodaSamples = coda.samples( jagsModel , variable.names=c(\"theta\") ,\n                            n.iter=3334 )\nDiagnósticos:\ndiagMCMC( codaObject=codaSamples , parName=\"theta\" )\nAjuste con el paquete R2jags:\nlibrary(R2jags)\n\nbern_model &lt;- function() {\n  for (i in 1:N) {\n    y[i] ~ dbern(theta) \n  }\n  theta ~ dbeta(1, 1)   \n}\n\nbern_jags &lt;- \n  jags(\n    data = list(y = myData$y, N = nrow(myData)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\")\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nResumen:\nbern_jags\n\nInference for Bugs model at \"/tmp/RtmpPjfSei/model6e9e5f7fbd7f.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.308   0.062  0.195  0.264  0.306  0.349  0.439 1.002  1700\ndeviance  62.028   1.345 61.087 61.184 61.517 62.310 65.829 1.001  3000\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 0.9 and DIC = 62.9\nDIC is an estimate of expected predictive error (lower deviance is better).\nGráficos alternativos usando el paquete bayesplot (compatible con ggplot2):\nlibrary(bayesplot)\nPrimero transformamos el output de JAGS a coda:\nbern_mcmc &lt;- as.mcmc(bern_jags)\nplot(bern_mcmc)\nGráfico de la distribución posterior:\nmcmc_areas(\n  bern_mcmc,            \n  pars = c(\"theta\"),     \n  prob = 0.90)\nTraceplots combinados:\nmcmc_trace(bern_mcmc, pars = \"theta\")\nTraceplots separados:\nlibrary(tidyverse)\nlibrary(ggformula)\n\nmcmc_trace(bern_mcmc, pars = \"theta\") %&gt;%\n  gf_facet_grid(chain ~ .) %&gt;%\n  gf_refine(scale_color_viridis_d())\nGráficos incluidos en los archivos del libro:\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) )\n\n\n\n\n\n\n\n\n        ESS      mean    median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 10002 0.3069837 0.3048172 0.2904594    0.95 0.1870631 0.4342261      NA\n      pGtCompVal ROPElow ROPEhigh pLtROPE pInROPE pGtROPE\ntheta         NA      NA       NA      NA      NA      NA\nplotPost( codaSamples[,\"theta\"] , main=\"theta\" , xlab=bquote(theta) , \n          cenTend=\"median\" , compVal=0.5 , ROPE=c(0.45,0.55) , credMass=0.90 )\n\n\n\n\n\n\n\n\n        ESS      mean    median      mode hdiMass    hdiLow   hdiHigh compVal\ntheta 10002 0.3069837 0.3048172 0.2904594     0.9 0.2003451 0.4085078     0.5\n      pGtCompVal ROPElow ROPEhigh   pLtROPE   pInROPE pGtROPE\ntheta 0.00209958    0.45     0.55 0.9840032 0.0159968       0\no bien se puede usar el paquete de github CalvinBayes (https://github.com/CalvinData/CalvinBayes) para hacer los mismos gráficos con el objeto obtenido en R2jags:\nlibrary(CalvinBayes)\n\ndiag_mcmc(bern_mcmc, par = \"theta\")\nplot_post(bern_mcmc[, \"theta\"], main = \"theta\", xlab = expression(theta),\n         cenTend = \"median\", compVal = 0.5, ROPE = c(0.45, 0.55), \n         credMass = 0.90, quietly = TRUE)\nOtra corrida de jags con distintos argumentos:\nset.seed(76543)\nbern_jags2 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    n.chains = 4, n.iter = 5000, n.burnin = 1000,n.thin = 1)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\n\nbern_jags2\n\nInference for Bugs model at \"/tmp/RtmpPjfSei/model6e9e1f4d9b64.txt\", fit using jags,\n 4 chains, each with 5000 iterations (first 1000 discarded)\n n.sims = 16000 iterations saved\n         mu.vect sd.vect   2.5%    25%    50%    75%  97.5%  Rhat n.eff\ntheta      0.307   0.063  0.192  0.263  0.305  0.349  0.438 1.001 14000\ndeviance  62.055   1.388 61.088 61.186 61.527 62.355 66.079 1.002  3400\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 1.0 and DIC = 63.0\nDIC is an estimate of expected predictive error (lower deviance is better).\nY podemos correr también modelos con distintos valores iniciales:\nset.seed(2345)\nbern_jags3 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    # start each chain by sampling from the prior\n    inits = function() list(theta = rbeta(1, 3, 3))    \n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\n\nbern_jags4 &lt;- \n  jags(\n    data = list(y = z15N50$y, N = nrow(z15N50)),\n    model.file = bern_model,\n    parameters.to.save = c(\"theta\"),\n    # choose specific starting point for each chain\n    inits = list(\n      list(theta = 0.5), list(theta = 0.7), list(theta = 0.9)\n    )\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 50\n   Unobserved stochastic nodes: 1\n   Total graph size: 53\n\nInitializing model\nmcmc_trace(as.mcmc(bern_jags4), pars = \"theta\")",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-2",
    "href": "estimacion_modelos1.html#ejemplo-2",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.2 Ejemplo 2",
    "text": "5.2 Ejemplo 2\nDos individuos (Reginald y Tony) tiran cada uno una moneda. Se tiene los resultados de los tiros de cada moneda:\n\nlibrary(mosaic)\n\nRegistered S3 method overwritten by 'mosaic':\n  method                           from   \n  fortify.SpatialPolygonsDataFrame ggplot2\n\n\n\nThe 'mosaic' package masks several functions from core packages in order to add \nadditional features.  The original behavior of these functions should not be affected by this.\n\n\n\nAttaching package: 'mosaic'\n\n\nThe following object is masked from 'package:Matrix':\n\n    mean\n\n\nThe following object is masked from 'package:scales':\n\n    rescale\n\n\nThe following objects are masked from 'package:dplyr':\n\n    count, do, tally\n\n\nThe following object is masked from 'package:purrr':\n\n    cross\n\n\nThe following object is masked from 'package:ggplot2':\n\n    stat\n\n\nThe following objects are masked from 'package:stats':\n\n    binom.test, cor, cor.test, cov, fivenum, IQR, median, prop.test,\n    quantile, sd, t.test, var\n\n\nThe following objects are masked from 'package:base':\n\n    max, mean, min, prod, range, sample, sum\n\nhead(z6N8z2N7)  \n\n# A tibble: 6 × 2\n      y s       \n  &lt;dbl&gt; &lt;chr&gt;   \n1     1 Reginald\n2     0 Reginald\n3     1 Reginald\n4     1 Reginald\n5     1 Reginald\n6     1 Reginald\n\n\n\nTarget &lt;- z6N8z2N7 %&gt;%\n  rename(hit = y, subject = s)\ndf_stats(hit ~ subject, data = Target, props, attempts = length)\n\n  response  subject    prop_0    prop_1 attempts\n1      hit Reginald 0.2500000 0.7500000        8\n2      hit     Tony 0.7142857 0.2857143        7\n\n\nModelo:\n\nbern2_model &lt;- function() {\n  for (i in 1:Nobs) {\n    hit[i] ~ dbern(theta[subject[i]])  \n  }\n  for (s in 1:Nsub) {\n    theta[s] ~ dbeta(2, 2)   \n  }\n}\n\nDatos:\n\nTargetList &lt;-\n  list(\n    Nobs = nrow(Target),\n    Nsub = 2,\n    hit = Target$hit,\n    subject = as.numeric(as.factor(Target$subject))\n)\nTargetList\n\n$Nobs\n[1] 15\n\n$Nsub\n[1] 2\n\n$hit\n [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n\n$subject\n [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n\n\nAjuste:\n\nbern2_jags &lt;- \n  jags(\n    data = TargetList,\n    model = bern2_model,\n    parameters.to.save = \"theta\")\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\n\nDiagnósticos:\n\nbern2_mcmc &lt;- as.mcmc(bern2_jags)\ndiag_mcmc(bern2_mcmc,parName = 'theta[1]')\n\n\n\n\n\n\n\n\n\nmcmc_acf(bern2_mcmc)\n\n\n\n\n\n\n\n\n\nmcmc_pairs(bern2_mcmc, pars = c(\"theta[1]\", \"theta[2]\"))\n\n\n\n\n\n\n\n\n\nmcmc_combo(bern2_mcmc)\n\n\n\n\n\n\n\n\nEstamos interesados en analizar la diferencia entre \\(\\theta_1\\) (Reginald) y \\(\\theta_2\\) (Tony):\n\nhead(posterior(bern2_jags))\n\n  deviance   theta.1   theta.2   chain iter\n1 17.40840 0.7775109 0.2917246 chain:1    1\n2 18.81437 0.8021381 0.4986514 chain:1    2\n3 17.72482 0.6563450 0.2599003 chain:1    3\n4 17.78892 0.6546149 0.3343049 chain:1    4\n5 17.50901 0.7569896 0.3506096 chain:1    5\n6 17.72967 0.6733703 0.3503326 chain:1    6\n\npost2 &lt;- posterior(bern2_jags) %&gt;% mutate(dif = theta.1-theta.2)\nmean(post2$dif)\n\n[1] 0.2996498\n\nquantile(post2$dif,c(0.025,0.975))\n\n       2.5%       97.5% \n-0.09420704  0.66259903 \n\n\n\ngf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerarquica",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerarquica",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerarquica",
    "text": "5.3 Ejemplo de Modelación Jerarquica\nhttps://jamanetwork.com/journals/jama/fullarticle/187390",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#sesgos-de-dos-monedas",
    "href": "estimacion_modelos1.html#sesgos-de-dos-monedas",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.2 Sesgos de dos monedas",
    "text": "5.2 Sesgos de dos monedas\nDos individuos (Reginald y Tony) tiran cada uno una moneda. Se tiene los resultados de los intentos de cada individuo:\n\nlibrary(mosaic)\nhead(z6N8z2N7)  \n\n# A tibble: 6 × 2\n      y s       \n  &lt;dbl&gt; &lt;chr&gt;   \n1     1 Reginald\n2     0 Reginald\n3     1 Reginald\n4     1 Reginald\n5     1 Reginald\n6     1 Reginald\n\n\nCambiamos los nombres de las variables. Además, noten que las proporciones de 0s y 1s obtenidas por cada individuo son muy distintas entre sí, por lo tanto en el modelo sería conveniente usar una probabilidad de ocurrencia de 1s distinta por individuo.\n\nTarget &lt;- z6N8z2N7 %&gt;%\n  rename(hit = y, subject = s)\ndf_stats(hit ~ subject, data = Target, props, attempts = length)\n\n  response  subject    prop_0    prop_1 attempts\n1      hit Reginald 0.2500000 0.7500000        8\n2      hit     Tony 0.7142857 0.2857143        7\n\n\nEl modelo en este caso considera la observación anterior:\n\nbern2_model &lt;- function() {\n  for (i in 1:Nobs) {\n    hit[i] ~ dbern(theta[subject[i]])  \n  }\n  for (s in 1:Nsub) {\n    theta[s] ~ dbeta(2, 2)   \n  }\n}\n\nLos datos deben declararse en la siguiente lista:\n\nTargetList &lt;-\n  list(\n    Nobs = nrow(Target),\n    Nsub = 2,\n    hit = Target$hit,\n    subject = as.numeric(as.factor(Target$subject))\n)\nTargetList\n\n$Nobs\n[1] 15\n\n$Nsub\n[1] 2\n\n$hit\n [1] 1 0 1 1 1 1 1 0 0 0 1 0 0 1 0\n\n$subject\n [1] 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2\n\n\nY realizamos el ajuste MCMC:\n\nbern2_jags &lt;- \n  jags(\n    data = TargetList,\n    model = bern2_model,\n    parameters.to.save = \"theta\")\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 15\n   Unobserved stochastic nodes: 2\n   Total graph size: 35\n\nInitializing model\n\n\nDiagnósticos para \\(\\theta_1\\). (Hacer los diagnósticos de \\(\\theta_2\\) como ejercicio)\n\nbern2_mcmc &lt;- as.mcmc(bern2_jags)\ndiag_mcmc(bern2_mcmc,parName = 'theta[1]')\n\n\n\n\n\n\n\n\n\nmcmc_acf(bern2_mcmc)\n\n\n\n\n\n\n\n\n\nmcmc_pairs(bern2_mcmc, pars = c(\"theta[1]\", \"theta[2]\"))\n\n\n\n\n\n\n\n\n\nmcmc_combo(bern2_mcmc)\n\n\n\n\n\n\n\n\nEstamos interesados en analizar la diferencia entre \\(\\theta_1\\) (Reginald) y \\(\\theta_2\\) (Tony), en particular a través de la diferencia \\(\\theta_1-\\theta_2\\). Note que a través de esta diferencia, es posible medir la hipótesis nula \\(H_0: \\theta_1&gt; \\theta_2\\):\n\nhead(posterior(bern2_jags))\n\n  deviance   theta.1   theta.2   chain iter\n1 17.40840 0.7775109 0.2917246 chain:1    1\n2 18.81437 0.8021381 0.4986514 chain:1    2\n3 17.72482 0.6563450 0.2599003 chain:1    3\n4 17.78892 0.6546149 0.3343049 chain:1    4\n5 17.50901 0.7569896 0.3506096 chain:1    5\n6 17.72967 0.6733703 0.3503326 chain:1    6\n\npost2 &lt;- posterior(bern2_jags) %&gt;% mutate(dif = theta.1-theta.2)\nmean(post2$dif)\n\n[1] 0.2996498\n\nquantile(post2$dif,c(0.025,0.975))\n\n       2.5%       97.5% \n-0.09420704  0.66259903 \n\n\n\ngf_density( ~(theta.1 - theta.2), data = posterior(bern2_jags))\n\n\n\n\n\n\n\n\nPara medir \\(H_0\\), estimamos la probabilidad posterior de \\(H_0\\):\n\nsum(post2$dif&gt;0)/3000  \n\n[1] 0.9323333\n\n\nPor lo tanto la probabilidad de que \\(H_0\\) sea cierta es 0.9323 y la probabilidad de rechazar tal hipótesis (o bien aceptar \\(H_1: \\theta_1&lt;\\theta_2\\)) es 6.77%.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerárquica",
    "text": "5.3 Ejemplo de Modelación Jerárquica\nhttps://jamanetwork.com/journals/jama/fullarticle/187390",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica-sección-9.2.4-kruschke",
    "href": "estimacion_modelos1.html#ejemplo-de-modelación-jerárquica-sección-9.2.4-kruschke",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.3 Ejemplo de Modelación Jerárquica (sección 9.2.4, Kruschke)",
    "text": "5.3 Ejemplo de Modelación Jerárquica (sección 9.2.4, Kruschke)\nContexto: El Toque Terapéutico (TT) es una práctica de enfermería que se dice trata condiciones médicas manipulando un “campo de energía humano” con las manos de los practicantes. Este estudio tuvo como objetivo probar si los practicantes de TT pueden percibir este campo de energía. Veintiún practicantes con 1 a 27 años de experiencia en TT fueron evaluados en condiciones cegadas. Se les pidió que identificaran cuál de sus manos estaba más cerca de la mano del investigador, que se colocaba al azar mediante el lanzamiento de una moneda. Catorce practicantes fueron evaluados 10 veces cada uno, y siete fueron evaluados 20 veces cada uno. La capacidad de los practicantes para identificar correctamente la posición de la mano del investigador se comparó con una tasa de éxito del 50% esperada por casualidad.\nPregunta de Investigación: ¿Las tasas de acierto para los practicantes será mayor al 50%?\nCarga de datos:\n\nhead(TherapeuticTouch, 3)\n\n# A tibble: 3 × 2\n      y s    \n  &lt;dbl&gt; &lt;chr&gt;\n1     1 S01  \n2     0 S01  \n3     0 S01  \n\n\nLas tasas de acierto empíricas para cada individuo se pueden visualizar de la siguiente forma:\n\ngf_bar(s ~ ., data = TherapeuticTouch, fill = ~ factor(y))\n\n\n\n\n\n\n\n\nde donde es interesante observar la diferencia entre tasas de acierto entre individuos (que en este caso está ordenado del que tiene menos al que tiene más acierto). Es por esto que un modelo con tasa de acierto variable por individuos tendría sentido.\nRecuerden que el modelo jerárquico tendría la forma:\n\\[\\begin{align*}\ny_{i|s} & \\sim \\text{Ber}(\\theta_s)\\\\\n\\theta_s & \\sim \\text{Beta}(\\omega(K-2)+1,(1-\\omega)(K-2)+1)\\\\\n\\omega & \\sim \\text{Beta}(1,1)\\\\\nK-2 & \\sim \\text{Gamma}(0.01,0.01)\n\\end{align*}\\]\ndonde esta última escogencia se hiperparámetros se basa en la aplicación de la siguiente función:\n\ngamma_params(mean = 1, sd = 10)\n\n# A tibble: 1 × 6\n  shape  rate scale mode   mean    sd\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  0.01  0.01   100 NA        1    10\n\n\nque garantiza una v.a. Gamma con media 1 y desviación estándar 10 (previas no-informativas).\nLa definición del modelo en lenguaje JAGS sería:\n\ntouch_model &lt;- function() {\n  for (i in 1:Ntotal) {\n    y[i] ~ dbern(theta[s[i]])\n  }\n  for (s in 1:Nsubj) {\n    theta[s] ~ dbeta(omega * (kappa - 2) + 1, (1 - omega) * (kappa - 2) + 1)\n  }\n  omega ~ dbeta(1, 1)\n  kappa &lt;- kappaMinusTwo + 2\n  kappaMinusTwo ~ dgamma(0.01, 0.01)     # mean = 1, sd = 10\n}\n\ncon el arreglo de datos:\n\nTouchData &lt;- list(\n  Ntotal = nrow(TherapeuticTouch),\n  Nsubj = length(unique(TherapeuticTouch$s)),\n  y = TherapeuticTouch$y,\n  # must convert subjects to sequence 1:Nsubj\n  s = as.numeric(factor(TherapeuticTouch$s))\n)\n\nSe procede a un ajuste preliminar, con los valores por default de JAGS:\n\nset.seed(1234)\ntouch_jags &lt;-\n  jags(\n    data = TouchData,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n  )\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 280\n   Unobserved stochastic nodes: 30\n   Total graph size: 602\n\nInitializing model\n\n\nSi analizamos los diagnósticos de convergencia, notamos que hay mucho autocorrelación en la series (usando el tamaño efectivo de muestra):\n\ntouch_jags\n\nInference for Bugs model at \"/tmp/RtmpPjfSei/model6e9e3267ecb6.txt\", fit using jags,\n 3 chains, each with 2000 iterations (first 1000 discarded)\n n.sims = 3000 iterations saved\n          mu.vect sd.vect    2.5%     25%     50%     75%   97.5%  Rhat n.eff\nkappa      52.286  54.028   8.932  20.025  34.399  65.489 210.966 1.056    44\nomega       0.439   0.035   0.367   0.416   0.439   0.462   0.508 1.004  1100\ntheta[1]    0.363   0.088   0.175   0.305   0.369   0.426   0.517 1.016   210\ntheta[2]    0.384   0.084   0.208   0.331   0.389   0.444   0.536 1.015   190\ntheta[3]    0.409   0.081   0.241   0.358   0.414   0.463   0.564 1.005   970\ntheta[4]    0.411   0.083   0.236   0.357   0.415   0.467   0.564 1.020   270\ntheta[5]    0.409   0.080   0.244   0.358   0.411   0.461   0.563 1.010   500\ntheta[6]    0.410   0.082   0.235   0.359   0.414   0.464   0.562 1.006  1100\ntheta[7]    0.409   0.080   0.244   0.359   0.412   0.461   0.560 1.019   180\ntheta[8]    0.410   0.080   0.243   0.360   0.413   0.462   0.565 1.012   510\ntheta[9]    0.407   0.080   0.247   0.356   0.410   0.459   0.561 1.008   650\ntheta[10]   0.409   0.081   0.238   0.358   0.413   0.463   0.559 1.008   710\ntheta[11]   0.433   0.077   0.276   0.384   0.433   0.483   0.588 1.004  1700\ntheta[12]   0.433   0.081   0.278   0.383   0.434   0.485   0.593 1.005   710\ntheta[13]   0.434   0.078   0.280   0.385   0.434   0.484   0.587 1.002  3000\ntheta[14]   0.432   0.080   0.272   0.380   0.432   0.482   0.593 1.001  3000\ntheta[15]   0.433   0.080   0.275   0.381   0.434   0.484   0.590 1.004  3000\ntheta[16]   0.457   0.080   0.300   0.408   0.454   0.504   0.624 1.002  3000\ntheta[17]   0.456   0.079   0.295   0.406   0.453   0.506   0.621 1.002  1600\ntheta[18]   0.454   0.081   0.295   0.401   0.453   0.504   0.626 1.003  3000\ntheta[19]   0.457   0.078   0.313   0.407   0.454   0.505   0.618 1.001  3000\ntheta[20]   0.455   0.080   0.298   0.403   0.452   0.508   0.612 1.003  3000\ntheta[21]   0.457   0.082   0.296   0.404   0.455   0.510   0.621 1.005  1000\ntheta[22]   0.457   0.079   0.311   0.405   0.454   0.507   0.625 1.003  1800\ntheta[23]   0.480   0.083   0.328   0.425   0.474   0.529   0.658 1.008   510\ntheta[24]   0.482   0.083   0.327   0.427   0.476   0.531   0.660 1.003  1300\ntheta[25]   0.506   0.088   0.351   0.446   0.497   0.562   0.691 1.008   260\ntheta[26]   0.507   0.088   0.354   0.446   0.498   0.560   0.700 1.003   680\ntheta[27]   0.505   0.087   0.355   0.445   0.495   0.559   0.695 1.008   250\ntheta[28]   0.527   0.093   0.374   0.460   0.517   0.581   0.735 1.008   300\ndeviance  378.963   5.156 368.591 375.437 379.284 382.411 388.755 1.010   220\n\nFor each parameter, n.eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor (at convergence, Rhat=1).\n\nDIC info (using the rule, pD = var(deviance)/2)\npD = 13.2 and DIC = 392.1\nDIC is an estimate of expected predictive error (lower deviance is better).\n\n\nAjustamos el modelo con un número de mayor de cadenas, con mayor tamaño de muestra posterior y con thinning. Noten que ejecutamos el modelo paralelizando el proceso (1 core por cadena)\n\ntouch_jags &lt;-\n  jags.parallel(\n    data = TouchData,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n    n.burnin = 1000,\n    n.iter = 41000,\n    n.chains = 5,\n    n.thin = 10,\n    jags.seed = 54321\n  )   \n\ny la autorrelación se mejora considerablemente, al comparar el tamaño de muestra efectivo del primer modelo con respecto al segundo:\n\ntouch_jags$BUGSoutput$summary[,'n.eff']\n\n deviance     kappa     omega  theta[1]  theta[2]  theta[3]  theta[4]  theta[5] \n    20000      5800     14000     14000     19000     20000      6500     20000 \n theta[6]  theta[7]  theta[8]  theta[9] theta[10] theta[11] theta[12] theta[13] \n    20000     19000     20000     20000     20000     20000     19000     20000 \ntheta[14] theta[15] theta[16] theta[17] theta[18] theta[19] theta[20] theta[21] \n     8300     13000     20000     16000      8700     20000     20000     20000 \ntheta[22] theta[23] theta[24] theta[25] theta[26] theta[27] theta[28] \n    15000     20000     10000     10000     20000     20000     20000 \n\n\nAhora hacemos algunos gráficos para analizar las muestras posteriores:\n\ntouch_mcmc &lt;- as.mcmc(touch_jags)\nplot_post(touch_mcmc[, \"omega\"], comparison_value = 0.5)\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 13197.07 0.4351743 0.4355163 0.4375461\n\n$hdi\n  prob        lo        hi\n1 0.95 0.3597935 0.5071227\n\n$comparison\n  value P(&lt; comp. val.) P(&gt; comp. val.)\n1   0.5          0.9596          0.0404\n\n\nDe donde se concluye que el 96% de la población de practicantes no tienen una tasa de acierto general mayor al 50%. Este análisis se puede realizar para la tasa de acierto del sujeto #28:\n\nplot_post(touch_mcmc[, \"theta[28]\"], comparison_value = 0.5)\n\n\n\n\n\n\n\n\n$posterior\n          ESS      mean    median      mode\nvar1 12746.09 0.5248268 0.5141253 0.4994144\n\n$hdi\n  prob        lo       hi\n1 0.95 0.3582065 0.717917\n\n$comparison\n  value P(&lt; comp. val.) P(&gt; comp. val.)\n1   0.5         0.43435         0.56565\n\n\nDiagnósticos del parámetro de precisión de la tasa de acierto individual:\n\ndiag_mcmc(touch_mcmc, par = \"kappa\")\n\n\n\n\n\n\n\n\nGráfico de dispersión entre las muestras posteriores de \\(K\\) y \\(\\omega\\):\n\nmcmc_pairs(touch_mcmc, pars = c(\"omega\", \"kappa\"))\n\n\n\n\n\n\n\n\nMuestreo a partir de la previa:\n\nTouchData_pre &lt;- list(\n  Ntotal = 0,\n  Nsubj = length(unique(TherapeuticTouch$s)),\n  # must convert subjects to sequence 1:Nsubj\n  s = as.numeric(factor(TherapeuticTouch$s))\n)\n\ntouch_jags_pre &lt;-\n  jags.parallel(\n    data = TouchData_pre,\n    model = touch_model,\n    parameters.to.save = c(\"theta\", \"kappa\", \"omega\"),\n    n.burnin = 1000,\n    n.iter = 41000,\n    n.chains = 5,\n    n.thin = 10,\n    jags.seed = 54321,\n    DIC = F\n  )\n\nDiagnósticos:\n\ndiag_mcmc(touch_mcmc, par = \"theta[1]\")\nmcmc_pairs(touch_mcmc, pars = c(\"omega\", \"kappa\"))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  },
  {
    "objectID": "estimacion_modelos1.html#introducción-a-stan",
    "href": "estimacion_modelos1.html#introducción-a-stan",
    "title": "5  Estimación de Modelos Bayesianos (Parte 1)",
    "section": "5.4 Introducción a STAN",
    "text": "5.4 Introducción a STAN\nCarga de librería:\n\nlibrary(rstan)\nrstan_options(auto_write = TRUE)\n\nPara ilustrar el uso de STAN, se va a ajustar un modelo Bernoulli a datos sintéticos. El modelo está definido en el archivo moneda.stan en el repositorio de estas notas.\n\nmodelo_moneda &lt;- stan_model(file = 'moneda.stan',verbose = T)\n\n\nTRANSLATING MODEL '' FROM Stan CODE TO C++ CODE NOW.\n\nmodelo_moneda\n\nS4 class stanmodel 'anon_model' coded as follows:\n//\n// This Stan program defines a simple model, with a\n// vector of values 'y' modeled as normally distributed\n// with mean 'mu' and standard deviation 'sigma'.\n//\n// Learn more about model development with Stan at:\n//\n//    http://mc-stan.org/users/interfaces/rstan.html\n//    https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started\n//\n// The input data is a vector 'y' of length 'N'.\ndata {\n  int&lt;lower=0&gt; N;  // N is a non-negative integer\n  int y[N];          // y is a length-N vector of integers\n}\n// The parameters accepted by the model. Our model\n// accepts two parameters 'mu' and 'sigma'.\nparameters {\n  real&lt;lower=0,upper=1&gt; theta;  // theta is between 0 and 1\n}\n// The model to be estimated. We model the output\n// 'y' to be normally distributed with mean 'mu'\n// and standard deviation 'sigma'.\nmodel {\n  theta ~ beta (1,1);\n  y ~ bernoulli(theta);\n} \n\n\nAjuste del modelo en condiciones similares a las que JAGS trabaja por default:\n\nsimple_stanfit &lt;- \n  sampling(\n    modelo_moneda, \n    data  = list(\n      N = 50,\n      y = c(rep(1, 15), rep(0, 35))\n    ),\n    chains = 3,     # default is 4\n    iter = 1000,    # default is 2000\n    warmup = 200    # default is half of iter\n  )\n\n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 3e-06 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0.03 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 1: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 1: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 1: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 1: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 1: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 1: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 1: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 1: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 1: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 1: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 1: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0 seconds (Warm-up)\nChain 1:                0.003 seconds (Sampling)\nChain 1:                0.003 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 1e-06 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 2: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 2: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 2: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 2: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 2: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 2: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 2: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 2: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 2: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 2: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 2: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.001 seconds (Warm-up)\nChain 2:                0.003 seconds (Sampling)\nChain 2:                0.004 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'anon_model' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 1e-06 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0.01 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:   1 / 1000 [  0%]  (Warmup)\nChain 3: Iteration: 100 / 1000 [ 10%]  (Warmup)\nChain 3: Iteration: 200 / 1000 [ 20%]  (Warmup)\nChain 3: Iteration: 201 / 1000 [ 20%]  (Sampling)\nChain 3: Iteration: 300 / 1000 [ 30%]  (Sampling)\nChain 3: Iteration: 400 / 1000 [ 40%]  (Sampling)\nChain 3: Iteration: 500 / 1000 [ 50%]  (Sampling)\nChain 3: Iteration: 600 / 1000 [ 60%]  (Sampling)\nChain 3: Iteration: 700 / 1000 [ 70%]  (Sampling)\nChain 3: Iteration: 800 / 1000 [ 80%]  (Sampling)\nChain 3: Iteration: 900 / 1000 [ 90%]  (Sampling)\nChain 3: Iteration: 1000 / 1000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0 seconds (Warm-up)\nChain 3:                0.003 seconds (Sampling)\nChain 3:                0.003 seconds (Total)\nChain 3: \n\n\n\nsimple_stanfit\n\nInference for Stan model: anon_model.\n3 chains, each with iter=1000; warmup=200; thin=1; \npost-warmup draws per chain=800, total post-warmup draws=2400.\n\n        mean se_mean   sd   2.5%    25%    50%    75%  97.5% n_eff Rhat\ntheta   0.31    0.00 0.07   0.19   0.26   0.31   0.35   0.44   742    1\nlp__  -32.64    0.03 0.80 -34.90 -32.79 -32.34 -32.16 -32.10   949    1\n\nSamples were drawn using NUTS(diag_e) at Tue Jun 11 11:13:28 2024.\nFor each parameter, n_eff is a crude measure of effective sample size,\nand Rhat is the potential scale reduction factor on split chains (at \nconvergence, Rhat=1).\n\n\nAlgunos diagnósticos:\n\ngf_dens(~theta, data = posterior(simple_stanfit))\n\n\n\n\n\n\n\nsimple_mcmc &lt;- as.matrix(simple_stanfit)\nmcmc_areas(as.mcmc.list(simple_stanfit), prob = 0.9, pars = \"theta\")\n\n\n\n\n\n\n\ndiag_mcmc(as.mcmc.list(simple_stanfit))",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Estimación de Modelos Bayesianos (Parte 1)</span>"
    ]
  }
]